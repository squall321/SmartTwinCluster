# YAML ê¸°ë°˜ Slurm ì„¤ì • - ë©”ì¸ ê°€ì´ë“œ

## ğŸ¯ í•µì‹¬ ìš”ì•½

**ë¬¸ì œ**: `configure_slurm_cgroup_v2.sh`ê°€ í•˜ë“œì½”ë”©ë˜ì–´ `my_cluster.yaml`ì˜ `reboot_program` ì„¤ì •ì´ ë°˜ì˜ë˜ì§€ ì•ŠìŒ

**í•´ê²°**: YAML ê¸°ë°˜ Python ìŠ¤í¬ë¦½íŠ¸ë¡œ ëª¨ë“  ì„¤ì •ì„ ë™ì ìœ¼ë¡œ ìƒì„±

---

## â“ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸

### Q1: setup_cluster_full.shëŠ” ì´ì œ ì•ˆ ì“°ë‚˜ìš”?

**A: ì•„ë‹™ë‹ˆë‹¤! ì—¬ì „íˆ ë©”ì¸ ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.**

- `setup_cluster_full.sh`ì˜ 11ë‹¨ê³„ ì¤‘ **Step 8ë§Œ** YAML ê¸°ë°˜ìœ¼ë¡œ ê°œì„ 
- ë‚˜ë¨¸ì§€ 10ê°œ ë‹¨ê³„ëŠ” **ê·¸ëŒ€ë¡œ ìœ ì§€**
- ì „ì²´ ê¸°ëŠ¥ **ëª¨ë‘ í¬í•¨**

### Q2: patch_setup_cluster_full.shëŠ” ì–¸ì œ ì‹¤í–‰í•˜ë‚˜ìš”?

**A: ë”± í•œ ë²ˆë§Œ ì‹¤í–‰í•˜ë©´ ë©ë‹ˆë‹¤.**

```bash
./patch_setup_cluster_full.sh  # ìµœì´ˆ 1íšŒë§Œ
```

- ì‹¤í–‰í•˜ë©´ `setup_cluster_full.sh` íŒŒì¼ì´ **ìˆ˜ì •**ë¨
- Step 8ì´ YAML ê¸°ë°˜ìœ¼ë¡œ ë³€ê²½ë¨
- ë°±ì—… íŒŒì¼ ìë™ ìƒì„± (`.backup_ë‚ ì§œì‹œê°„`)

### Q3: ëª¨ë“  ê¸°ëŠ¥ì´ í¬í•¨ë˜ì–´ ìˆë‚˜ìš”?

**A: ë„¤! ëª¨ë“  ê¸°ëŠ¥ì´ ê·¸ëŒ€ë¡œ ìˆìŠµë‹ˆë‹¤.**

| ë‹¨ê³„ | ê¸°ëŠ¥ | ë³€ê²½ ì—¬ë¶€ |
|------|------|----------|
| Step 1-7 | YAMLê²€ì¦, SSHí…ŒìŠ¤íŠ¸, Munge, Slurmì„¤ì¹˜ | âœ… ë³€ê²½ ì—†ìŒ |
| **Step 8** | **ì„¤ì • íŒŒì¼ ìƒì„±** | **â­ YAML ê¸°ë°˜ìœ¼ë¡œ ê°œì„ ** |
| Step 9-12 | ì„¤ì •ë°°í¬, ì„œë¹„ìŠ¤ì‹œì‘, PATH, MPI | âœ… ë³€ê²½ ì—†ìŒ |

---

## ğŸ“Š Step 8 ê°œì„  ë‚´ìš©

### âŒ ì´ì „ (configure_slurm_cgroup_v2.sh)
```bash
# í•˜ë“œì½”ë”©
ClusterName=mini-cluster
SlurmctldHost=smarttwincluster(192.168.122.1)
NodeName=node001 NodeAddr=192.168.122.90 CPUs=2 ...
# RebootProgram ì„¤ì • ì—†ìŒ!
```

### âœ… í˜„ì¬ (configure_slurm_from_yaml.py)
```yaml
# my_cluster.yamlì—ì„œ ì½ìŒ
cluster_info:
  cluster_name: mini-cluster

slurm_config:
  reboot_program: /sbin/reboot  # â† ìë™ ë°˜ì˜!

nodes:
  compute_nodes:  # â† ë™ì  ìƒì„±!
    - hostname: node001
```

---

## ğŸš€ ì‚¬ìš© ë°©ë²•

### ë°©ë²• 1: ìƒˆë¡œìš´ í´ëŸ¬ìŠ¤í„° ì „ì²´ ì„¤ì¹˜

```bash
cd /home/koopark/claude/KooSlurmInstallAutomationRefactory

# 1. íŒ¨ì¹˜ ì ìš© (ìµœì´ˆ 1íšŒë§Œ)
./patch_setup_cluster_full.sh

# 2. ì „ì²´ ì„¤ì¹˜
./setup_cluster_full.sh

# âœ… ì™„ë£Œ! Step 8ì—ì„œ ìë™ìœ¼ë¡œ YAML ê¸°ë°˜ ì„¤ì • ì‚¬ìš©
```

### ë°©ë²• 2: ì„¤ì •ë§Œ ë³€ê²½ (ê¸°ì¡´ í´ëŸ¬ìŠ¤í„°)

```bash
# 1. YAML ìˆ˜ì •
vim my_cluster.yaml

# 2. ì„¤ì • ì¬ìƒì„±
python3 configure_slurm_from_yaml.py

# 3. ë°°í¬ ë° ì¬ì‹œì‘
./sync_config_to_nodes.sh
sudo systemctl restart slurmctld

# âœ… ì™„ë£Œ!
```

### ë°©ë²• 3: ë¹ ë¥¸ ì‹œì‘

```bash
# ì˜¬ì¸ì› ìŠ¤í¬ë¦½íŠ¸
./quickstart_yaml_config.sh
```

---

## ğŸ“ ìƒì„±ëœ íŒŒì¼ ëª©ë¡

### ì‹¤í–‰ íŒŒì¼ (10ê°œ)

1. **`configure_slurm_from_yaml.py`** â­
   - ë©”ì¸ Python ìŠ¤í¬ë¦½íŠ¸
   - YAML â†’ Slurm ì„¤ì • íŒŒì¼ ë³€í™˜
   - RebootProgram ìë™ ë°˜ì˜

2. `quickstart_yaml_config.sh`
   - ë¹ ë¥¸ ì‹œì‘ (ëŒ€í™”í˜•)

3. `setup_yaml_all_in_one.sh`
   - ì˜¬ì¸ì› ë©”ë‰´

4. `configure_slurm_cgroup_v2_YAML.sh`
   - Bash ë˜í¼

5. `patch_setup_cluster_full.sh`
   - setup_cluster_full.sh íŒ¨ì¹˜

6. `FINAL_SETUP_YAML.sh`
   - ìµœì´ˆ ì„¤ì •

7. `YAML_CONFIG_SUMMARY.sh`
   - ìš”ì•½ ì •ë³´

8. `FAQ_YAML_CONFIG.sh`
   - FAQ í‘œì‹œ

9. `SHOW_FAQ.sh`
   - FAQ + ê¶Œí•œ ë¶€ì—¬

10. `chmod_yaml_scripts.sh`
    - ê¶Œí•œ ì¼ê´„ ë¶€ì—¬

### ë¬¸ì„œ (3ê°œ)

11. `YAML_CONFIG_GUIDE.md`
    - ì™„ì „í•œ ì‚¬ìš© ê°€ì´ë“œ

12. `YAML_CONFIG_README.md`
    - ë¹ ë¥¸ ì°¸ì¡°

13. `SETUP_CLUSTER_FULL_INTEGRATION.md`
    - setup_cluster_full.sh í†µí•© ê°€ì´ë“œ

---

## ğŸ¯ YAML â†’ slurm.conf ë³€í™˜ ì˜ˆì‹œ

### Input: my_cluster.yaml
```yaml
cluster_info:
  cluster_name: mini-cluster

nodes:
  controller:
    hostname: smarttwincluster
    ip_address: 192.168.122.1
  
  compute_nodes:
    - hostname: node001
      ip_address: 192.168.122.90
      hardware:
        cpus: 2
        sockets: 1
        cores_per_socket: 2
        memory_mb: 4096

slurm_config:
  reboot_program: /sbin/reboot  # â­ í•µì‹¬!
  
  partitions:
    - name: normal
      nodes: node[001-002]
      default: true
      max_time: 7-00:00:00
```

### Output: /usr/local/slurm/etc/slurm.conf
```conf
ClusterName=mini-cluster
SlurmctldHost=smarttwincluster(192.168.122.1)

SlurmUser=slurm
SlurmdUser=root

AuthType=auth/munge
CredType=cred/munge

# â­ YAMLì—ì„œ ìë™ìœ¼ë¡œ ì½ì–´ì˜´!
RebootProgram=/sbin/reboot

SchedulerType=sched/backfill
SelectType=select/cons_tres
ProctrackType=proctrack/cgroup
TaskPlugin=task/cgroup,task/affinity

# ë…¸ë“œ ë™ì  ìƒì„±!
NodeName=node001 NodeAddr=192.168.122.90 CPUs=2 Sockets=1 CoresPerSocket=2 ThreadsPerCore=1 RealMemory=4096 State=UNKNOWN

# íŒŒí‹°ì…˜ ë™ì  ìƒì„±!
PartitionName=normal Nodes=node[001-002] Default=YES MaxTime=7-00:00:00 State=UP
```

---

## ğŸ” í™•ì¸ ë°©ë²•

```bash
# 1. RebootProgram ì„¤ì • í™•ì¸
grep "^RebootProgram" /usr/local/slurm/etc/slurm.conf
# ì¶œë ¥: RebootProgram=/sbin/reboot

# 2. scontrolë¡œ í™•ì¸
scontrol show config | grep RebootProgram
# ì¶œë ¥: RebootProgram         = /sbin/reboot

# 3. ì „ì²´ ì„¤ì • í™•ì¸
cat /usr/local/slurm/etc/slurm.conf

# 4. ë…¸ë“œ ì¬ë¶€íŒ… í…ŒìŠ¤íŠ¸
scontrol reboot node001 reason="YAML config test"
```

---

## ğŸ“‹ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: ì™„ì „íˆ ìƒˆë¡œìš´ í´ëŸ¬ìŠ¤í„° ì„¤ì¹˜

```bash
# 1. YAML ì¤€ë¹„
cp examples/2node_example.yaml my_cluster.yaml
vim my_cluster.yaml

# 2. íŒ¨ì¹˜ ì ìš© (ìµœì´ˆ 1íšŒ)
./patch_setup_cluster_full.sh

# 3. ì „ì²´ ì„¤ì¹˜
./setup_cluster_full.sh

# âœ… ì™„ë£Œ!
```

### ì‹œë‚˜ë¦¬ì˜¤ 2: RebootProgram ë³€ê²½

```yaml
# my_cluster.yaml ìˆ˜ì •
slurm_config:
  reboot_program: /usr/local/bin/custom-reboot.sh
```

```bash
# ì¬ìƒì„± ë° ë°°í¬
python3 configure_slurm_from_yaml.py
./sync_config_to_nodes.sh
sudo systemctl restart slurmctld

# í™•ì¸
grep RebootProgram /usr/local/slurm/etc/slurm.conf
```

### ì‹œë‚˜ë¦¬ì˜¤ 3: ë…¸ë“œ ì¶”ê°€

```yaml
# my_cluster.yamlì— ë…¸ë“œ ì¶”ê°€
nodes:
  compute_nodes:
    - hostname: node003
      ip_address: 192.168.122.104
      hardware:
        cpus: 4
        memory_mb: 8192
```

```bash
# 1. ìƒˆ ë…¸ë“œì— Slurm ì„¤ì¹˜
scp install_slurm_cgroup_v2.sh koopark@192.168.122.104:/tmp/
ssh koopark@192.168.122.104 'sudo bash /tmp/install_slurm_cgroup_v2.sh'

# 2. ì„¤ì • ì¬ìƒì„±
python3 configure_slurm_from_yaml.py

# 3. ë°°í¬ ë° ì¬ì‹œì‘
./sync_config_to_nodes.sh
sudo systemctl restart slurmctld
ssh node003 'sudo systemctl restart slurmd'

# âœ… ì™„ë£Œ!
```

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì´ˆê¸° ì„¤ì •
- [ ] `my_cluster.yaml` ì¤€ë¹„
- [ ] `reboot_program` ì„¤ì • í™•ì¸
- [ ] `./patch_setup_cluster_full.sh` ì‹¤í–‰ (ìµœì´ˆ 1íšŒ)
- [ ] `./setup_cluster_full.sh` ì‹¤í–‰
- [ ] `grep RebootProgram /usr/local/slurm/etc/slurm.conf` í™•ì¸

### ì„¤ì • ë³€ê²½ ì‹œ
- [ ] `my_cluster.yaml` ìˆ˜ì •
- [ ] `python3 configure_slurm_from_yaml.py` ì‹¤í–‰
- [ ] `./sync_config_to_nodes.sh` ì‹¤í–‰
- [ ] Slurm ì¬ì‹œì‘
- [ ] `scontrol show config | grep RebootProgram` í™•ì¸

---

## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### Q: YAML íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ë‹¤ëŠ” ì˜¤ë¥˜
```bash
cp examples/2node_example.yaml my_cluster.yaml
vim my_cluster.yaml
```

### Q: Permission denied ì˜¤ë¥˜
```bash
sudo python3 configure_slurm_from_yaml.py
```

### Q: RebootProgramì´ ë°˜ì˜ë˜ì§€ ì•ŠìŒ
```bash
# YAML í™•ì¸
grep reboot_program my_cluster.yaml

# ì—†ìœ¼ë©´ ì¶”ê°€
vim my_cluster.yaml
# slurm_config:
#   reboot_program: /sbin/reboot

# ì¬ìƒì„±
python3 configure_slurm_from_yaml.py
```

---

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

- **ì™„ì „í•œ ê°€ì´ë“œ**: `YAML_CONFIG_GUIDE.md`
- **ë¹ ë¥¸ ì°¸ì¡°**: `YAML_CONFIG_README.md`
- **í†µí•© ê°€ì´ë“œ**: `SETUP_CLUSTER_FULL_INTEGRATION.md`
- **FAQ**: `./FAQ_YAML_CONFIG.sh`

---

## ğŸ¯ í•µì‹¬ ì •ë¦¬

1. âœ… `setup_cluster_full.sh`ëŠ” **ì—¬ì „íˆ ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸**
2. âœ… **Step 8ë§Œ** YAML ê¸°ë°˜ìœ¼ë¡œ ê°œì„ 
3. âœ… `./patch_setup_cluster_full.sh` **í•œ ë²ˆë§Œ** ì‹¤í–‰
4. âœ… `RebootProgram` ìë™ ë°˜ì˜
5. âœ… YAMLë§Œ ìˆ˜ì •í•˜ë©´ **ëª¨ë“  ì„¤ì • ìë™**

---

## ğŸš€ ì§€ê¸ˆ ë°”ë¡œ ì‹œì‘!

```bash
cd /home/koopark/claude/KooSlurmInstallAutomationRefactory

# FAQ ë° ì‚¬ìš©ë²• ë³´ê¸°
chmod +x SHOW_FAQ.sh
./SHOW_FAQ.sh

# ë˜ëŠ” ë¹ ë¥¸ ì‹œì‘
chmod +x quickstart_yaml_config.sh
./quickstart_yaml_config.sh
```

---

**ì‘ì„±ì¼**: 2025-10-11  
**ìœ„ì¹˜**: `/home/koopark/claude/KooSlurmInstallAutomationRefactory/`  
**ë¬¸ì˜**: ì´ ë¬¸ì„œ ë˜ëŠ” `YAML_CONFIG_GUIDE.md` ì°¸ì¡°
