# Hybrid HA ì•„í‚¤í…ì²˜: Slurm ì´ì¤‘í™” + ì›¹ì„œë¹„ìŠ¤ Nì¤‘í™” ìë™ ìŠ¤ì¼€ì¼ë§

## ğŸ“‹ ì „ëµ ê°œìš”

### âœ… ì™œ ì´ êµ¬ì„±ì´ í•©ë¦¬ì ì¸ê°€?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HPC í´ëŸ¬ìŠ¤í„°ì—ì„œ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” HA ì „ëµ                 â”‚
â”‚                                                               â”‚
â”‚  â€¢ Slurm: Active-Standby (ì´ì¤‘í™”)                            â”‚
â”‚    â†’ ìƒíƒœ ì €ì¥(Stateful), ë‹¨ì¼ ì œì–´ì  í•„ìš”                    â”‚
â”‚                                                               â”‚
â”‚  â€¢ ì›¹ì„œë¹„ìŠ¤: Active-Active Nì¤‘í™” (ìë™ ìŠ¤ì¼€ì¼ë§)              â”‚
â”‚    â†’ ìƒíƒœ ë¹„ì €ì¥(Stateless), ìˆ˜í‰ í™•ì¥ ê°€ëŠ¥                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**í•µì‹¬ ì´ìœ **:
1. **Slurmì€ ë¶„ì‚° ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì•„ë‹˜** â†’ ë‹¨ì¼ ì»¨íŠ¸ë¡¤ëŸ¬ê°€ í´ëŸ¬ìŠ¤í„° ì „ì²´ë¥¼ ê´€ë¦¬
2. **ì›¹ì„œë¹„ìŠ¤ëŠ” ì´ë¯¸ Stateless** â†’ Redis/DBë§Œ ê³µìœ í•˜ë©´ ë¬´í•œ í™•ì¥ ê°€ëŠ¥
3. **ë¶€í•˜ íŒ¨í„´ì´ ë‹¤ë¦„** â†’ Slurmì€ ì•ˆì •ì , ì›¹ì„œë¹„ìŠ¤ëŠ” ì‚¬ìš©ì ìˆ˜ì— ë”°ë¼ ë³€ë™

---

## ğŸ—ï¸ ì•„í‚¤í…ì²˜ ì„¤ê³„

### 1ï¸âƒ£ Slurm ì´ì¤‘í™” (Active-Standby)

```
                  VIP (192.168.1.100)
                         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                               â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Slurm   â”‚ ACTIVE             â”‚ Slurm   â”‚ STANDBY
    â”‚ Master1 â”‚â—„â”€â”€â”€â”€â”€â”€heartbeatâ”€â”€â”€â”€â–ºâ”‚ Master2 â”‚
    â”‚ Node    â”‚                    â”‚ Node    â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â”€ slurmctld (ìŠ¤ì¼€ì¤„ëŸ¬)
         â”œâ”€â”€â”€ slurmdbd (DB ë°ëª¬)
         â””â”€â”€â”€ ê³µìœ  ìŠ¤í† ë¦¬ì§€ (/etc/slurm, /var/spool/slurmd)
```

**êµ¬ì„± ìš”ì†Œ**:
- **VIP (Virtual IP)**: Keepalivedë¡œ ê´€ë¦¬
- **Heartbeat**: Pacemaker/Corosync ë˜ëŠ” Keepalived
- **ê³µìœ  ìŠ¤í† ë¦¬ì§€**: NFS ë˜ëŠ” DRBD (ì„¤ì • íŒŒì¼, ì‘ì—… í ë™ê¸°í™”)
- **ìë™ ì „í™˜**: Master1 ì‹¤íŒ¨ ì‹œ Master2ê°€ VIP ì¸ìˆ˜ ë° slurmctld ì‹œì‘

**ì™œ ì´ì¤‘í™”ë§Œ?**
- Slurmì€ **ë‹¨ì¼ ì œì–´ì ** ì•„í‚¤í…ì²˜ (Split-brain ë°©ì§€ í•„ìš”)
- 3ì¤‘í™” ì´ìƒì€ **ë³µì¡ë„ë§Œ ì¦ê°€**, ì‹¤ì§ˆì  ì´ì  ì—†ìŒ
- ê³„ì‚° ë…¸ë“œ(compute node)ëŠ” Nê°œ â†’ ì‹¤ì œ ì‘ì—…ì€ ë¶„ì‚°ë¨

---

### 2ï¸âƒ£ ì›¹ì„œë¹„ìŠ¤ Nì¤‘í™” (Auto-Scaling)

```
                    ì¸í„°ë„· / ì‚¬ìš©ì
                         â”‚
                    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
                    â”‚ HAProxy â”‚ (VIP: 192.168.1.101)
                    â”‚  LB     â”‚
                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚               â”‚               â”‚               â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚  Web1   â”‚     â”‚  Web2   â”‚     â”‚  Web3   â”‚ ... â”‚  WebN   â”‚
    â”‚ 4430/31 â”‚     â”‚ 4430/31 â”‚     â”‚ 4430/31 â”‚     â”‚ 4430/31 â”‚
    â”‚ 5010/11 â”‚     â”‚ 5010/11 â”‚     â”‚ 5010/11 â”‚     â”‚ 5010/11 â”‚
    â”‚ 5000/01 â”‚     â”‚ 5000/01 â”‚     â”‚ 5000/01 â”‚     â”‚ 5000/01 â”‚
    â”‚ 5173/74 â”‚     â”‚ 5173/74 â”‚     â”‚ 5173/74 â”‚     â”‚ 5173/74 â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚               â”‚               â”‚               â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Redis Sentinel  â”‚ (ì„¸ì…˜, JWT í† í°)
                    â”‚ 3 Master Nodes  â”‚
                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ MariaDB Galera  â”‚ (ì„¤ì •, ì‚¬ìš©ì ë°ì´í„°)
                    â”‚ 3 Master Nodes  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ìë™ ìŠ¤ì¼€ì¼ë§ ë©”ì»¤ë‹ˆì¦˜**:

#### ë°©ë²• 1: ê°„ë‹¨í•œ ìŠ¤í¬ë¦½íŠ¸ ê¸°ë°˜ (ì¶”ì²œ)
```bash
#!/bin/bash
# auto_scale_web.sh

HAPROXY_STATS="http://192.168.1.101:8404/stats"
CPU_THRESHOLD=70
CONNECTIONS_THRESHOLD=1000

# í˜„ì¬ ë¶€í•˜ ì²´í¬
CURRENT_CPU=$(get_avg_cpu_from_haproxy)
CURRENT_CONN=$(get_active_connections)

if [ $CURRENT_CPU -gt $CPU_THRESHOLD ] || [ $CURRENT_CONN -gt $CONNECTIONS_THRESHOLD ]; then
    # ìƒˆ ì›¹ì„œë²„ ì¶”ê°€
    NEW_SERVER_ID=$((LAST_SERVER_ID + 1))

    # 1. VM ë˜ëŠ” ì»¨í…Œì´ë„ˆ ì‹œì‘
    virsh start web-node-$NEW_SERVER_ID

    # 2. ì›¹ì„œë¹„ìŠ¤ ìë™ ë°°í¬ (Ansible)
    ansible-playbook -i inventory deploy_web_services.yml --limit web-node-$NEW_SERVER_ID

    # 3. HAProxyì— ë“±ë¡
    echo "server web$NEW_SERVER_ID 192.168.1.$NEW_SERVER_ID:4430 check" | \
        socat stdio /var/run/haproxy.sock

    echo "âœ… ì›¹ì„œë²„ $NEW_SERVER_ID ì¶”ê°€ë¨"
fi
```

#### ë°©ë²• 2: Kubernetes + HPA (ê³ ê¸‰)
```yaml
# web-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: auth-portal
spec:
  replicas: 2  # ìµœì†Œ 2ê°œ
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: auth-portal-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: auth-portal
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

---

## ğŸ”§ êµ¬í˜„ ë°©ë²•

### Phase 1: Slurm ì´ì¤‘í™” (1-2ì£¼)

#### í•„ìš”í•œ í•˜ë“œì›¨ì–´
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ì—­í•             â”‚ í˜¸ìŠ¤íŠ¸ëª…  â”‚ IP       â”‚ ì‚¬ì–‘         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Slurm Master 1 â”‚ slurm-m1 â”‚ .1.10    â”‚ 8C/32GB     â”‚
â”‚ Slurm Master 2 â”‚ slurm-m2 â”‚ .1.11    â”‚ 8C/32GB     â”‚
â”‚ NFS Storage    â”‚ nfs-srv  â”‚ .1.12    â”‚ 4C/16GB+RAIDâ”‚
â”‚ VIP            â”‚ (ê°€ìƒ)   â”‚ .1.100   â”‚ -           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ë‹¨ê³„ë³„ ì‘ì—…

**1. Keepalived ì„¤ì • (VIP ê´€ë¦¬)**

`/etc/keepalived/keepalived.conf` (Master1):
```bash
vrrp_script check_slurmctld {
    script "/usr/local/bin/check_slurm_health.sh"
    interval 2
    weight -20
}

vrrp_instance SLURM_HA {
    state MASTER
    interface ens18
    virtual_router_id 51
    priority 100
    advert_int 1

    authentication {
        auth_type PASS
        auth_pass slurm_vip_secret
    }

    virtual_ipaddress {
        192.168.1.100/24
    }

    track_script {
        check_slurmctld
    }
}
```

**2. NFS ê³µìœ  ìŠ¤í† ë¦¬ì§€ ì„¤ì •**

NFS ì„œë²„:
```bash
# /etc/exports
/slurm_shared  192.168.1.0/24(rw,sync,no_root_squash)

# ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p /slurm_shared/{config,spool,logs}
exportfs -arv
```

Master ë…¸ë“œë“¤:
```bash
# /etc/fstab
nfs-srv:/slurm_shared  /mnt/slurm  nfs  defaults,_netdev  0 0

# Slurm ì‹¬ë³¼ë¦­ ë§í¬
ln -s /mnt/slurm/config /etc/slurm
ln -s /mnt/slurm/spool /var/spool/slurmd
ln -s /mnt/slurm/logs /var/log/slurm
```

**3. Slurm ì„¤ì • íŒŒì¼ ìˆ˜ì •**

`/etc/slurm/slurm.conf`:
```bash
# HA ì„¤ì •
SlurmctldHost=slurm-m1(192.168.1.10)   # Primary
SlurmctldHost=slurm-m2(192.168.1.11)   # Backup

# ê³µìœ  ìƒíƒœ ë””ë ‰í† ë¦¬
StateSaveLocation=/mnt/slurm/spool
SlurmdSpoolDir=/mnt/slurm/spool/slurmd

# ë¹ ë¥¸ ì „í™˜ì„ ìœ„í•œ íƒ€ì„ì•„ì›ƒ
SlurmctldTimeout=300
SlurmdTimeout=300
```

**4. ìë™ ì „í™˜ í…ŒìŠ¤íŠ¸**

```bash
# Master1ì—ì„œ slurmctld ì¤‘ì§€
systemctl stop slurmctld

# VIPê°€ Master2ë¡œ ì´ë™í•˜ëŠ”ì§€ í™•ì¸ (2ì´ˆ ì´ë‚´)
watch -n 1 'ip addr show | grep 192.168.1.100'

# Master2ì—ì„œ slurmctldê°€ ìë™ ì‹œì‘ë˜ëŠ”ì§€ í™•ì¸
systemctl status slurmctld

# í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì‘ì—… ì œì¶œì´ ê³„ì† ê°€ëŠ¥í•œì§€ í™•ì¸
sbatch test_job.sh
```

---

### Phase 2: ì›¹ì„œë¹„ìŠ¤ ìë™ ìŠ¤ì¼€ì¼ë§ (2-3ì£¼)

#### ë°©ë²• A: ìŠ¤í¬ë¦½íŠ¸ ê¸°ë°˜ (ê°„ë‹¨, ì¶”ì²œ)

**1. HAProxy ì„¤ì • (ë™ì  ì„œë²„ ì¶”ê°€ ì§€ì›)**

`/etc/haproxy/haproxy.cfg`:
```bash
# Runtime API í™œì„±í™”
stats socket /var/run/haproxy.sock mode 600 level admin
stats timeout 2m

# Frontend
frontend web_https
    bind *:443 ssl crt /etc/ssl/certs/hpc-portal.pem
    mode http

    # ì„œë¹„ìŠ¤ë³„ ë¼ìš°íŒ…
    acl is_auth path_beg /auth
    acl is_dashboard path_beg /dashboard
    acl is_cae path_beg /cae
    acl is_vnc path_beg /vnc
    acl is_app path_beg /app

    use_backend auth_backend if is_auth
    use_backend dashboard_backend if is_dashboard
    use_backend cae_backend if is_cae
    use_backend vnc_backend if is_vnc
    use_backend app_backend if is_app

# Backend - ë™ì  ì„œë²„ ì¶”ê°€ ê°€ëŠ¥
backend auth_backend
    mode http
    balance roundrobin
    option httpchk GET /health

    # ì´ˆê¸° ì„œë²„ (ìµœì†Œ 2ëŒ€)
    server web1 192.168.1.21:4430 check
    server web2 192.168.1.22:4430 check
    # ì´í›„ Runtime APIë¡œ ë™ì  ì¶”ê°€

backend dashboard_backend
    mode http
    balance leastconn
    option httpchk GET /health

    server web1 192.168.1.21:5010 check
    server web2 192.168.1.22:5010 check
```

**2. ìë™ ìŠ¤ì¼€ì¼ë§ ìŠ¤í¬ë¦½íŠ¸**

`/usr/local/bin/auto_scale_web.sh`:
```bash
#!/bin/bash
# ì›¹ì„œë¹„ìŠ¤ ìë™ ìŠ¤ì¼€ì¼ë§ ìŠ¤í¬ë¦½íŠ¸

CONFIG_FILE="/etc/auto-scale/web-scale.conf"
HAPROXY_SOCK="/var/run/haproxy.sock"
LOG_FILE="/var/log/auto-scale.log"

# ì„¤ì • ë¡œë“œ
source $CONFIG_FILE

# í˜„ì¬ ìƒíƒœ ì²´í¬
get_current_metrics() {
    # HAProxy í†µê³„ì—ì„œ í˜„ì¬ ì—°ê²° ìˆ˜, í ê¸¸ì´ ê°€ì ¸ì˜¤ê¸°
    echo "show stat" | socat stdio $HAPROXY_SOCK | \
        awk -F',' '/auth_backend/{print $5,$8,$34}'
}

# ìŠ¤ì¼€ì¼ ì•„ì›ƒ íŒë‹¨
should_scale_out() {
    local current_conn=$1
    local queue_len=$2

    if [ $current_conn -gt $MAX_CONNECTIONS_PER_SERVER ] || \
       [ $queue_len -gt $MAX_QUEUE_LENGTH ]; then
        return 0
    fi
    return 1
}

# ìŠ¤ì¼€ì¼ ì¸ íŒë‹¨
should_scale_in() {
    local avg_conn=$1
    local server_count=$2

    if [ $avg_conn -lt $MIN_CONNECTIONS_PER_SERVER ] && \
       [ $server_count -gt $MIN_SERVERS ]; then
        return 0
    fi
    return 1
}

# ìƒˆ ì›¹ì„œë²„ ì¶”ê°€
add_web_server() {
    local new_id=$(get_next_server_id)
    local new_ip="192.168.1.$((20 + new_id))"

    log "INFO" "ìƒˆ ì›¹ì„œë²„ ì¶”ê°€ ì‹œì‘: web$new_id ($new_ip)"

    # 1. VM ì‹œì‘
    virsh start web-node-$new_id || {
        log "ERROR" "VM ì‹œì‘ ì‹¤íŒ¨: web-node-$new_id"
        return 1
    }

    # 2. VMì´ ë¶€íŒ…ë  ë•Œê¹Œì§€ ëŒ€ê¸° (SSH ì ‘ì† ê°€ëŠ¥í•  ë•Œê¹Œì§€)
    wait_for_ssh $new_ip 60 || {
        log "ERROR" "VM ë¶€íŒ… íƒ€ì„ì•„ì›ƒ: $new_ip"
        return 1
    }

    # 3. Ansibleë¡œ ì›¹ì„œë¹„ìŠ¤ ë°°í¬
    ansible-playbook -i inventory.yml deploy_web_services.yml \
        --limit web-node-$new_id || {
        log "ERROR" "ì›¹ì„œë¹„ìŠ¤ ë°°í¬ ì‹¤íŒ¨: web-node-$new_id"
        return 1
    }

    # 4. HAProxyì— ë“±ë¡
    for port in 4430 5010 5000 5173; do
        backend=$(get_backend_name_for_port $port)
        echo "add server $backend/web$new_id $new_ip:$port check" | \
            socat stdio $HAPROXY_SOCK
    done

    log "INFO" "ì›¹ì„œë²„ ì¶”ê°€ ì™„ë£Œ: web$new_id ($new_ip)"
    return 0
}

# ì›¹ì„œë²„ ì œê±°
remove_web_server() {
    local server_id=$1

    log "INFO" "ì›¹ì„œë²„ ì œê±° ì‹œì‘: web$server_id"

    # 1. HAProxyì—ì„œ drain ëª¨ë“œ ì„¤ì • (ìƒˆ ì—°ê²° ì°¨ë‹¨)
    for backend in auth_backend dashboard_backend cae_backend vnc_backend app_backend; do
        echo "set server $backend/web$server_id state drain" | \
            socat stdio $HAPROXY_SOCK
    done

    # 2. ê¸°ì¡´ ì—°ê²° ì¢…ë£Œ ëŒ€ê¸° (ìµœëŒ€ 5ë¶„)
    wait_for_connections_drain web$server_id 300

    # 3. HAProxyì—ì„œ ì œê±°
    for backend in auth_backend dashboard_backend cae_backend vnc_backend app_backend; do
        echo "del server $backend/web$server_id" | \
            socat stdio $HAPROXY_SOCK
    done

    # 4. VM ì¢…ë£Œ
    virsh shutdown web-node-$server_id

    log "INFO" "ì›¹ì„œë²„ ì œê±° ì™„ë£Œ: web$server_id"
}

# ë©”ì¸ ë£¨í”„
main() {
    while true; do
        metrics=$(get_current_metrics)
        current_conn=$(echo $metrics | awk '{print $1}')
        queue_len=$(echo $metrics | awk '{print $2}')
        server_count=$(get_active_server_count)

        if should_scale_out $current_conn $queue_len; then
            if [ $server_count -lt $MAX_SERVERS ]; then
                add_web_server
            else
                log "WARN" "ìµœëŒ€ ì„œë²„ ìˆ˜($MAX_SERVERS) ë„ë‹¬, ìŠ¤ì¼€ì¼ ì•„ì›ƒ ë¶ˆê°€"
            fi
        elif should_scale_in $((current_conn / server_count)) $server_count; then
            oldest_server=$(get_oldest_server_id)
            remove_web_server $oldest_server
        fi

        # ì²´í¬ ì£¼ê¸° (ê¸°ë³¸ 30ì´ˆ)
        sleep ${CHECK_INTERVAL:-30}
    done
}

main "$@"
```

**3. ì„¤ì • íŒŒì¼**

`/etc/auto-scale/web-scale.conf`:
```bash
# ìŠ¤ì¼€ì¼ë§ ì„ê³„ê°’
MAX_CONNECTIONS_PER_SERVER=500
MIN_CONNECTIONS_PER_SERVER=50
MAX_QUEUE_LENGTH=20

# ì„œë²„ ê°œìˆ˜ ì œí•œ
MIN_SERVERS=2
MAX_SERVERS=10

# ì²´í¬ ê°„ê²© (ì´ˆ)
CHECK_INTERVAL=30

# VM í…œí”Œë¦¿
VM_TEMPLATE="web-node-template"
NETWORK_BRIDGE="br0"
```

**4. Ansible í”Œë ˆì´ë¶ (ì›¹ì„œë¹„ìŠ¤ ìë™ ë°°í¬)**

`deploy_web_services.yml`:
```yaml
---
- name: Deploy HPC Web Services
  hosts: web_nodes
  become: yes
  vars:
    dashboard_path: /opt/hpc-dashboard
    services:
      - { name: "auth_portal_4430", port: 4430 }
      - { name: "auth_frontend_4431", port: 4431 }
      - { name: "backend_5010", port: 5010 }
      - { name: "websocket_5011", port: 5011 }
      - { name: "kooCAEWebServer_5000", port: 5000 }
      - { name: "kooCAEWebAutomationServer_5001", port: 5001 }
      - { name: "dashboard_5173", port: 5173 }
      - { name: "app_5174", port: 5174 }

  tasks:
    - name: Git clone dashboard repository
      git:
        repo: https://github.com/your-org/hpc-dashboard.git
        dest: "{{ dashboard_path }}"
        version: main

    - name: Install Python dependencies
      pip:
        requirements: "{{ dashboard_path }}/{{ item.name }}/requirements.txt"
        virtualenv: "{{ dashboard_path }}/{{ item.name }}/venv"
      loop: "{{ services }}"
      when: "'backend' in item.name or 'Server' in item.name or 'portal' in item.name"

    - name: Install Node.js dependencies and build
      shell: |
        cd {{ dashboard_path }}/{{ item.name }}
        npm install
        npm run build
      loop: "{{ services }}"
      when: "'frontend' in item.name or 'dashboard' in item.name or 'app' in item.name"

    - name: Create systemd services
      template:
        src: templates/service.j2
        dest: /etc/systemd/system/{{ item.name }}.service
      loop: "{{ services }}"

    - name: Enable and start services
      systemd:
        name: "{{ item.name }}"
        enabled: yes
        state: started
        daemon_reload: yes
      loop: "{{ services }}"

    - name: Configure environment variables
      template:
        src: templates/env.j2
        dest: "{{ dashboard_path }}/{{ item.name }}/.env"
      loop: "{{ services }}"
      vars:
        redis_host: "{{ redis_sentinel_vip }}"
        redis_port: 6379
        db_host: "{{ mariadb_galera_vip }}"
        db_port: 3306
```

**5. Systemd ì„œë¹„ìŠ¤ë¡œ ìë™ ìŠ¤ì¼€ì¼ë§ ì‹¤í–‰**

`/etc/systemd/system/web-autoscale.service`:
```ini
[Unit]
Description=Web Services Auto-Scaling
After=network.target haproxy.service

[Service]
Type=simple
ExecStart=/usr/local/bin/auto_scale_web.sh
Restart=always
RestartSec=10
User=root

[Install]
WantedBy=multi-user.target
```

```bash
systemctl enable web-autoscale
systemctl start web-autoscale
```

---

#### ë°©ë²• B: Kubernetes ê¸°ë°˜ (ê³ ê¸‰, ê¶Œì¥í•˜ì§€ ì•ŠìŒ)

**ì™œ ì¶”ì²œí•˜ì§€ ì•ŠëŠ”ê°€?**
- Slurmê³¼ Kubernetes ëª¨ë‘ ë¦¬ì†ŒìŠ¤ ìŠ¤ì¼€ì¤„ëŸ¬ â†’ **ì¶©ëŒ ê°€ëŠ¥**
- HPC í´ëŸ¬ìŠ¤í„°ëŠ” ë³´í†µ ë² ì–´ë©”íƒˆ â†’ K8s ì˜¤ë²„í—¤ë“œ ë¶ˆí•„ìš”
- ë³µì¡ë„ë§Œ ì¦ê°€, ì‹¤ì§ˆì  ì´ì  ì ìŒ

**ë§Œì•½ ë„ì…í•œë‹¤ë©´**:
```yaml
# ì›¹ì„œë¹„ìŠ¤ë§Œ K8së¡œ ê´€ë¦¬ (Slurmì€ ë³„ë„)
# StatefulSetì´ ì•„ë‹Œ Deployment ì‚¬ìš© (Stateless)

apiVersion: apps/v1
kind: Deployment
metadata:
  name: auth-portal
spec:
  replicas: 2
  selector:
    matchLabels:
      app: auth-portal
  template:
    metadata:
      labels:
        app: auth-portal
    spec:
      containers:
      - name: backend
        image: hpc-dashboard/auth-portal-backend:latest
        ports:
        - containerPort: 4430
        env:
        - name: REDIS_HOST
          value: "redis-sentinel-service"
        - name: DB_HOST
          value: "mariadb-galera-service"
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: auth-portal-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: auth-portal
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
```

---

## ğŸ“Š ìë™í™” ë‚œì´ë„ í‰ê°€

| êµ¬ì„± ìš”ì†Œ | ë‚œì´ë„ | ì‹œê°„ | ì´ìœ  |
|----------|-------|------|------|
| **Slurm ì´ì¤‘í™”** | â­â­â­ ì¤‘ê°„ | 1-2ì£¼ | Keepalived, NFS ì„¤ì •ì€ í‘œì¤€ ì ˆì°¨ |
| **Redis Sentinel** | â­â­ ì‰¬ì›€ | 3-5ì¼ | ì´ë¯¸ êµ¬í˜„ ê°€ì´ë“œ ìˆìŒ ([HA_MINIMAL_CHANGES.md](HA_MINIMAL_CHANGES.md)) |
| **MariaDB Galera** | â­â­â­ ì¤‘ê°„ | 1ì£¼ | ì´ˆê¸° ì„¤ì • í›„ ìë™ ë™ê¸°í™” |
| **HAProxy + Keepalived** | â­â­ ì‰¬ì›€ | 3-5ì¼ | ì„¤ì • íŒŒì¼ ê¸°ë°˜, ë³µì¡ë„ ë‚®ìŒ |
| **ìŠ¤í¬ë¦½íŠ¸ ê¸°ë°˜ Auto-Scale** | â­â­â­ ì¤‘ê°„ | 1-2ì£¼ | Bash + Ansible, í…ŒìŠ¤íŠ¸ í•„ìš” |
| **K8s ê¸°ë°˜ Auto-Scale** | â­â­â­â­â­ ë§¤ìš° ì–´ë ¤ì›€ | 1-2ê°œì›” | ì „ì²´ ì¬ì„¤ê³„ í•„ìš”, ê¶Œì¥ ì•ˆ í•¨ |

**ì´ ì˜ˆìƒ ì‹œê°„ (ìŠ¤í¬ë¦½íŠ¸ ê¸°ë°˜)**: **4-6ì£¼**

---

## âœ… ì¥ì 

### 1. Slurm ì´ì¤‘í™”
âœ… **ì•ˆì •ì„±**: Master ë…¸ë“œ ì¥ì•  ì‹œ 2ì´ˆ ì´ë‚´ ìë™ ì „í™˜
âœ… **ë‹¨ìˆœì„±**: Active-StandbyëŠ” ê²€ì¦ëœ HA ë°©ì‹
âœ… **ë¹„ìš© íš¨ìœ¨**: ì„œë²„ 2ëŒ€ë¡œ ì¶©ë¶„ (3ì¤‘í™”ëŠ” ë¶ˆí•„ìš”)

### 2. ì›¹ì„œë¹„ìŠ¤ Nì¤‘í™”
âœ… **íƒ„ë ¥ì„±**: ì‚¬ìš©ì ìˆ˜ì— ë”°ë¼ ìë™ í™•ì¥/ì¶•ì†Œ
âœ… **ë¹„ìš© ì ˆê°**: í”¼í¬ ì‹œê°„ëŒ€ë§Œ ì„œë²„ ì¦ì„¤, í‰ì†ŒëŠ” ìµœì†Œ ìš´ì˜
âœ… **ë¬´ì¤‘ë‹¨ ë°°í¬**: í•œ ëŒ€ì”© ì—…ë°ì´íŠ¸í•˜ë©° ì„œë¹„ìŠ¤ ìœ ì§€
âœ… **ë¶€í•˜ ë¶„ì‚°**: HAProxyê°€ ìë™ìœ¼ë¡œ ìµœì  ì„œë²„ ì„ íƒ

### 3. í†µí•© ì´ì 
âœ… **ì—­í•  ë¶„ë¦¬**: Slurm(ê³„ì‚°)ê³¼ ì›¹(UI)ì˜ ì¥ì• ê°€ ì„œë¡œ ì˜í–¥ ì•ˆ ì¤Œ
âœ… **í™•ì¥ì„±**: ì›¹ì„œë²„ë§Œ ì¶”ê°€í•˜ë©´ ë” ë§ì€ ì‚¬ìš©ì ìˆ˜ìš©
âœ… **ëª¨ë‹ˆí„°ë§**: Prometheusë¡œ ì–‘ìª½ ëª¨ë‘ í†µí•© ëª¨ë‹ˆí„°ë§

---

## âš ï¸ ì£¼ì˜ì‚¬í•­

### 1. Slurm ì´ì¤‘í™”
âš ï¸ **Split-brain ë°©ì§€ í•„ìˆ˜**: Keepalived VRRP + fencing ì„¤ì •
âš ï¸ **ê³µìœ  ìŠ¤í† ë¦¬ì§€ í•„ìˆ˜**: NFS ë˜ëŠ” DRBD ì—†ìœ¼ë©´ ì‘ë™ ì•ˆ í•¨
âš ï¸ **ë„¤íŠ¸ì›Œí¬ ì•ˆì •ì„±**: Master ê°„ heartbeat ëŠê¸°ë©´ ë¬¸ì œ ë°œìƒ

### 2. ì›¹ì„œë¹„ìŠ¤ ìë™ ìŠ¤ì¼€ì¼ë§
âš ï¸ **Redis/DB HA ì„ í–‰**: ì›¹ì„œë²„ë§Œ ëŠ˜ë ¤ë„ DBê°€ SPOFë©´ ì˜ë¯¸ ì—†ìŒ
âš ï¸ **VM í…œí”Œë¦¿ ê´€ë¦¬**: ì›¹ì„œë²„ ì´ë¯¸ì§€ í•­ìƒ ìµœì‹ ìœ¼ë¡œ ìœ ì§€
âš ï¸ **ìŠ¤ì¼€ì¼ë§ ì†ë„**: VM ë¶€íŒ… ì‹œê°„ ê³ ë ¤ (30ì´ˆ~2ë¶„)
âš ï¸ **ë¼ì´ì„ ìŠ¤ í™•ì¸**: ìƒìš© SW ìˆìœ¼ë©´ ì„œë²„ ìˆ˜ë§Œí¼ í•„ìš”

### 3. ëª¨ë‹ˆí„°ë§
âš ï¸ **ì•Œë¦¼ ì„¤ì •**: ìë™ ìŠ¤ì¼€ì¼ë§ ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ ì•Œë¦¼ í•„ìš”
âš ï¸ **ë¡œê·¸ ì¤‘ì•™í™”**: ì„œë²„ NëŒ€ â†’ ë¡œê·¸ ìˆ˜ì§‘ ì‹œìŠ¤í…œ í•„ìˆ˜

---

## ğŸš€ êµ¬í˜„ ë¡œë“œë§µ

### Week 1-2: Slurm ì´ì¤‘í™”
- [ ] NFS ì„œë²„ êµ¬ì¶• ë° ê³µìœ  ë””ë ‰í† ë¦¬ ì„¤ì •
- [ ] Keepalived ì„¤ì • ë° VIP í…ŒìŠ¤íŠ¸
- [ ] Slurm Master 2ëŒ€ ì„¤ì • (Primary/Backup)
- [ ] ìë™ ì „í™˜ í…ŒìŠ¤íŠ¸ (Master1 ì¤‘ì§€ â†’ Master2 ìë™ ì‹œì‘)
- [ ] ê³„ì‚° ë…¸ë“œë“¤ì´ VIPë¡œ ì ‘ì†í•˜ë„ë¡ ì„¤ì • ë³€ê²½

### Week 3: Redis + MariaDB HA
- [ ] Redis Sentinel 3ë…¸ë“œ êµ¬ì„±
- [ ] MariaDB Galera Cluster 3ë…¸ë“œ êµ¬ì„±
- [ ] ì›¹ì„œë¹„ìŠ¤ë“¤ DB ì—°ê²° í™˜ê²½ë³€ìˆ˜ë¡œ ë³€ê²½
- [ ] ì¥ì•  í…ŒìŠ¤íŠ¸ (ë…¸ë“œ 1ê°œ ì¤‘ì§€í•´ë„ ì„œë¹„ìŠ¤ ì •ìƒ)

### Week 4: HAProxy + ê¸°ë³¸ ì›¹ì„œë²„ 2ëŒ€
- [ ] HAProxy ì„¤ì¹˜ ë° ì„¤ì •
- [ ] ì›¹ì„œë²„ 2ëŒ€ êµ¬ì„± (ìµœì†Œ êµ¬ì„±)
- [ ] Health Check ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
- [ ] SSL ì¸ì¦ì„œ ì„¤ì •

### Week 5-6: ìë™ ìŠ¤ì¼€ì¼ë§ êµ¬í˜„
- [ ] VM í…œí”Œë¦¿ ìƒì„± (ì›¹ì„œë¹„ìŠ¤ All-in-One)
- [ ] Ansible í”Œë ˆì´ë¶ ì‘ì„±
- [ ] ìë™ ìŠ¤ì¼€ì¼ë§ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
- [ ] ë¶€í•˜ í…ŒìŠ¤íŠ¸ (Apache Bench, Locust ë“±)
- [ ] ì•Œë¦¼ ì‹œìŠ¤í…œ ì—°ë™ (Slack, Email)

---

## ğŸ“ˆ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

### 1. Slurm ì¥ì•  ì „í™˜ í…ŒìŠ¤íŠ¸
```bash
# Master1ì—ì„œ ì‹¤í–‰
systemctl stop slurmctld

# ì˜ˆìƒ ê²°ê³¼:
# - 2ì´ˆ ì´ë‚´ VIPê°€ Master2ë¡œ ì´ë™
# - Master2ì—ì„œ slurmctld ìë™ ì‹œì‘
# - squeue, sbatch ëª…ë ¹ ê³„ì† ì‘ë™
# - ì‹¤í–‰ ì¤‘ì¸ ì‘ì—… ì˜í–¥ ì—†ìŒ
```

### 2. ì›¹ì„œë²„ ìë™ ìŠ¤ì¼€ì¼ ì•„ì›ƒ í…ŒìŠ¤íŠ¸
```bash
# ë¶€í•˜ ìƒì„± (1000ëª… ë™ì‹œ ì‚¬ìš©ì)
ab -n 10000 -c 1000 https://hpc-portal.example.com/auth/login

# ì˜ˆìƒ ê²°ê³¼:
# - 30ì´ˆ ì´ë‚´ ìë™ ìŠ¤ì¼€ì¼ë§ ê°ì§€
# - 1-2ë¶„ ë‚´ ìƒˆ ì›¹ì„œë²„ ì¶”ê°€
# - HAProxyì— ìë™ ë“±ë¡
# - ë¶€í•˜ ë¶„ì‚° í™•ì¸
```

### 3. Redis ì¥ì•  í…ŒìŠ¤íŠ¸
```bash
# Redis ë…¸ë“œ 1ê°œ ì¤‘ì§€
systemctl stop redis-server  # on redis-node-1

# ì˜ˆìƒ ê²°ê³¼:
# - Redis Sentinelì´ ìë™ìœ¼ë¡œ ìƒˆ Master ì„ ì¶œ
# - ì›¹ì„œë¹„ìŠ¤ ì¬ì ‘ì† ìë™ (5ì´ˆ ì´ë‚´)
# - ê¸°ì¡´ ì„¸ì…˜ ìœ ì§€ (JWTëŠ” ë¬´ê´€)
```

---

## ğŸ’¡ ì¶”ê°€ ìµœì í™” ì•„ì´ë””ì–´

### 1. ì§€ì—­ë³„ ë¶„ì‚° (Geo-Redundancy)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Site A      â”‚         â”‚ Site B      â”‚
â”‚ (ì„œìš¸)      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ (ë¶€ì‚°)      â”‚
â”‚             â”‚  WAN    â”‚             â”‚
â”‚ - Slurm M1  â”‚         â”‚ - Slurm M2  â”‚
â”‚ - Web 1-5   â”‚         â”‚ - Web 6-10  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
â†’ ì¬í•´ ë³µêµ¬(DR) + ì§€ì—­ë³„ ë¡œë“œ ë°¸ëŸ°ì‹±

### 2. ìŠ¤ì¼€ì¤„ ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§
```bash
# crontab
# ì˜¤ì „ 9ì‹œ: ì¶œê·¼ ì‹œê°„ â†’ ì›¹ì„œë²„ 5ëŒ€ë¡œ ì¦ì„¤
0 9 * * * /usr/local/bin/scale_to.sh 5

# ì˜¤í›„ 6ì‹œ: í‡´ê·¼ ì‹œê°„ â†’ ì›¹ì„œë²„ 2ëŒ€ë¡œ ì¶•ì†Œ
0 18 * * * /usr/local/bin/scale_to.sh 2
```
â†’ ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë¶€í•˜ íŒ¨í„´ ëŒ€ì‘

### 3. WebSocket ì„¸ì…˜ ìœ ì§€
```bash
# HAProxy - Sticky Session ì„¤ì •
backend websocket_backend
    balance leastconn
    cookie SERVERID insert indirect nocache
    server web1 192.168.1.21:5011 check cookie web1
    server web2 192.168.1.22:5011 check cookie web2
```
â†’ WebSocket ì—°ê²°ì´ ì„œë²„ ì¬ì‹œì‘ ì‹œì—ë„ ìœ ì§€

---

## ğŸ“š ì°¸ê³  ìë£Œ

### Slurm HA
- [Slurm Workload Manager - High Availability Guide](https://slurm.schedmd.com/high_availability.html)
- [Building a Highly Available Slurm Cluster](https://wiki.fysik.dtu.dk/niflheim/Slurm_configuration#high-availability-ha-using-slurmdbd)

### ìë™ ìŠ¤ì¼€ì¼ë§
- [HAProxy Runtime API](https://www.haproxy.com/blog/dynamic-configuration-haproxy-runtime-api/)
- [Ansible Dynamic Inventory](https://docs.ansible.com/ansible/latest/user_guide/intro_dynamic_inventory.html)

### í˜„ì¬ ì‹œìŠ¤í…œ ë¬¸ì„œ
- [HIGH_AVAILABILITY_PREPARATION.md](HIGH_AVAILABILITY_PREPARATION.md) - ì „ì²´ HA ì•„í‚¤í…ì²˜
- [HA_MINIMAL_CHANGES.md](HA_MINIMAL_CHANGES.md) - ì½”ë“œ ìµœì†Œ ë³€ê²½ì‚¬í•­

---

## ğŸ¯ ê²°ë¡ 

### âœ… í•  ë§Œí•œê°€? â†’ **ë„¤, ì¶©ë¶„íˆ ê°€ëŠ¥í•©ë‹ˆë‹¤!**

**ì´ìœ **:
1. **Slurm ì´ì¤‘í™”**ëŠ” í‘œì¤€ HA ë°©ì‹, ë¬¸ì„œë„ ì¶©ë¶„
2. **ì›¹ì„œë¹„ìŠ¤ ìë™ ìŠ¤ì¼€ì¼ë§**ì€ ì´ë¯¸ Stateless ì„¤ê³„ë˜ì–´ ìˆì–´ ì‰¬ì›€
3. **ìŠ¤í¬ë¦½íŠ¸ ê¸°ë°˜** ì ‘ê·¼ì´ë©´ Kubernetes ì—†ì´ë„ êµ¬í˜„ ê°€ëŠ¥
4. **í˜„ì¬ ì‹œìŠ¤í…œ**ì´ ì´ë¯¸ ì¢‹ì€ êµ¬ì¡° (Nginx upstream, Redis ì„¸ì…˜)

### ğŸš« ì–´ë µì§€ ì•Šì€ê°€? â†’ **ì¤‘ê°„ ë‚œì´ë„, ê´€ë¦¬ ê°€ëŠ¥**

**ìˆ˜ì •í•´ì•¼ í•  ê²ƒ**:
- âœ… Slurm ì„¤ì • íŒŒì¼ (`slurm.conf`) - **2ì¤„ ì¶”ê°€**
- âœ… ì›¹ì„œë¹„ìŠ¤ í™˜ê²½ë³€ìˆ˜ (`.env`) - **10ê°œ íŒŒì¼, 20ì¤„**
- âœ… Nginx â†’ HAProxy ì „í™˜ - **ì„¤ì • íŒŒì¼ ë³€í™˜ (1:1 ë§¤í•‘)**

**ìƒˆë¡œ ë§Œë“¤ ê²ƒ**:
- Keepalived ì„¤ì • (ë³µì‚¬-ë¶™ì—¬ë„£ê¸° ìˆ˜ì¤€)
- ìë™ ìŠ¤ì¼€ì¼ë§ ìŠ¤í¬ë¦½íŠ¸ (ì´ ë¬¸ì„œì— ìƒ˜í”Œ ìˆìŒ)
- Ansible í”Œë ˆì´ë¶ (ì´ ë¬¸ì„œì— ìƒ˜í”Œ ìˆìŒ)

### ğŸ’° ë¹„ìš© ëŒ€ë¹„ íš¨ê³¼

```
ì´ˆê¸° íˆ¬ì: 4-6ì£¼ ì‘ì—… ì‹œê°„
ìš´ì˜ ë¹„ìš©: ìµœì†Œ ì„œë²„ 2ëŒ€ â†’ í”¼í¬ ì‹œ NëŒ€ (ìë™ ì¡°ì ˆ)
íš¨ê³¼:
  - 99.9% ê°€ìš©ì„± (Slurm ì´ì¤‘í™”)
  - ë¬´í•œ í™•ì¥ì„± (ì›¹ì„œë¹„ìŠ¤ Auto-Scale)
  - ë¹„ìš© ì ˆê° (ì‚¬ìš©ëŸ‰ë§Œí¼ë§Œ ì§€ë¶ˆ)
```

**ì¶”ì²œ**: ìŠ¤í¬ë¦½íŠ¸ ê¸°ë°˜ ìë™ ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ ì‹œì‘, ì¶”í›„ í•„ìš”ì‹œ K8s ê³ ë ¤
