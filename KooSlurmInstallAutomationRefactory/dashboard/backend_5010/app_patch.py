"""
app.pyì— ì—…ë¡œë“œ/ë‹¤ìš´ë¡œë“œ ë° ì„±ëŠ¥ ìµœì í™” ê¸°ëŠ¥ í†µí•©ì„ ìœ„í•œ íŒ¨ì¹˜

ê¸°ì¡´ app.py íŒŒì¼ ëë¶€ë¶„(if __name__ == '__main__': ìœ„)ì— ì•„ë˜ ì½”ë“œë¥¼ ì¶”ê°€í•˜ì„¸ìš”:
"""

# ==================== íŒŒì¼ ì—…ë¡œë“œ/ë‹¤ìš´ë¡œë“œ í†µí•© ====================

from upload_api import upload_bp

# Blueprint ë“±ë¡
app.register_blueprint(upload_bp)

print("  ğŸ“¤ Upload/Download API enabled")

# ==================== ì„±ëŠ¥ ìµœì í™” í†µí•© ====================

from storage_api_optimized import (
    get_data_stats_cached,
    get_slurm_nodes_cached,
    get_scratch_info_parallel,
    get_scratch_directories_parallel,
    invalidate_storage_cache,
    warm_storage_cache
)

from performance import get_cache_stats

# ê¸°ì¡´ /api/storage/data/stats ì—”ë“œí¬ì¸íŠ¸ë¥¼ ìºì‹± ë²„ì „ìœ¼ë¡œ êµì²´
@app.route('/api/storage/data/stats', methods=['GET'])
def get_data_storage_stats_optimized():
    """
    /data ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ ì¡°íšŒ (ìºì‹± ì ìš©)
    """
    try:
        if MOCK_MODE:
            return jsonify({
                'success': True,
                'mode': 'mock',
                'data': {
                    'path': '/data',
                    'total': '10TB',
                    'used': '4.5TB',
                    'available': '5.5TB',
                    'use_percent': 45
                }
            })
        else:
            stats = get_data_stats_cached()
            return jsonify({
                'success': True,
                'mode': 'production',
                'data': stats,
                'cached': True
            })
    except Exception as e:
        print(f"âŒ Error getting data storage stats: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


# ê¸°ì¡´ /api/storage/scratch/nodes ì—”ë“œí¬ì¸íŠ¸ë¥¼ ìµœì í™” ë²„ì „ìœ¼ë¡œ êµì²´
@app.route('/api/storage/scratch/nodes', methods=['GET'])
def get_scratch_nodes_optimized():
    """
    Scratch ìŠ¤í† ë¦¬ì§€ ë…¸ë“œ ì¡°íšŒ (ë³‘ë ¬ ì²˜ë¦¬ + ìºì‹±)
    
    Performance:
        - ê¸°ì¡´: 4-6ì´ˆ (2ë…¸ë“œ, ìˆœì°¨ SSH)
        - ê°œì„ : 2-3ì´ˆ (ë³‘ë ¬ SSH + ìºì‹±)
        - ìºì‹œ íˆíŠ¸: ~100ms
    """
    try:
        if MOCK_MODE:
            from data.mockStorageData import mockScratchNodes
            return jsonify({
                'success': True,
                'mode': 'mock',
                'data': mockScratchNodes
            })
        else:
            # 1. ë…¸ë“œ ëª©ë¡ ì¡°íšŒ (ìºì‹±)
            nodes = get_slurm_nodes_cached()
            
            if not nodes:
                return jsonify({
                    'success': True,
                    'mode': 'production',
                    'data': [],
                    'message': 'No compute nodes found'
                })
            
            # 2. í™œì„± ë…¸ë“œë§Œ í•„í„°ë§
            active_nodes = [
                n['hostname'] for n in nodes 
                if n.get('state') in ['idle', 'allocated', 'mixed']
            ]
            
            if not active_nodes:
                return jsonify({
                    'success': True,
                    'mode': 'production',
                    'data': [],
                    'message': 'No active nodes'
                })
            
            # 3. Scratch ì •ë³´ ë³‘ë ¬ ìˆ˜ì§‘ (ìºì‹±)
            scratch_info = get_scratch_info_parallel(active_nodes)
            
            # 4. ë””ë ‰í† ë¦¬ ëª©ë¡ ë³‘ë ¬ ìˆ˜ì§‘ (ìºì‹±)
            directories = get_scratch_directories_parallel(active_nodes)
            
            # 5. ë°ì´í„° ê²°í•©
            result = []
            for info in scratch_info:
                node_name = info.get('node')
                node_dirs = [d for d in directories if d.get('node') == node_name]
                
                result.append({
                    'id': node_name,
                    'name': node_name,
                    'status': info.get('status', 'unknown'),
                    'diskUsage': {
                        'total': info.get('total', 'N/A'),
                        'used': info.get('used', 'N/A'),
                        'available': info.get('available', 'N/A'),
                        'usePercent': info.get('use_percent', 0)
                    },
                    'directories': node_dirs
                })
            
            return jsonify({
                'success': True,
                'mode': 'production',
                'data': result,
                'cached': True,
                'node_count': len(result)
            })
            
    except Exception as e:
        print(f"âŒ Error getting scratch nodes: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


# ìºì‹œ í†µê³„ ì—”ë“œí¬ì¸íŠ¸
@app.route('/api/cache/stats', methods=['GET'])
def get_cache_statistics():
    """ìºì‹œ í†µê³„ ì¡°íšŒ"""
    try:
        stats = get_cache_stats()
        return jsonify({
            'success': True,
            'data': stats
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


# ìºì‹œ ë¬´íš¨í™” ì—”ë“œí¬ì¸íŠ¸
@app.route('/api/cache/invalidate', methods=['POST'])
def invalidate_cache_endpoint():
    """ìºì‹œ ë¬´íš¨í™”"""
    try:
        invalidate_storage_cache()
        return jsonify({
            'success': True,
            'message': 'Storage cache invalidated'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


# ì•± ì‹œì‘ ì‹œ ìºì‹œ ì›Œë° (Production ëª¨ë“œë§Œ)
if not MOCK_MODE:
    import threading
    
    def warm_cache_background():
        import time
        time.sleep(2)  # ì•± ì‹œì‘ í›„ 2ì´ˆ ëŒ€ê¸°
        print("ğŸ”¥ Warming up cache...")
        warm_storage_cache()
        print("âœ… Cache warming completed")
    
    # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œë¡œ ì‹¤í–‰
    warming_thread = threading.Thread(target=warm_cache_background, daemon=True)
    warming_thread.start()


print("  âš¡ Performance optimizations enabled (Redis caching + parallel SSH)")
