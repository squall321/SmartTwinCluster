# í’€ ì¹´í”¼ ì‚¬ì¤‘í™”(Full-Copy Quad-Redundancy) HA ì•„í‚¤í…ì²˜

## ðŸ“‹ ì „ëžµ ê°œìš”

### âœ… í’€ ì¹´í”¼ ì‚¬ì¤‘í™”ëž€?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ëª¨ë“  ì„œë²„ê°€ ë™ì¼í•œ ê¸°ëŠ¥ì„ ìˆ˜í–‰ (Full Copy)                   â”‚
â”‚                                                               â”‚
â”‚  â€¢ ê° ì„œë²„: All-in-One (Slurm + Web + DB + Redis)           â”‚
â”‚  â€¢ 4ëŒ€ ì¤‘ 1ëŒ€ ì£½ì–´ë„ â†’ ë‚˜ë¨¸ì§€ 3ëŒ€ê°€ 100% ê¸°ëŠ¥ ìˆ˜í–‰            â”‚
â”‚  â€¢ ë¶€í•˜ ë¶„ì‚°: 4ëŒ€ê°€ ë™ì‹œì— ëª¨ë“  ìš”ì²­ ì²˜ë¦¬                     â”‚
â”‚  â€¢ ë°ì´í„° ë™ê¸°í™”: ì‹¤ì‹œê°„ Multi-Master Replication            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**í•µì‹¬ ì°¨ì´ì **:
- âŒ ê¸°ì¡´ ê³„íš: ì—­í•  ë¶„ë¦¬ (Web/App/Data Tier ë¶„ë¦¬)
- âœ… ìƒˆ ê³„íš: **ëª¨ë“  ì„œë²„ê°€ ë™ì¼** (ì™„ë²½í•œ ë™ì§ˆì„±)

**ìž¥ì **:
- âœ… **ì™„ë²½í•œ ìž¥ì•  ëŒ€ì‘**: 3ëŒ€ê¹Œì§€ ì£½ì–´ë„ ì„œë¹„ìŠ¤ ê°€ëŠ¥
- âœ… **ê°„ë‹¨í•œ ê´€ë¦¬**: ëª¨ë“  ì„œë²„ ì„¤ì • ë™ì¼
- âœ… **ìµœëŒ€ ì„±ëŠ¥**: ê³ ì‚¬ì–‘ ì„œë²„ 4ëŒ€ ëª¨ë‘ í™œìš©
- âœ… **ì‰¬ìš´ í™•ìž¥**: ë™ì¼í•œ ì„œë²„ 1ëŒ€ ì¶”ê°€í•˜ë©´ 5ì¤‘í™”

**ë‹¨ì **:
- âš ï¸ **ë¦¬ì†ŒìŠ¤ ì¤‘ë³µ**: ê° ì„œë²„ê°€ ëª¨ë“  ê¸°ëŠ¥ ì‹¤í–‰ (CPU/ë©”ëª¨ë¦¬ ë‚­ë¹„ ê°€ëŠ¥)
- âš ï¸ **ë³µìž¡í•œ ë™ê¸°í™”**: Multi-Master DB ë™ê¸°í™” í•„ìš”
- âš ï¸ **ì´ˆê¸° êµ¬ì¶• ë¹„ìš©**: 4ëŒ€ ëª¨ë‘ ê³ ì‚¬ì–‘ í•„ìš”

---

## ðŸ—ï¸ ì•„í‚¤í…ì²˜ ì„¤ê³„

### ì „ì²´ êµ¬ì„±ë„

```
                          ì¸í„°ë„· / ì‚¬ìš©ìž
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   VIP (192.168.1.100)   â”‚ â† Keepalived (Floating IP)
                    â”‚   Load Balancer         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                       â”‚                       â”‚
         â”‚                       â”‚                       â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Server1  â”‚           â”‚ Server2  â”‚           â”‚ Server3  â”‚           â”‚ Server4  â”‚
    â”‚ (MASTER) â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ (MASTER) â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ (MASTER) â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ (MASTER) â”‚
    â”‚          â”‚   Sync    â”‚          â”‚   Sync    â”‚          â”‚   Sync    â”‚          â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
         â”‚                      â”‚                      â”‚                       â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚                      ëª¨ë“  ì„œë²„ê°€ ë™ì¼í•œ êµ¬ì„±                                    â”‚
    â”‚                                                                                â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚ Slurm Layer                                                              â”‚  â”‚
    â”‚  â”‚  - slurmctld (Multi-Master with VIP failover)                           â”‚  â”‚
    â”‚  â”‚  - slurmdbd (MariaDB ì—°ê²°)                                              â”‚  â”‚
    â”‚  â”‚  - Compute Node Manager                                                 â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚                                                                                â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚ Web Services Layer                                                       â”‚  â”‚
    â”‚  â”‚  - auth_portal (4430/4431)                                              â”‚  â”‚
    â”‚  â”‚  - backend (5010/5011)                                                  â”‚  â”‚
    â”‚  â”‚  - kooCAEWebServer (5000/5001)                                          â”‚  â”‚
    â”‚  â”‚  - dashboard (5173)                                                     â”‚  â”‚
    â”‚  â”‚  - app_framework (5174)                                                 â”‚  â”‚
    â”‚  â”‚  - Nginx (ë¡œì»¬ reverse proxy)                                           â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚                                                                                â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚ Data Layer                                                               â”‚  â”‚
    â”‚  â”‚  - Redis Cluster (Multi-Master) â† 4-node cluster                        â”‚  â”‚
    â”‚  â”‚  - MariaDB Galera Cluster (Multi-Master) â† 4-node cluster               â”‚  â”‚
    â”‚  â”‚  - Shared Storage (GlusterFS 4-node) â† í”„ë¡ íŠ¸ì—”ë“œ ë¹Œë“œ íŒŒì¼ ê³µìœ          â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚                                                                                â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚ Monitoring Layer                                                         â”‚  â”‚
    â”‚  â”‚  - Prometheus (ê° ì„œë²„ì—ì„œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘)                                   â”‚  â”‚
    â”‚  â”‚  - Node Exporter (9100)                                                 â”‚  â”‚
    â”‚  â”‚  - Health Check Script (/health)                                        â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ”§ ê° ë ˆì´ì–´ë³„ êµ¬ì„±

### 1ï¸âƒ£ Load Balancer (VIP + Keepalived)

**ëª©ì **: ë‹¨ì¼ ì§„ìž…ì , ìžë™ ìž¥ì•  ì „í™˜

```
VIP: 192.168.1.100 (Floating IP)
â”‚
â”œâ”€ Server1 (Priority 100) â† MASTER
â”œâ”€ Server2 (Priority 99)
â”œâ”€ Server3 (Priority 98)
â””â”€ Server4 (Priority 97)
```

**Keepalived ì„¤ì •** (`/etc/keepalived/keepalived.conf`):

Server1 (Priority 100):
```bash
vrrp_script check_services {
    script "/usr/local/bin/check_all_services.sh"
    interval 2
    weight -20
    fall 3
    rise 2
}

vrrp_instance VI_1 {
    state MASTER
    interface ens18
    virtual_router_id 51
    priority 100  # Server1: 100, Server2: 99, Server3: 98, Server4: 97
    advert_int 1

    authentication {
        auth_type PASS
        auth_pass hpc_cluster_secret
    }

    virtual_ipaddress {
        192.168.1.100/24
    }

    track_script {
        check_services
    }

    # ìž¥ì•  ì „í™˜ ì‹œ ì•Œë¦¼
    notify_master "/usr/local/bin/notify_master.sh"
    notify_backup "/usr/local/bin/notify_backup.sh"
    notify_fault "/usr/local/bin/notify_fault.sh"
}
```

**í—¬ìŠ¤ì²´í¬ ìŠ¤í¬ë¦½íŠ¸** (`/usr/local/bin/check_all_services.sh`):
```bash
#!/bin/bash
# ëª¨ë“  í•µì‹¬ ì„œë¹„ìŠ¤ ì²´í¬

check_service() {
    local service=$1
    systemctl is-active --quiet $service
    return $?
}

# í•µì‹¬ ì„œë¹„ìŠ¤ ë¦¬ìŠ¤íŠ¸
CRITICAL_SERVICES=(
    "slurmctld"
    "redis-server"
    "mariadb"
    "auth_portal_4430"
    "backend_5010"
    "kooCAEWebServer_5000"
)

for service in "${CRITICAL_SERVICES[@]}"; do
    if ! check_service "$service"; then
        echo "CRITICAL: $service is down"
        exit 1
    fi
done

# HTTP í—¬ìŠ¤ì²´í¬
curl -sf http://localhost:4430/health > /dev/null || exit 1
curl -sf http://localhost:5010/health > /dev/null || exit 1
curl -sf http://localhost:5000/health > /dev/null || exit 1

exit 0
```

**ìž‘ë™ ë°©ì‹**:
1. Server1ì´ MASTERë¡œ VIP ì†Œìœ 
2. 2ì´ˆë§ˆë‹¤ í—¬ìŠ¤ì²´í¬ ì‹¤í–‰
3. Server1 ìž¥ì•  ì‹œ â†’ VIPê°€ Server2ë¡œ ì¦‰ì‹œ ì´ë™ (2-3ì´ˆ)
4. Server1 ë³µêµ¬ ì‹œ â†’ VIPëŠ” Server2ì— ìœ ì§€ (preempt ë¹„í™œì„±í™”)

---

### 2ï¸âƒ£ Slurm Multi-Master Configuration

**ëª©ì **: 4ëŒ€ ì¤‘ ì–´ëŠ ì„œë²„ë“  Slurm Controller ì—­í•  ìˆ˜í–‰ ê°€ëŠ¥

#### Slurm ì„¤ì • (`/etc/slurm/slurm.conf`)

```bash
# Multi-Master ì„¤ì • (4ëŒ€ ëª¨ë‘ ë°±ì—… ì»¨íŠ¸ë¡¤ëŸ¬)
SlurmctldHost=server1(192.168.1.101)
SlurmctldHost=server2(192.168.1.102)
SlurmctldHost=server3(192.168.1.103)
SlurmctldHost=server4(192.168.1.104)

# ê³µìœ  ìƒíƒœ ë””ë ‰í† ë¦¬ (GlusterFS)
StateSaveLocation=/mnt/gluster/slurm/state
SlurmdSpoolDir=/var/spool/slurmd

# ë¹ ë¥¸ ìž¥ì•  ì „í™˜
SlurmctldTimeout=120
SlurmdTimeout=300
MessageTimeout=30

# ìž‘ì—… í ê³µìœ  (MariaDB via slurmdbd)
AccountingStorageType=accounting_storage/slurmdbd
AccountingStorageHost=127.0.0.1  # ë¡œì»¬ slurmdbd â†’ ë¡œì»¬ MariaDB (Galera)
AccountingStoragePort=6819

# ë¡œê·¸ ì¤‘ì•™í™” (GlusterFS)
SlurmctldLogFile=/mnt/gluster/slurm/logs/slurmctld.log
SlurmdLogFile=/var/log/slurm/slurmd.log
```

#### Slurmdbd ì„¤ì • (`/etc/slurm/slurmdbd.conf`)

```bash
# MariaDB Galera ì—°ê²° (ë¡œì»¬ ë…¸ë“œ)
StorageType=accounting_storage/mysql
StorageHost=127.0.0.1
StoragePort=3306
StorageUser=slurm
StoragePass=slurm_password

# Galeraê°€ multi-masterì´ë¯€ë¡œ ì–´ëŠ ë…¸ë“œë“  ì½ê¸°/ì“°ê¸° ê°€ëŠ¥
# ìž¥ì•  ì‹œ ìžë™ìœ¼ë¡œ ë‹¤ë¥¸ ë…¸ë“œì˜ slurmdbdê°€ ê³„ì† ì“°ê¸°

LogFile=/mnt/gluster/slurm/logs/slurmdbd.log
```

#### systemd ì„œë¹„ìŠ¤ (ëª¨ë“  ì„œë²„ì— ë™ì¼í•˜ê²Œ ì„¤ì¹˜)

`/etc/systemd/system/slurmctld.service`:
```ini
[Unit]
Description=Slurm Controller Daemon
After=network.target mariadb.service
Requires=mariadb.service

[Service]
Type=forking
ExecStart=/usr/local/slurm/sbin/slurmctld -D
ExecReload=/bin/kill -HUP $MAINPID
Restart=on-failure
RestartSec=5s

[Install]
WantedBy=multi-user.target
```

**ëª¨ë“  ì„œë²„ì—ì„œ slurmctld ì‹¤í–‰**:
- Primary: VIPë¥¼ ê°€ì§„ ì„œë²„ì˜ slurmctldê°€ Active
- Others: Standby ëª¨ë“œë¡œ ëŒ€ê¸°
- ìž¥ì•  ì‹œ: VIPê°€ ì´ë™í•˜ë©´ í•´ë‹¹ ì„œë²„ì˜ slurmctldê°€ Active

---

### 3ï¸âƒ£ MariaDB Galera Cluster (4-node Multi-Master)

**ëª©ì **: ëª¨ë“  ë…¸ë“œì—ì„œ ì½ê¸°/ì“°ê¸° ê°€ëŠ¥, ìžë™ ë™ê¸°í™”

#### MariaDB ì„¤ì¹˜ (ëª¨ë“  ì„œë²„)

```bash
apt install -y mariadb-server galera-4 rsync
```

#### Galera ì„¤ì • (`/etc/mysql/mariadb.conf.d/galera.cnf`)

Server1:
```ini
[galera]
wsrep_on=ON
wsrep_provider=/usr/lib/galera/libgalera_smm.so

# í´ëŸ¬ìŠ¤í„° ì„¤ì •
wsrep_cluster_name="hpc_portal_cluster"
wsrep_cluster_address="gcomm://192.168.1.101,192.168.1.102,192.168.1.103,192.168.1.104"

# ë…¸ë“œ ì„¤ì •
wsrep_node_address="192.168.1.101"
wsrep_node_name="server1"

# Replication ì„¤ì •
binlog_format=row
default_storage_engine=InnoDB
innodb_autoinc_lock_mode=2

# SST (State Snapshot Transfer) ë°©ì‹
wsrep_sst_method=rsync

# ë™ì‹œ ì“°ê¸° í—ˆìš©
wsrep_slave_threads=4
```

Server2/3/4ëŠ” `wsrep_node_address`ì™€ `wsrep_node_name`ë§Œ ë³€ê²½

#### í´ëŸ¬ìŠ¤í„° ì´ˆê¸°í™”

**ì²« ë²ˆì§¸ ë…¸ë“œ (Server1):**
```bash
# Bootstrap (ìµœì´ˆ 1íšŒë§Œ)
galera_new_cluster

# ë˜ëŠ”
systemctl start mariadb@bootstrap
```

**ë‚˜ë¨¸ì§€ ë…¸ë“œ (Server2/3/4):**
```bash
# ì¼ë°˜ ì‹œìž‘ (ìžë™ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„° ì¡°ì¸)
systemctl start mariadb
```

#### í´ëŸ¬ìŠ¤í„° ìƒíƒœ í™•ì¸

```bash
mysql -u root -p -e "SHOW STATUS LIKE 'wsrep_cluster_size';"
# ê²°ê³¼: 4 (4ê°œ ë…¸ë“œ ëª¨ë‘ ì—°ê²°ë¨)

mysql -u root -p -e "SHOW STATUS LIKE 'wsrep_ready';"
# ê²°ê³¼: ON

mysql -u root -p -e "SHOW STATUS LIKE 'wsrep_local_state_comment';"
# ê²°ê³¼: Synced
```

#### ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± (í•œ ë…¸ë“œì—ì„œë§Œ)

```sql
-- Server1ì—ì„œ ì‹¤í–‰ (ìžë™ìœ¼ë¡œ ëª¨ë“  ë…¸ë“œì— ë³µì œë¨)

-- Slurm accounting DB
CREATE DATABASE slurm_acct_db;
CREATE USER 'slurm'@'localhost' IDENTIFIED BY 'slurm_password';
GRANT ALL ON slurm_acct_db.* TO 'slurm'@'localhost';

-- Auth Portal ì‚¬ìš©ìž DB
CREATE DATABASE auth_portal;
CREATE USER 'auth_user'@'localhost' IDENTIFIED BY 'auth_password';
GRANT ALL ON auth_portal.* TO 'auth_user'@'localhost';

FLUSH PRIVILEGES;
```

**ìž¥ì•  ëŒ€ì‘**:
- 1-2ëŒ€ ë‹¤ìš´: ë‚˜ë¨¸ì§€ ë…¸ë“œê°€ ìžë™ìœ¼ë¡œ ì¿¼ëŸ¼ ìœ ì§€, ì„œë¹„ìŠ¤ ê³„ì†
- 3ëŒ€ ë‹¤ìš´ (1ëŒ€ë§Œ ë‚¨ìŒ): Read-Only ëª¨ë“œ ì „í™˜ (ì•ˆì „ ìž¥ì¹˜)
- ë³µêµ¬: ë‹¤ìš´ëœ ë…¸ë“œ ìž¬ì‹œìž‘ ì‹œ ìžë™ìœ¼ë¡œ ë°ì´í„° ë™ê¸°í™” (IST/SST)

---

### 4ï¸âƒ£ Redis Cluster (4-node Multi-Master)

**ëª©ì **: ì„¸ì…˜ ë°ì´í„° ê³µìœ , 4ëŒ€ ëª¨ë‘ ì½ê¸°/ì“°ê¸° ê°€ëŠ¥

#### Redis ì„¤ì¹˜ ë° ì„¤ì •

```bash
apt install -y redis-server redis-tools
```

#### Redis Cluster ì„¤ì • (`/etc/redis/redis.conf`)

Server1:
```bash
# ë„¤íŠ¸ì›Œí¬
bind 0.0.0.0
port 6379
protected-mode yes
requirepass redis_cluster_secret

# í´ëŸ¬ìŠ¤í„° ëª¨ë“œ
cluster-enabled yes
cluster-config-file nodes-6379.conf
cluster-node-timeout 5000

# ë°ì´í„° ë™ê¸°í™”
appendonly yes
appendfsync everysec

# ë©”ëª¨ë¦¬ ì •ì±…
maxmemory 4gb
maxmemory-policy allkeys-lru
```

#### í´ëŸ¬ìŠ¤í„° ìƒì„±

**ëª¨ë“  ë…¸ë“œì—ì„œ Redis ì‹œìž‘:**
```bash
systemctl enable redis-server
systemctl start redis-server
```

**í´ëŸ¬ìŠ¤í„° ì´ˆê¸°í™” (Server1ì—ì„œ):**
```bash
redis-cli --cluster create \
    192.168.1.101:6379 \
    192.168.1.102:6379 \
    192.168.1.103:6379 \
    192.168.1.104:6379 \
    --cluster-replicas 0 \
    -a redis_cluster_secret

# --cluster-replicas 0: ëª¨ë“  ë…¸ë“œê°€ Master (Replica ì—†ìŒ)
# 4ëŒ€ê°€ ëª¨ë‘ ë™ë“±í•œ Masterë¡œ ë™ìž‘
```

#### í´ëŸ¬ìŠ¤í„° ìƒíƒœ í™•ì¸

```bash
redis-cli -c -h 192.168.1.101 -a redis_cluster_secret cluster info
# cluster_state:ok
# cluster_slots_assigned:16384
# cluster_known_nodes:4

redis-cli -c -h 192.168.1.101 -a redis_cluster_secret cluster nodes
# 4ê°œ ë…¸ë“œ ëª¨ë‘ masterë¡œ í‘œì‹œë¨
```

#### ì• í”Œë¦¬ì¼€ì´ì…˜ ì—°ê²° (Python)

```python
# auth_portal_4430/config/config.py
import os
from redis.cluster import RedisCluster

# Redis Cluster ì—°ê²°
REDIS_NODES = [
    {"host": "192.168.1.101", "port": 6379},
    {"host": "192.168.1.102", "port": 6379},
    {"host": "192.168.1.103", "port": 6379},
    {"host": "192.168.1.104", "port": 6379},
]

redis_client = RedisCluster(
    startup_nodes=REDIS_NODES,
    password=os.getenv('REDIS_PASSWORD', 'redis_cluster_secret'),
    decode_responses=True,
    skip_full_coverage_check=True  # ì¼ë¶€ ë…¸ë“œ ë‹¤ìš´ë˜ì–´ë„ ê³„ì† ìž‘ë™
)
```

**ìž¥ì•  ëŒ€ì‘**:
- 1-2ëŒ€ ë‹¤ìš´: ë‚˜ë¨¸ì§€ ë…¸ë“œê°€ í•´ì‹œ ìŠ¬ë¡¯ ìž¬ë¶„ë°°, ì„œë¹„ìŠ¤ ê³„ì†
- ì„¸ì…˜ ë°ì´í„°: íŠ¹ì • í‚¤ê°€ ë‹¤ìš´ëœ ë…¸ë“œì— ìžˆì—ˆë‹¤ë©´ ìœ ì‹¤ (JWTë¡œ ë³µêµ¬ ê°€ëŠ¥)

---

### 5ï¸âƒ£ GlusterFS (ë¶„ì‚° íŒŒì¼ ì‹œìŠ¤í…œ)

**ëª©ì **: í”„ë¡ íŠ¸ì—”ë“œ ë¹Œë“œ íŒŒì¼, Slurm ìƒíƒœ íŒŒì¼ ê³µìœ 

#### GlusterFS ì„¤ì¹˜

```bash
apt install -y glusterfs-server
systemctl enable glusterd
systemctl start glusterd
```

#### Peer ì—°ê²° (Server1ì—ì„œ)

```bash
gluster peer probe 192.168.1.102
gluster peer probe 192.168.1.103
gluster peer probe 192.168.1.104

gluster peer status
# State: Peer in Cluster (Connected)
```

#### Volume ìƒì„± (Replica 4)

```bash
# /mnt/gluster_brick ë””ë ‰í† ë¦¬ ì¤€ë¹„ (ëª¨ë“  ì„œë²„)
mkdir -p /mnt/gluster_brick/shared

# Replica 4 ë³¼ë¥¨ ìƒì„± (4ê°œ ë…¸ë“œì— ëª¨ë‘ ë³µì œ)
gluster volume create shared_data replica 4 \
    192.168.1.101:/mnt/gluster_brick/shared \
    192.168.1.102:/mnt/gluster_brick/shared \
    192.168.1.103:/mnt/gluster_brick/shared \
    192.168.1.104:/mnt/gluster_brick/shared

gluster volume start shared_data

# ë³¼ë¥¨ ì˜µì…˜ ì„¤ì •
gluster volume set shared_data performance.cache-size 256MB
gluster volume set shared_data network.ping-timeout 10
```

#### ë§ˆìš´íŠ¸ (ëª¨ë“  ì„œë²„)

```bash
# /etc/fstabì— ì¶”ê°€
echo "localhost:/shared_data /mnt/gluster glusterfs defaults,_netdev 0 0" >> /etc/fstab

mkdir -p /mnt/gluster
mount -a

# í™•ì¸
df -h | grep gluster
# localhost:/shared_data  xxxG  xxxG  xxxG  xx% /mnt/gluster
```

#### ë””ë ‰í† ë¦¬ êµ¬ì¡°

```bash
/mnt/gluster/
â”œâ”€â”€ frontend_builds/         # í”„ë¡ íŠ¸ì—”ë“œ ë¹Œë“œ ê²°ê³¼ (Nginxê°€ ì„œë¹™)
â”‚   â”œâ”€â”€ auth_frontend/
â”‚   â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ app_framework/
â”œâ”€â”€ slurm/
â”‚   â”œâ”€â”€ state/               # Slurm ìƒíƒœ íŒŒì¼
â”‚   â”œâ”€â”€ logs/                # Slurm ë¡œê·¸
â”‚   â””â”€â”€ spool/               # ìž‘ì—… í
â””â”€â”€ uploads/                 # ì‚¬ìš©ìž ì—…ë¡œë“œ íŒŒì¼
```

**ìž¥ì•  ëŒ€ì‘**:
- 1-3ëŒ€ ë‹¤ìš´: Replica 4ì´ë¯€ë¡œ ìµœì†Œ 1ëŒ€ë§Œ ì‚´ì•„ìžˆìœ¼ë©´ ë°ì´í„° ì ‘ê·¼ ê°€ëŠ¥
- ë³µêµ¬: ë‹¤ìš´ëœ ë…¸ë“œ ìž¬ì‹œìž‘ ì‹œ ìžë™ ë™ê¸°í™” (Self-heal)

---

### 6ï¸âƒ£ Web Services (ëª¨ë“  ì„œë²„ì— ë™ì¼í•˜ê²Œ ë°°í¬)

**ëª©ì **: 4ëŒ€ ëª¨ë‘ ë™ì¼í•œ ì›¹ì„œë¹„ìŠ¤ ì‹¤í–‰

#### ì„œë¹„ìŠ¤ ë¦¬ìŠ¤íŠ¸ (ê° ì„œë²„ì— All-in-One)

```
auth_portal_4430        â†’ JWT ì¸ì¦ ë°±ì—”ë“œ
auth_frontend_4431      â†’ SSO ë¡œê·¸ì¸ UI (ë¹Œë“œ íŒŒì¼ â†’ GlusterFS)
backend_5010            â†’ Dashboard API
websocket_5011          â†’ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
kooCAEWebServer_5000    â†’ CAE ìžë™í™” ë°±ì—”ë“œ
kooCAEWebAutomation_5001 â†’ CAE ìžë™í™” ì‹¤í–‰ê¸°
dashboard_5173          â†’ Dashboard UI (ë¹Œë“œ íŒŒì¼ â†’ GlusterFS)
app_5174                â†’ App Framework UI (ë¹Œë“œ íŒŒì¼ â†’ GlusterFS)
```

#### ë°°í¬ ì „ëžµ

**ë°©ë²• 1: Git + Systemd (ì¶”ì²œ)**

ê° ì„œë²„ì—ì„œ:
```bash
# 1. ì €ìž¥ì†Œ í´ë¡ 
cd /opt
git clone https://github.com/your-org/hpc-dashboard.git
cd hpc-dashboard/dashboard

# 2. ë°±ì—”ë“œ ì„œë¹„ìŠ¤ ì„¤ì¹˜ (Python)
for service in auth_portal_4430 backend_5010 kooCAEWebServer_5000 kooCAEWebAutomationServer_5001 websocket_5011; do
    cd $service
    python3 -m venv venv
    source venv/bin/activate
    pip install -r requirements.txt
    deactivate
    cd ..
done

# 3. í”„ë¡ íŠ¸ì—”ë“œ ë¹Œë“œ â†’ GlusterFSë¡œ ë³µì‚¬
./build_all_frontends.sh

# ë¹Œë“œ ê²°ê³¼ë¥¼ GlusterFSë¡œ ë³µì‚¬ (1ê°œ ì„œë²„ì—ì„œë§Œ ì‹¤í–‰)
if [ "$(hostname)" == "server1" ]; then
    cp -r auth_frontend_4431/dist /mnt/gluster/frontend_builds/auth_frontend
    cp -r dashboard_5173/dist /mnt/gluster/frontend_builds/dashboard
    cp -r app_5174/dist /mnt/gluster/frontend_builds/app_framework
fi

# 4. í™˜ê²½ë³€ìˆ˜ ì„¤ì •
for service in auth_portal_4430 backend_5010 kooCAEWebServer_5000 kooCAEWebAutomationServer_5001; do
    cat > $service/.env <<EOF
REDIS_HOST=127.0.0.1
REDIS_PORT=6379
REDIS_PASSWORD=redis_cluster_secret
DB_HOST=127.0.0.1
DB_PORT=3306
DB_USER=auth_user
DB_PASSWORD=auth_password
MOCK_MODE=false
EOF
done

# 5. Systemd ì„œë¹„ìŠ¤ ìƒì„± ë° ì‹œìž‘
./create_systemd_services.sh
systemctl daemon-reload
./start_complete.sh
```

#### Nginx ì„¤ì • (ë¡œì»¬ ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ)

ê° ì„œë²„ì˜ `/etc/nginx/sites-available/local-proxy.conf`:
```nginx
# GlusterFSì—ì„œ ì •ì  íŒŒì¼ ì„œë¹™
server {
    listen 80;
    server_name localhost;

    # Auth Frontend
    location /auth/ {
        alias /mnt/gluster/frontend_builds/auth_frontend/;
        try_files $uri $uri/ /auth/index.html;
    }

    # Dashboard Frontend
    location /dashboard/ {
        alias /mnt/gluster/frontend_builds/dashboard/;
        try_files $uri $uri/ /dashboard/index.html;
    }

    # App Framework Frontend
    location /app/ {
        alias /mnt/gluster/frontend_builds/app_framework/;
        try_files $uri $uri/ /app/index.html;
    }

    # ë°±ì—”ë“œ API í”„ë¡ì‹œ (ë¡œì»¬ ì„œë¹„ìŠ¤)
    location /api/auth {
        proxy_pass http://127.0.0.1:4430;
    }

    location /api/dashboard {
        proxy_pass http://127.0.0.1:5010;
    }

    location /api/cae {
        proxy_pass http://127.0.0.1:5000;
    }

    # WebSocket
    location /ws/ {
        proxy_pass http://127.0.0.1:5011;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}
```

---

### 7ï¸âƒ£ External Load Balancer (ì„ íƒ ì‚¬í•­)

**ëª©ì **: VIP ì•žë‹¨ì— HAProxy ì¶”ê°€ë¡œ ë” ì •êµí•œ ë¼ìš°íŒ…

```
ì‚¬ìš©ìž â†’ HAProxy (ì™¸ë¶€) â†’ VIP (Keepalived) â†’ 4ëŒ€ ì„œë²„
```

**HAProxy ì„¤ì •** (`/etc/haproxy/haproxy.cfg`):
```bash
frontend https_frontend
    bind *:443 ssl crt /etc/ssl/certs/hpc-portal.pem
    mode http

    # í—¬ìŠ¤ì²´í¬ ê¸°ë°˜ ë¼ìš°íŒ…
    acl server1_up srv_is_up(hpc_backend/server1)
    acl server2_up srv_is_up(hpc_backend/server2)
    acl server3_up srv_is_up(hpc_backend/server3)
    acl server4_up srv_is_up(hpc_backend/server4)

    use_backend hpc_backend

backend hpc_backend
    mode http
    balance roundrobin
    option httpchk GET /health

    # 4ëŒ€ ì„œë²„ ëª¨ë‘ ë“±ë¡
    server server1 192.168.1.101:80 check inter 2s fall 3 rise 2
    server server2 192.168.1.102:80 check inter 2s fall 3 rise 2
    server server3 192.168.1.103:80 check inter 2s fall 3 rise 2
    server server4 192.168.1.104:80 check inter 2s fall 3 rise 2

    # Sticky Session (WebSocketìš©)
    cookie SERVERID insert indirect nocache
    server server1 192.168.1.101:80 check cookie s1
    server server2 192.168.1.102:80 check cookie s2
    server server3 192.168.1.103:80 check cookie s3
    server server4 192.168.1.104:80 check cookie s4
```

---

## ðŸ“Š ìž¥ì•  ì‹œë‚˜ë¦¬ì˜¤ë³„ ëŒ€ì‘

### ì‹œë‚˜ë¦¬ì˜¤ 1: Server1 ì™„ì „ ë‹¤ìš´

**ë°œìƒ ìˆœì„œ**:
1. Keepalived í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨ (2ì´ˆ)
2. VIPê°€ Server2ë¡œ ì´ë™ (3ì´ˆ)
3. Slurm: Server2ì˜ slurmctldê°€ Active
4. MariaDB Galera: 3ë…¸ë“œë¡œ ì¿¼ëŸ¼ ìœ ì§€
5. Redis Cluster: í•´ì‹œ ìŠ¬ë¡¯ ìž¬ë¶„ë°°
6. GlusterFS: Replica 3ìœ¼ë¡œ ì„œë¹„ìŠ¤ ê³„ì†

**ì‚¬ìš©ìž ì˜í–¥**:
- âœ… 5ì´ˆ ì´ë‚´ ìžë™ ë³µêµ¬
- âœ… ì§„í–‰ ì¤‘ì¸ HTTP ìš”ì²­: ì¼ë¶€ ì‹¤íŒ¨ (í´ë¼ì´ì–¸íŠ¸ ìž¬ì‹œë„ í•„ìš”)
- âœ… WebSocket: ìž¬ì ‘ì† (í”„ë¡ íŠ¸ì—”ë“œ ìžë™ ìž¬ì—°ê²°)
- âœ… Slurm ìž‘ì—…: ì˜í–¥ ì—†ìŒ (ê³„ì† ì‹¤í–‰)

---

### ì‹œë‚˜ë¦¬ì˜¤ 2: Server1, Server2 ë™ì‹œ ë‹¤ìš´ (2ëŒ€ ë‹¤ìš´)

**ë°œìƒ ìˆœì„œ**:
1. VIPê°€ Server3ë¡œ ì´ë™
2. MariaDB Galera: 2ë…¸ë“œë¡œ ì¿¼ëŸ¼ ìœ ì§€ (ì •ìƒ)
3. Redis Cluster: 2ë…¸ë“œë¡œ í•´ì‹œ ìŠ¬ë¡¯ ìž¬ë¶„ë°°
4. GlusterFS: Replica 2ë¡œ ì„œë¹„ìŠ¤ ê³„ì†

**ì‚¬ìš©ìž ì˜í–¥**:
- âœ… ì„œë¹„ìŠ¤ ì •ìƒ ìž‘ë™
- âš ï¸ ì„±ëŠ¥ 50% ê°ì†Œ (2ëŒ€ê°€ 4ëŒ€ ë¶„ëŸ‰ ì²˜ë¦¬)
- âš ï¸ ì¶”ê°€ ìž¥ì•  ì‹œ ìœ„í—˜ (1ëŒ€ ë” ë‹¤ìš´ë˜ë©´ ë¬¸ì œ)

---

### ì‹œë‚˜ë¦¬ì˜¤ 3: Server1, Server2, Server3 ë‹¤ìš´ (3ëŒ€ ë‹¤ìš´ - ìµœì•…)

**ë°œìƒ ìˆœì„œ**:
1. VIPê°€ Server4ë¡œ ì´ë™
2. MariaDB Galera: 1ë…¸ë“œë§Œ ë‚¨ìŒ â†’ **Read-Only ëª¨ë“œ**
3. Redis Cluster: 1ë…¸ë“œë§Œ ë‚¨ìŒ â†’ ì¼ë¶€ í‚¤ ìœ ì‹¤ ê°€ëŠ¥
4. GlusterFS: Replica 1 â†’ ë°ì´í„° ì ‘ê·¼ ê°€ëŠ¥í•˜ì§€ë§Œ ë³µì œ ì—†ìŒ

**ì‚¬ìš©ìž ì˜í–¥**:
- âš ï¸ **ì½ê¸° ì „ìš© ëª¨ë“œ**: ë¡œê·¸ì¸, ì¡°íšŒëŠ” ê°€ëŠ¥, ìž‘ì—… ì œì¶œ/ìˆ˜ì • ë¶ˆê°€
- âš ï¸ ì¼ë¶€ ì„¸ì…˜ ìœ ì‹¤ (Redis í‚¤ ìœ ì‹¤)
- âš ï¸ ì„±ëŠ¥ 75% ê°ì†Œ
- ðŸš¨ **ê¸´ê¸‰ ë³µêµ¬ í•„ìš”**: ìµœì†Œ 1ëŒ€ ì´ìƒ ë³µêµ¬í•´ì•¼ ì“°ê¸° ìž¬ê°œ

**ë³µêµ¬ ë°©ë²•**:
```bash
# Server2 ë˜ëŠ” Server3 ìž¬ì‹œìž‘
# MariaDBê°€ ìžë™ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„° ìž¬ì¡°ì¸

# ì¿¼ëŸ¼ ë³µêµ¬ í™•ì¸
mysql -u root -p -e "SHOW STATUS LIKE 'wsrep_cluster_size';"
# ê²°ê³¼: 2 ì´ìƒì´ë©´ Read-Write ëª¨ë“œ ë³µêµ¬
```

---

## ðŸ› ï¸ êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 1: í•˜ë“œì›¨ì–´ ì¤€ë¹„ (1-3ì¼)

- [ ] ì„œë²„ 4ëŒ€ ì¤€ë¹„ (ë™ì¼ ìŠ¤íŽ™)
  - CPU: 16+ Core
  - RAM: 64+ GB
  - Disk: 1TB+ SSD
  - Network: 10Gbps ì´ìƒ ê¶Œìž¥
- [ ] ë„¤íŠ¸ì›Œí¬ êµ¬ì„±
  - ê³ ì • IP í• ë‹¹ (192.168.1.101-104)
  - VIP ì˜ˆì•½ (192.168.1.100)
  - ìŠ¤ìœ„ì¹˜ ì„¤ì • (VRRP/Multicast í—ˆìš©)

### Phase 2: ê¸°ë³¸ ì¸í”„ë¼ (1ì£¼)

- [ ] OS ì„¤ì¹˜ ë° ì—…ë°ì´íŠ¸ (Ubuntu 22.04 LTS)
- [ ] í˜¸ìŠ¤íŠ¸ëª… ì„¤ì • (server1-4)
- [ ] SSH í‚¤ êµí™˜ (íŒ¨ìŠ¤ì›Œë“œ ì—†ì´ ì ‘ì†)
- [ ] NTP ë™ê¸°í™” ì„¤ì •
- [ ] ë°©í™”ë²½ ì„¤ì • (iptables/ufw)

### Phase 3: ë°ì´í„° ë ˆì´ì–´ (2ì£¼)

- [ ] MariaDB Galera Cluster êµ¬ì„±
  - [ ] Server1-4 ëª¨ë‘ ì„¤ì¹˜
  - [ ] í´ëŸ¬ìŠ¤í„° ì´ˆê¸°í™”
  - [ ] ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
  - [ ] ìž¥ì•  í…ŒìŠ¤íŠ¸ (1ëŒ€ ì¤‘ì§€ â†’ ìžë™ ë³µêµ¬ í™•ì¸)
- [ ] Redis Cluster êµ¬ì„±
  - [ ] Server1-4 ëª¨ë‘ ì„¤ì¹˜
  - [ ] í´ëŸ¬ìŠ¤í„° ìƒì„±
  - [ ] ì—°ê²° í…ŒìŠ¤íŠ¸
- [ ] GlusterFS êµ¬ì„±
  - [ ] Peer ì—°ê²°
  - [ ] Replica 4 ë³¼ë¥¨ ìƒì„±
  - [ ] ë§ˆìš´íŠ¸ ë° í…ŒìŠ¤íŠ¸

### Phase 4: Slurm ì„¤ì • (1ì£¼)

- [ ] Slurm ì„¤ì¹˜ (Server1-4)
- [ ] `slurm.conf` Multi-Master ì„¤ì •
- [ ] `slurmdbd.conf` Galera ì—°ê²° ì„¤ì •
- [ ] Systemd ì„œë¹„ìŠ¤ ë“±ë¡
- [ ] VIP ì „í™˜ í…ŒìŠ¤íŠ¸

### Phase 5: ì›¹ ì„œë¹„ìŠ¤ ë°°í¬ (2ì£¼)

- [ ] Git ì €ìž¥ì†Œ í´ë¡  (Server1-4)
- [ ] Python ê°€ìƒí™˜ê²½ ì„¤ì •
- [ ] Node.js ì˜ì¡´ì„± ì„¤ì¹˜
- [ ] í”„ë¡ íŠ¸ì—”ë“œ ë¹Œë“œ â†’ GlusterFS ë³µì‚¬
- [ ] í™˜ê²½ë³€ìˆ˜ ì„¤ì • (Redis/DB ì—°ê²°)
- [ ] Systemd ì„œë¹„ìŠ¤ ìƒì„±
- [ ] Nginx ë¡œì»¬ í”„ë¡ì‹œ ì„¤ì •

### Phase 6: Keepalived ì„¤ì • (3ì¼)

- [ ] Keepalived ì„¤ì¹˜ (Server1-4)
- [ ] VIP ì„¤ì • (Priority: 100/99/98/97)
- [ ] í—¬ìŠ¤ì²´í¬ ìŠ¤í¬ë¦½íŠ¸ ìž‘ì„±
- [ ] ì•Œë¦¼ ìŠ¤í¬ë¦½íŠ¸ ìž‘ì„± (Slack/Email)
- [ ] VIP ì „í™˜ í…ŒìŠ¤íŠ¸

### Phase 7: ëª¨ë‹ˆí„°ë§ (1ì£¼)

- [ ] Prometheus ì„¤ì¹˜ (ì¤‘ì•™ ì„œë²„ ë˜ëŠ” Server1)
- [ ] Node Exporter (Server1-4)
- [ ] Grafana ëŒ€ì‹œë³´ë“œ
- [ ] ì•Œë¦¼ ê·œì¹™ ì„¤ì •

### Phase 8: í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ (1-2ì£¼)

- [ ] ë¶€í•˜ í…ŒìŠ¤íŠ¸ (4ëŒ€ â†’ 3ëŒ€ â†’ 2ëŒ€ â†’ 1ëŒ€)
- [ ] ìž¥ì•  ì „í™˜ í…ŒìŠ¤íŠ¸ (ê° ì„œë²„ ìˆœì°¨ì  ì¤‘ì§€)
- [ ] ë°ì´í„° ì¼ê´€ì„± í…ŒìŠ¤íŠ¸ (Galera, Redis, GlusterFS)
- [ ] ë°±ì—…/ë³µêµ¬ í…ŒìŠ¤íŠ¸
- [ ] ì‚¬ìš©ìž ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸

---

## ðŸš€ ë°°í¬ ìžë™í™” ìŠ¤í¬ë¦½íŠ¸

### ì „ì²´ ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ (`deploy_all.sh`)

```bash
#!/bin/bash
# 4ëŒ€ ì„œë²„ì— ë™ì¼í•˜ê²Œ ë°°í¬í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

SERVERS=("192.168.1.101" "192.168.1.102" "192.168.1.103" "192.168.1.104")
SSH_USER="hpcadmin"

# ë³‘ë ¬ ì‹¤í–‰
for server in "${SERVERS[@]}"; do
    echo "ðŸš€ Deploying to $server..."

    ssh $SSH_USER@$server << 'EOF' &
        set -e

        # Git pull
        cd /opt/hpc-dashboard
        git pull origin main

        # ë°±ì—”ë“œ ìž¬ì‹œìž‘
        for service in auth_portal_4430 backend_5010 kooCAEWebServer_5000; do
            sudo systemctl restart $service
        done

        # í”„ë¡ íŠ¸ì—”ë“œ ìž¬ë¹Œë“œ (Server1ì—ì„œë§Œ)
        if [ "$(hostname)" == "server1" ]; then
            cd dashboard
            ./build_all_frontends.sh
            cp -r */dist /mnt/gluster/frontend_builds/
        fi

        echo "âœ… Deployment on $(hostname) completed"
EOF
done

# ëª¨ë“  ë°±ê·¸ë¼ìš´ë“œ ìž‘ì—… ì™„ë£Œ ëŒ€ê¸°
wait

echo "ðŸŽ‰ All servers deployed successfully!"
```

---

## ðŸ“ˆ ì„±ëŠ¥ ë° ë¹„ìš© ë¶„ì„

### ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥  (4ëŒ€ ì„œë²„)

| ìƒíƒœ | CPU | RAM | ë„¤íŠ¸ì›Œí¬ | ë¹„ê³  |
|------|-----|-----|----------|------|
| **ì •ìƒ (4ëŒ€)** | 25% | 40% | ë‚®ìŒ | ì—¬ìœ  ì¶©ë¶„ |
| **1ëŒ€ ë‹¤ìš´ (3ëŒ€)** | 33% | 53% | ì¤‘ê°„ | ì •ìƒ ìš´ì˜ |
| **2ëŒ€ ë‹¤ìš´ (2ëŒ€)** | 50% | 80% | ë†’ìŒ | ì„œë¹„ìŠ¤ ê°€ëŠ¥, ì„±ëŠ¥ ì €í•˜ |
| **3ëŒ€ ë‹¤ìš´ (1ëŒ€)** | 100% | 100% | ë§¤ìš° ë†’ìŒ | ê¸´ê¸‰ ìƒí™©, ì½ê¸°ë§Œ ê°€ëŠ¥ |

### ìž¥ì•  í™•ë¥  (ê°€ì •: ê° ì„œë²„ 99% ê°€ìš©ì„±)

```
1ëŒ€ ìš´ì˜: 99.0% ê°€ìš©ì„±
2ëŒ€ ìš´ì˜: 99.99% (í•œ ëŒ€ë§Œ ì‚´ì•„ìžˆìœ¼ë©´ OK)
4ëŒ€ ìš´ì˜: 99.999999% (ë„¤ ëŒ€ ëª¨ë‘ ì£½ì„ í™•ë¥ : 0.01^4)
```

### ë¹„ìš© ë¹„êµ

| êµ¬ì„± | ì´ˆê¸° ë¹„ìš© | ì›” ìš´ì˜ ë¹„ìš© | ê°€ìš©ì„± |
|------|----------|-------------|--------|
| **ë‹¨ì¼ ì„œë²„** | 1x | 1x | 99% |
| **ì´ì¤‘í™”** | 2x | 2x | 99.99% |
| **í’€ ì¹´í”¼ 4ì¤‘í™”** | 4x | 4x | 99.999999% |

**íŒë‹¨ ê¸°ì¤€**:
- ë¯¸ì…˜ í¬ë¦¬í‹°ì»¬ ì‹œìŠ¤í…œ (HPC í´ëŸ¬ìŠ¤í„°) â†’ âœ… 4ì¤‘í™” ê¶Œìž¥
- ê°œë°œ/í…ŒìŠ¤íŠ¸ í™˜ê²½ â†’ ì´ì¤‘í™”ë¡œ ì¶©ë¶„

---

## âš™ï¸ ìœ ì§€ë³´ìˆ˜ ê°€ì´ë“œ

### ì •ê¸° ì ê²€ (ì›” 1íšŒ)

```bash
#!/bin/bash
# monthly_check.sh

echo "=== Galera Cluster Status ==="
mysql -u root -p -e "SHOW STATUS LIKE 'wsrep%';" | grep -E 'cluster_size|ready|local_state'

echo "=== Redis Cluster Status ==="
redis-cli -c cluster info

echo "=== GlusterFS Status ==="
gluster volume status shared_data

echo "=== Keepalived Status ==="
systemctl status keepalived | grep -E 'Active|VIP'

echo "=== Disk Usage ==="
df -h | grep -E 'gluster|Filesystem'

echo "=== Service Status ==="
for service in slurmctld slurmdbd mariadb redis-server auth_portal_4430 backend_5010; do
    systemctl is-active --quiet $service && echo "âœ… $service" || echo "âŒ $service"
done
```

### ì—…ë°ì´íŠ¸ ì ˆì°¨ (Rolling Update)

```bash
# 1. Server4 ì—…ë°ì´íŠ¸ (Priority ê°€ìž¥ ë‚®ìŒ)
ssh server4
sudo systemctl stop all_services
cd /opt/hpc-dashboard && git pull
sudo systemctl start all_services

# 2. Server3 ì—…ë°ì´íŠ¸
# ... ë™ì¼ ...

# 3. Server2 ì—…ë°ì´íŠ¸
# ...

# 4. Server1 ì—…ë°ì´íŠ¸ (ë§ˆì§€ë§‰, VIP ì†Œìœ )
# ...
```

---

## ðŸŽ¯ ê²°ë¡ 

### âœ… í’€ ì¹´í”¼ ì‚¬ì¤‘í™” ê°€ëŠ¥í•œê°€? â†’ **ë„¤, ê°€ëŠ¥í•©ë‹ˆë‹¤!**

**ì´ìœ **:
1. **MariaDB Galera**: Multi-Master ì§€ì›, 4-node ê²€ì¦ë¨
2. **Redis Cluster**: Multi-Master ì§€ì›, ë¬´ì œí•œ ë…¸ë“œ
3. **GlusterFS**: Replica 4 ì§€ì›, ìžë™ ë³µêµ¬
4. **Slurm**: Multi-Master ì„¤ì • ê³µì‹ ì§€ì›

### ðŸ”§ ìˆ˜ì •í•´ì•¼ í•  ê²ƒ

| íŒŒì¼ | ë³€ê²½ ë‚´ìš© |
|------|----------|
| `slurm.conf` | `SlurmctldHost` 4ê°œ ì„ ì–¸ (4ì¤„) |
| ì›¹ì„œë¹„ìŠ¤ `.env` | Redis/DB ì£¼ì†Œ â†’ `127.0.0.1` (ë¡œì»¬) |
| Nginx ì„¤ì • | ì •ì  íŒŒì¼ ê²½ë¡œ â†’ `/mnt/gluster/frontend_builds/` |

**ì´ ìˆ˜ì •ëŸ‰**: ~15ê°œ íŒŒì¼, ~40ì¤„

### â±ï¸ ì˜ˆìƒ ì†Œìš” ì‹œê°„

- **Phase 1-2 (í•˜ë“œì›¨ì–´)**: 3-5ì¼
- **Phase 3 (ë°ì´í„° ë ˆì´ì–´)**: 2ì£¼
- **Phase 4 (Slurm)**: 1ì£¼
- **Phase 5 (ì›¹ ì„œë¹„ìŠ¤)**: 2ì£¼
- **Phase 6 (Keepalived)**: 3ì¼
- **Phase 7-8 (ëª¨ë‹ˆí„°ë§/í…ŒìŠ¤íŠ¸)**: 2ì£¼

**ì´ 6-7ì£¼**

### ðŸ’° íˆ¬ìž ëŒ€ë¹„ íš¨ê³¼

```
ì´ˆê¸° íˆ¬ìž: ì„œë²„ 4ëŒ€ + 6-7ì£¼ ìž‘ì—…
ìš´ì˜ ì´ì :
  âœ… 99.999999% ê°€ìš©ì„± (ì—°ê°„ ë‹¤ìš´íƒ€ìž„ < 3ì´ˆ)
  âœ… 3ëŒ€ê¹Œì§€ ë™ì‹œ ìž¥ì•  ëŒ€ì‘
  âœ… ë¬´ì¤‘ë‹¨ ì—…ë°ì´íŠ¸ (Rolling Update)
  âœ… ê³ ì„±ëŠ¥ (4ëŒ€ ë³‘ë ¬ ì²˜ë¦¬)
  âœ… ê°„ë‹¨í•œ ê´€ë¦¬ (ëª¨ë“  ì„œë²„ ë™ì¼)
```

**ì¶”ì²œ**: âœ… HPC ë¯¸ì…˜ í¬ë¦¬í‹°ì»¬ ì‹œìŠ¤í…œì— ìµœì 
