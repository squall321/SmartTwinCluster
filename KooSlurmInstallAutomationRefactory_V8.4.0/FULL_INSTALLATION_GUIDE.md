# HPC í´ëŸ¬ìŠ¤í„° + ì›¹ ì„œë¹„ìŠ¤ ì™„ì „ ì„¤ì¹˜ ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

ì´ ë¬¸ì„œëŠ” **Slurm í´ëŸ¬ìŠ¤í„° ì„¤ì¹˜**ë¶€í„° **ì›¹ ì„œë¹„ìŠ¤ ë°°í¬**ê¹Œì§€ ì „ì²´ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ìˆœì„œë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤.

**ì „ì²´ ì†Œìš” ì‹œê°„**: ì•½ 1-2ì‹œê°„ (ìë™í™” ê¸°ì¤€)
**ìˆ˜ë™ ì‘ì—…**: ìµœì†Œí™” (ì„¤ì • íŒŒì¼ 2ê°œë§Œ í¸ì§‘)

---

## ğŸ—‚ï¸ ì „ì²´ êµ¬ì¡°

```
HPC ì‹œìŠ¤í…œ = Slurm í´ëŸ¬ìŠ¤í„° + ì›¹ ì„œë¹„ìŠ¤

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 1: Slurm í´ëŸ¬ìŠ¤í„° ì„¤ì¹˜                        â”‚
â”‚  â”œâ”€ ìŠ¤í¬ë¦½íŠ¸: setup_cluster_full.sh                 â”‚
â”‚  â””â”€ ì„¤ì • íŒŒì¼: my_cluster.yaml                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 2: ì›¹ ì„œë¹„ìŠ¤ ì„¤ì¹˜                            â”‚
â”‚  â”œâ”€ ìŠ¤í¬ë¦½íŠ¸: setup_web_services.sh                 â”‚
â”‚  â””â”€ ì„¤ì • íŒŒì¼: web_services_config.yaml             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Phase 1: Slurm í´ëŸ¬ìŠ¤í„° ì„¤ì¹˜

### 1.1 í•„ìš”í•œ íŒŒì¼

| íŒŒì¼ | ì—­í•  | í¸ì§‘ í•„ìš” |
|------|------|----------|
| **my_cluster.yaml** | í´ëŸ¬ìŠ¤í„° ì„¤ì • (ë…¸ë“œ, íŒŒí‹°ì…˜ ë“±) | âœ… **í•„ìˆ˜** |
| `setup_cluster_full.sh` | ìë™ ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ | âŒ í¸ì§‘ ë¶ˆí•„ìš” |
| `install_slurm_cgroup_v2.sh` | Slurm ì»´íŒŒì¼ ì„¤ì¹˜ | âŒ ìë™ í˜¸ì¶œ |
| `configure_slurm_from_yaml.py` | Slurm ì„¤ì • ìƒì„± | âŒ ìë™ í˜¸ì¶œ |
| `install_munge_auto.sh` | Munge ì¸ì¦ ì„¤ì¹˜ | âŒ ìë™ í˜¸ì¶œ |

### 1.2 ì„¤ì • íŒŒì¼: my_cluster.yaml

**í¸ì§‘ ìœ„ì¹˜**: í”„ë¡œì íŠ¸ ë£¨íŠ¸
**í¸ì§‘ ë‚´ìš©**: í´ëŸ¬ìŠ¤í„° ë…¸ë“œ ì •ë³´, íŒŒí‹°ì…˜ ì„¤ì •

```yaml
# ============================================================
# í´ëŸ¬ìŠ¤í„° ê¸°ë³¸ ì •ë³´
# ============================================================
cluster_info:
  cluster_name: "SmartTwinCluster"          # í´ëŸ¬ìŠ¤í„° ì´ë¦„
  domain: "hpc.local"                       # ë„ë©”ì¸
  admin_email: "admin@hpc.local"            # ê´€ë¦¬ì ì´ë©”ì¼

# ============================================================
# ë…¸ë“œ êµ¬ì„± (í¸ì§‘ í•„ìš”!)
# ============================================================
nodes:
  controller:
    hostname: "gpu-master"                  # ì»¨íŠ¸ë¡¤ëŸ¬ í˜¸ìŠ¤íŠ¸ëª…
    ip_address: "192.168.122.90"            # ì»¨íŠ¸ë¡¤ëŸ¬ IP
    ssh_user: "koopark"                     # SSH ì‚¬ìš©ì
    ssh_key_path: "~/.ssh/id_rsa"           # SSH í‚¤ ê²½ë¡œ

  compute_nodes:
    - hostname: "node001"                   # ê³„ì‚° ë…¸ë“œ 1
      ip_address: "192.168.122.91"
      ssh_user: "koopark"
      hardware:
        cpus: 16
        memory_mb: 32768
        gpus: 1

    - hostname: "node002"                   # ê³„ì‚° ë…¸ë“œ 2
      ip_address: "192.168.122.92"
      ssh_user: "koopark"
      hardware:
        cpus: 16
        memory_mb: 32768
        gpus: 1

# ============================================================
# Slurm íŒŒí‹°ì…˜ ì„¤ì •
# ============================================================
slurm:
  partitions:
    - name: "compute"                       # CPU íŒŒí‹°ì…˜
      nodes: "node001,node002"
      default: true
      max_time: "24:00:00"

    - name: "gpu"                           # GPU íŒŒí‹°ì…˜
      nodes: "node001,node002"
      default: false
      max_time: "48:00:00"
```

**ì£¼ìš” í¸ì§‘ í•­ëª©**:
- `controller`: ë§ˆìŠ¤í„° ë…¸ë“œ IP, í˜¸ìŠ¤íŠ¸ëª…
- `compute_nodes`: ê³„ì‚° ë…¸ë“œ ëª©ë¡ (IP, CPU, ë©”ëª¨ë¦¬, GPU)
- `partitions`: Slurm íŒŒí‹°ì…˜ êµ¬ì„±

### 1.3 ì„¤ì¹˜ ëª…ë ¹ì–´

```bash
# 1. ì„¤ì • íŒŒì¼ í¸ì§‘
nano my_cluster.yaml

# 2. ìë™ ì„¤ì¹˜ ì‹¤í–‰ (14ë‹¨ê³„)
chmod +x setup_cluster_full.sh
./setup_cluster_full.sh
```

### 1.4 ì„¤ì¹˜ ë‹¨ê³„ (14ë‹¨ê³„)

`setup_cluster_full.sh`ê°€ ìë™ìœ¼ë¡œ ì‹¤í–‰í•˜ëŠ” ë‹¨ê³„:

| ë‹¨ê³„ | ë‚´ìš© | ìŠ¤í¬ë¦½íŠ¸ | ì„¤ì • íŒŒì¼ |
|------|------|----------|----------|
| **Step 1** | Python ê°€ìƒí™˜ê²½ ìƒì„± | ìë™ | - |
| **Step 2** | Python ê°€ìƒí™˜ê²½ í™œì„±í™” | ìë™ | - |
| **Step 3** | ì„¤ì • íŒŒì¼ ê²€ì¦ | `validate_config.py` | my_cluster.yaml |
| **Step 4** | SSH ì—°ê²° í…ŒìŠ¤íŠ¸ | `test_connection.py` | my_cluster.yaml |
| **Step 4.3** | **/etc/hosts ìë™ ì„¤ì •** | `complete_slurm_setup.py` | my_cluster.yaml |
| **Step 4.5** | RebootProgram ì„¤ì • | `setup_reboot_program.sh` | my_cluster.yaml |
| **Step 5** | Munge ì¸ì¦ ì„¤ì¹˜ | `install_munge_auto.sh` | - |
| **Step 6** | Slurm ì»¨íŠ¸ë¡¤ëŸ¬ ì„¤ì¹˜ | `install_slurm_cgroup_v2.sh` | - |
| **Step 6.1** | systemd ì„œë¹„ìŠ¤ ìƒì„± | `create_slurm_systemd_services.sh` | - |
| **Step 6.5** | Slurm Accounting ì„¤ì¹˜ | `install_slurm_accounting.sh` | - |
| **Step 7** | ê³„ì‚° ë…¸ë“œ Slurm ì„¤ì¹˜ | SSH ì›ê²© ì‹¤í–‰ | my_cluster.yaml |
| **Step 7.5** | ì›ê²© systemd ì„œë¹„ìŠ¤ ì„¤ì • | `setup_slurmd_service_remote.sh` | - |
| **Step 8** | Slurm ì„¤ì • íŒŒì¼ ìƒì„± | `configure_slurm_from_yaml.py` | my_cluster.yaml |
| **Step 9** | ì„¤ì • íŒŒì¼ ë°°í¬ | SSH ì›ê²© ë³µì‚¬ | - |
| **Step 10** | Slurm ì„œë¹„ìŠ¤ ì‹œì‘ | systemctl | - |
| **Step 11** | PATH ì˜êµ¬ ì„¤ì • | /etc/profile.d/slurm.sh | - |
| **Step 12** | MPI ì„¤ì¹˜ (ì„ íƒ) | `install_mpi.py` | - |
| **Step 13** | Apptainer ë™ê¸°í™” (ì„ íƒ) | `sync_apptainers_to_nodes.sh` | - |
| **Step 14** | Apptainer ë°°í¬ (ì„ íƒ) | `deploy_apptainers.sh` | - |

**Step 4.3 ìƒì„¸ ì„¤ëª…**:
- my_cluster.yamlì˜ ëª¨ë“  ë…¸ë“œ ì •ë³´ë¥¼ ì½ì–´ /etc/hosts íŒŒì¼ ìë™ ì—…ë°ì´íŠ¸
- SSH í‚¤ ìë™ ì„¤ì • (ì»¨íŠ¸ë¡¤ëŸ¬ â†’ ëª¨ë“  ë…¸ë“œ)
- ë°©í™”ë²½, SELinux, NTP, í•„ìˆ˜ íŒ¨í‚¤ì§€, í™˜ê²½ë³€ìˆ˜ ìë™ ì„¤ì •
- viz-node ì§€ì› (compute_nodes ì™¸ì— viz_nodes ì„¹ì…˜ë„ ì¸ì‹)
- ì¤‘ë³µ ë‹¨ê³„ ìë™ ê±´ë„ˆë›°ê¸° (Munge, slurm.conf, cgroup, NFSëŠ” í›„ì† ë‹¨ê³„ì—ì„œ ì²˜ë¦¬)

### 1.5 ì„¤ì¹˜ ê²°ê³¼ í™•ì¸

```bash
# Slurm ëª…ë ¹ì–´ í™•ì¸
sinfo              # ë…¸ë“œ ìƒíƒœ
squeue             # ì‘ì—… í
scontrol show nodes # ë…¸ë“œ ìƒì„¸ ì •ë³´

# ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
sudo systemctl status slurmctld  # ì»¨íŠ¸ë¡¤ëŸ¬
sudo systemctl status slurmd     # ê³„ì‚° ë…¸ë“œ (ê° ë…¸ë“œì—ì„œ)
```

**ì˜ˆìƒ ì¶œë ¥**:
```
PARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST
compute*     up 1-00:00:00      2   idle node[001-002]
gpu          up 2-00:00:00      2   idle node[001-002]
```

---

## ğŸ“ Phase 2: ì›¹ ì„œë¹„ìŠ¤ ì„¤ì¹˜

### 2.1 í•„ìš”í•œ íŒŒì¼

| íŒŒì¼ | ì—­í•  | í¸ì§‘ í•„ìš” |
|------|------|----------|
| **web_services_config.yaml** | ì›¹ ì„œë¹„ìŠ¤ ì„¤ì • | âœ… **í”„ë¡œë•ì…˜ë§Œ** |
| `setup_web_services.sh` | ìë™ ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ | âŒ í¸ì§‘ ë¶ˆí•„ìš” |
| `generate_env_files.py` | .env íŒŒì¼ ìƒì„± | âŒ ìë™ í˜¸ì¶œ |
| `install_dependencies.sh` | ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜ | âŒ ìë™ í˜¸ì¶œ |
| `start.sh` | ì„œë¹„ìŠ¤ ì‹œì‘ | âŒ í¸ì§‘ ë¶ˆí•„ìš” |
| `stop.sh` | ì„œë¹„ìŠ¤ ì¤‘ì§€ | âŒ í¸ì§‘ ë¶ˆí•„ìš” |

### 2.2 ì„¤ì • íŒŒì¼: web_services_config.yaml

**í¸ì§‘ ìœ„ì¹˜**: í”„ë¡œì íŠ¸ ë£¨íŠ¸
**í¸ì§‘ í•„ìš”**: DevelopmentëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©, Productionë§Œ í¸ì§‘

```yaml
# ============================================================
# í™˜ê²½ë³„ ì„¤ì •
# ============================================================
environments:
  development:
    domain: "localhost"                     # ê°œë°œ í™˜ê²½
    sso_enabled: false                      # SSO ë¹„í™œì„±í™”

  production:
    domain: "hpc.example.com"               # â† í”„ë¡œë•ì…˜ ë„ë©”ì¸ ë³€ê²½
    sso_enabled: true                       # SSO í™œì„±í™”

# ============================================================
# ì„œë¹„ìŠ¤ë³„ ì„¤ì • (11ê°œ ì„œë¹„ìŠ¤)
# ============================================================
services:
  # Auth Portal Backend (4430)
  auth_portal_backend:
    environment:
      development:
        JWT_SECRET_KEY: "dev-jwt-secret-please-change"

      production:
        JWT_SECRET_KEY: "CHANGE-THIS-IN-PRODUCTION"  # â† ë³€ê²½ í•„ìš”
        SAML_IDP_METADATA_URL: "https://your-idp.com/metadata"  # â† IdP URL

  # Dashboard Backend (5010)
  dashboard_backend:
    environment:
      development:
        SLURM_CONTROL_NODE: "gpu-master"    # â† my_cluster.yamlê³¼ ì¼ì¹˜
        SLURM_PARTITION_CPU: "compute"      # â† my_cluster.yamlê³¼ ì¼ì¹˜
        SLURM_PARTITION_GPU: "gpu"          # â† my_cluster.yamlê³¼ ì¼ì¹˜

      production:
        SLURM_CONTROL_NODE: "gpu-master"    # â† í”„ë¡œë•ì…˜ ë§ˆìŠ¤í„° ë…¸ë“œ
        SLURM_PARTITION_CPU: "compute"
        SLURM_PARTITION_GPU: "gpu"

  # ... (ë‚˜ë¨¸ì§€ 9ê°œ ì„œë¹„ìŠ¤ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©)
```

**ì£¼ìš” í¸ì§‘ í•­ëª© (í”„ë¡œë•ì…˜ ë°°í¬ ì‹œ)**:
- `environments.production.domain`: ì‹¤ì œ ë„ë©”ì¸
- `JWT_SECRET_KEY`: ë³´ì•ˆ í‚¤ ë³€ê²½
- `SAML_IDP_METADATA_URL`: SSO IdP URL
- `SLURM_CONTROL_NODE`: my_cluster.yamlì˜ controllerì™€ ì¼ì¹˜

**Development í™˜ê²½ì€ ê¸°ë³¸ê°’ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥!**

### 2.3 ì„¤ì¹˜ ëª…ë ¹ì–´

**ëª¨ë“  ëª…ë ¹ì–´ëŠ” í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤!**

```bash
# ============================================================
# Phase 0-2: ì´ˆê¸° ì„¤ì •
# ============================================================

# 1. í˜„ì¬ ìƒíƒœ ìˆ˜ì§‘
./collect_current_state.sh

# 2. ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
./create_directory_structure.sh

# 3. Python ì˜ì¡´ì„± ì„¤ì¹˜
pip3 install pyyaml jinja2

# ============================================================
# Phase 3: í™˜ê²½ ë³€ìˆ˜ ìƒì„±
# ============================================================

# 4. ì„¤ì • íŒŒì¼ í¸ì§‘ (í”„ë¡œë•ì…˜ë§Œ)
# nano web_services_config.yaml

# 5. í™˜ê²½ ë³€ìˆ˜ ìƒì„± (11ê°œ .env íŒŒì¼ ìë™ ìƒì„±)
./generate_env_files.sh development

# ============================================================
# Phase 4: ONE-COMMAND ì„¤ì¹˜ + ìë™ ì‹œì‘
# ============================================================

# 6. ì™„ì „ ìë™ ì„¤ì¹˜ (ì˜ì¡´ì„± + ì„œë¹„ìŠ¤ ì‹œì‘)
./setup_web_services.sh development --auto-start

# ë˜ëŠ” ìˆ˜ë™ ì‹œì‘ ë°©ì‹:
# ./setup_web_services.sh development
# ./start.sh

# ============================================================
# Phase 5: í™•ì¸
# ============================================================

# 7. í—¬ìŠ¤ ì²´í¬
./health_check.sh
```

### 2.4 ì„¤ì¹˜ ë‹¨ê³„ ìƒì„¸

#### Phase 0-2: ì´ˆê¸° ì„¤ì • (3ë‹¨ê³„)

| ë‹¨ê³„ | ìŠ¤í¬ë¦½íŠ¸ | ê¸°ëŠ¥ | ì†Œìš” ì‹œê°„ |
|------|----------|------|----------|
| 1 | `collect_current_state.sh` | í˜„ì¬ ì‹œìŠ¤í…œ ìƒíƒœ ìˆ˜ì§‘ | 10ì´ˆ |
| 2 | `create_directory_structure.sh` | ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± | 5ì´ˆ |
| 3 | `pip3 install pyyaml jinja2` | Python ì˜ì¡´ì„± ì„¤ì¹˜ | 30ì´ˆ |

#### Phase 3: í™˜ê²½ ë³€ìˆ˜ ìƒì„± (1ë‹¨ê³„)

| ìŠ¤í¬ë¦½íŠ¸ | ì…ë ¥ | ì¶œë ¥ | ê¸°ëŠ¥ |
|----------|------|------|------|
| `generate_env_files.sh` | web_services_config.yaml | 11ê°œ .env íŒŒì¼ | Jinja2 í…œí”Œë¦¿ìœ¼ë¡œ í™˜ê²½ ë³€ìˆ˜ ìƒì„± |

**ë‚´ë¶€ í˜¸ì¶œ**: `web_services/scripts/generate_env_files.py`

**ìƒì„±ë˜ëŠ” íŒŒì¼**:
```
dashboard/auth_portal_4430/.env
dashboard/auth_portal_4431/.env
dashboard/frontend_3010/.env
dashboard/backend_5010/.env
dashboard/websocket_5011/.env
dashboard/kooCAEWeb_5173/.env
dashboard/kooCAEWebServer_5000/.env
dashboard/kooCAEWebAutomationServer_5001/.env
dashboard/vnc_service_8002/.env
dashboard/prometheus_9090/.env
dashboard/node_exporter_9100/.env
```

#### Phase 4: ONE-COMMAND ì„¤ì¹˜ (setup_web_services.sh)

**ë‚´ë¶€ í˜¸ì¶œ**: `web_services/scripts/setup_web_services.sh`

`setup_web_services.sh`ê°€ ìë™ìœ¼ë¡œ ìˆ˜í–‰í•˜ëŠ” ì‘ì—…:

| ìˆœì„œ | ì‘ì—… | ìŠ¤í¬ë¦½íŠ¸ | ì†Œìš” ì‹œê°„ |
|------|------|----------|----------|
| 1 | ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜ | `install_dependencies.sh` | 3-5ë¶„ |
| 2 | .env íŒŒì¼ ë°±ì—… | ë‚´ì¥ | 10ì´ˆ |
| 3 | Python venv ìƒì„± (5ê°œ) | ìë™ | 2-3ë¶„ |
| 4 | Node.js npm install (4ê°œ) | ìë™ | 3-5ë¶„ |
| 5 | ì„œë¹„ìŠ¤ ìë™ ì‹œì‘ (ì˜µì…˜) | `./start.sh` | 30ì´ˆ |
| 6 | í—¬ìŠ¤ ì²´í¬ | `health_check.sh` | 10ì´ˆ |

**ìë™ìœ¼ë¡œ ì„¤ì¹˜ë˜ëŠ” ì˜ì¡´ì„±**:
- âœ… Python3, Node.js, npm
- âœ… Redis (ìë™ ì„¤ì¹˜ ë° ì‹œì‘)
- âœ… Nginx (ì„¤ì • íŒŒì¼ ìƒì„±)
- âœ… Python venv (ê° ì„œë¹„ìŠ¤ë³„)
- âœ… Python íŒ¨í‚¤ì§€ (requirements.txt)
- âœ… Node.js íŒ¨í‚¤ì§€ (npm install)

### 2.5 ì„¤ì¹˜ ê²°ê³¼ í™•ì¸

```bash
# í—¬ìŠ¤ ì²´í¬
./health_check.sh
```

**ì˜ˆìƒ ì¶œë ¥**:
```
ğŸ” ì›¹ ì„œë¹„ìŠ¤ í—¬ìŠ¤ ì²´í¬
====================
âœ… Dashboard Frontend             (3010) - HEALTHY
âœ… Auth Portal Backend            (4430) - HEALTHY
âœ… Auth Portal Frontend           (4431) - HEALTHY
âœ… Dashboard Backend              (5010) - HEALTHY
âœ… Dashboard WebSocket            (5011) - HEALTHY
âœ… CAE Frontend                   (5173) - HEALTHY
âœ… CAE Backend                    (5000) - HEALTHY
âœ… CAE Automation                 (5001) - HEALTHY
âœ… VNC Service                    (8002) - HEALTHY
âœ… Prometheus                     (9090) - HEALTHY
âœ… Node Exporter                  (9100) - HEALTHY

âœ… ì „ì²´: 11/11 ì„œë¹„ìŠ¤ ì •ìƒ
```

**ë¸Œë¼ìš°ì € ì ‘ì†**: http://localhost:4431/

---

## ğŸ”„ ì „ì²´ ì„¤ì¹˜ ìˆœì„œ (ìš”ì•½)

### ì‹ ê·œ ì„œë²„ ì™„ì „ ì„¤ì¹˜

```bash
# ============================================================
# Part 1: Slurm í´ëŸ¬ìŠ¤í„° ì„¤ì¹˜ (30-45ë¶„)
# ============================================================

# 1. ì„¤ì • íŒŒì¼ í¸ì§‘
nano my_cluster.yaml

# 2. Slurm í´ëŸ¬ìŠ¤í„° ìë™ ì„¤ì¹˜
./setup_cluster_full.sh

# 3. Slurm í™•ì¸
sinfo

# ============================================================
# Part 2: ì›¹ ì„œë¹„ìŠ¤ ì„¤ì¹˜ (10-15ë¶„)
# ============================================================

# 4. ì´ˆê¸° ì„¤ì •
./collect_current_state.sh
./create_directory_structure.sh
pip3 install pyyaml jinja2

# 5. í™˜ê²½ ë³€ìˆ˜ ìƒì„±
./generate_env_files.sh development

# 6. ì›¹ ì„œë¹„ìŠ¤ ONE-COMMAND ì„¤ì¹˜
./setup_web_services.sh development --auto-start

# 7. ì›¹ ì„œë¹„ìŠ¤ í™•ì¸
./health_check.sh

# ============================================================
# ì™„ë£Œ!
# ============================================================
# - Slurm í´ëŸ¬ìŠ¤í„°: http://localhost:9090 (Prometheus)
# - ì›¹ ëŒ€ì‹œë³´ë“œ: http://localhost:4431/
```

**ì´ ì†Œìš” ì‹œê°„**: 40-60ë¶„
**ì‚¬ìš©ì í¸ì§‘ íŒŒì¼**: 2ê°œ (my_cluster.yaml, web_services_config.yaml)

---

## ğŸ“Š ì„¤ì • íŒŒì¼ ë§¤í•‘

### my_cluster.yaml â†’ Slurm ì„¤ì •

| my_cluster.yaml | ìƒì„±ë˜ëŠ” Slurm ì„¤ì • |
|-----------------|---------------------|
| `cluster_info.cluster_name` | `/usr/local/slurm/etc/slurm.conf`: ClusterName |
| `nodes.controller` | `/usr/local/slurm/etc/slurm.conf`: SlurmctldHost |
| `nodes.compute_nodes` | `/usr/local/slurm/etc/slurm.conf`: NodeName |
| `slurm.partitions` | `/usr/local/slurm/etc/slurm.conf`: PartitionName |

**ìƒì„± ìŠ¤í¬ë¦½íŠ¸**: `configure_slurm_from_yaml.py`

### web_services_config.yaml â†’ .env íŒŒì¼

| web_services_config.yaml | ìƒì„±ë˜ëŠ” .env íŒŒì¼ |
|--------------------------|-------------------|
| `environments.development` | ê° ì„œë¹„ìŠ¤ì˜ .env (development ì„¹ì…˜) |
| `environments.production` | ê° ì„œë¹„ìŠ¤ì˜ .env (production ì„¹ì…˜) |
| `services.dashboard_backend.SLURM_CONTROL_NODE` | `dashboard/backend_5010/.env`: SLURM_CONTROL_NODE |
| `services.auth_portal_backend.JWT_SECRET_KEY` | `dashboard/auth_portal_4430/.env`: JWT_SECRET_KEY |

**ìƒì„± ìŠ¤í¬ë¦½íŠ¸**: `generate_env_files.py`

### my_cluster.yaml â†” web_services_config.yaml ì—°ê³„

**ë°˜ë“œì‹œ ì¼ì¹˜í•´ì•¼ í•˜ëŠ” ê°’**:

| í•­ëª© | my_cluster.yaml | web_services_config.yaml |
|------|-----------------|--------------------------|
| ë§ˆìŠ¤í„° ë…¸ë“œ | `nodes.controller.hostname` | `services.dashboard_backend.SLURM_CONTROL_NODE` |
| CPU íŒŒí‹°ì…˜ | `slurm.partitions[0].name` | `services.dashboard_backend.SLURM_PARTITION_CPU` |
| GPU íŒŒí‹°ì…˜ | `slurm.partitions[1].name` | `services.dashboard_backend.SLURM_PARTITION_GPU` |

**ì˜ˆì‹œ**:
```yaml
# my_cluster.yaml
nodes:
  controller:
    hostname: "gpu-master"  # â† ì´ ê°’ì„

slurm:
  partitions:
    - name: "compute"       # â† ì´ ê°’ì„
    - name: "gpu"           # â† ì´ ê°’ì„
```

```yaml
# web_services_config.yaml
services:
  dashboard_backend:
    environment:
      development:
        SLURM_CONTROL_NODE: "gpu-master"      # â† ì—¬ê¸° ë™ì¼
        SLURM_PARTITION_CPU: "compute"        # â† ì—¬ê¸° ë™ì¼
        SLURM_PARTITION_GPU: "gpu"            # â† ì—¬ê¸° ë™ì¼
```

---

## ğŸ”§ ì£¼ìš” ëª…ë ¹ì–´ ì°¸ì¡°

### Slurm ê´€ë ¨

```bash
# ì„œë¹„ìŠ¤ ì œì–´
sudo systemctl start slurmctld    # ì»¨íŠ¸ë¡¤ëŸ¬ ì‹œì‘
sudo systemctl stop slurmctld     # ì»¨íŠ¸ë¡¤ëŸ¬ ì¤‘ì§€
sudo systemctl status slurmctld   # ì»¨íŠ¸ë¡¤ëŸ¬ ìƒíƒœ

./start_slurm_cluster.sh          # ì „ì²´ í´ëŸ¬ìŠ¤í„° ì‹œì‘
./stop_slurm_cluster.sh           # ì „ì²´ í´ëŸ¬ìŠ¤í„° ì¤‘ì§€

# ìƒíƒœ í™•ì¸
sinfo                             # ë…¸ë“œ ìƒíƒœ
sinfo -N                          # ë…¸ë“œë³„ ìƒì„¸ ì •ë³´
squeue                            # ì‘ì—… í
scontrol show nodes               # ë…¸ë“œ ìƒì„¸ ì •ë³´
scontrol show partition           # íŒŒí‹°ì…˜ ì •ë³´

# ì‘ì—… ì œì¶œ
sbatch test.sh                    # ë°°ì¹˜ ì‘ì—… ì œì¶œ
srun hostname                     # ëŒ€í™”í˜• ì‘ì—… ì‹¤í–‰
scancel 123                       # ì‘ì—… ì·¨ì†Œ

# ì„¤ì • ì¬ë¡œë“œ
sudo scontrol reconfigure         # ì„¤ì • ë‹¤ì‹œ ì½ê¸°
```

### ì›¹ ì„œë¹„ìŠ¤ ê´€ë ¨

```bash
# ì„œë¹„ìŠ¤ ì œì–´
./start.sh                        # ì „ì²´ ì„œë¹„ìŠ¤ ì‹œì‘
./stop.sh                         # ì „ì²´ ì„œë¹„ìŠ¤ ì¤‘ì§€

# ìƒíƒœ í™•ì¸
./health_check.sh                 # í—¬ìŠ¤ ì²´í¬

# ì„¤ì • ì¬ìƒì„±
./generate_env_files.sh development          # .env ì¬ìƒì„±
./setup_web_services.sh development          # ì¬ì„¤ì¹˜

# í™˜ê²½ ì „í™˜
./web_services/scripts/reconfigure_web_services.sh production  # Dev â†’ Prod
./web_services/scripts/reconfigure_web_services.sh development # Prod â†’ Dev

# ë¡¤ë°±
./web_services/scripts/rollback.sh --latest  # ìµœì‹  ë°±ì—…ìœ¼ë¡œ ë³µêµ¬

# Nginx ì„¤ì •
./web_services/scripts/setup_nginx.sh development   # Nginx ì„¤ì • ìƒì„±
./web_services/scripts/setup_letsencrypt.sh <domain> <email>  # SSL ì¸ì¦ì„œ
```

---

## ğŸ¯ í™˜ê²½ë³„ ì°¨ì´ì 

### Development í™˜ê²½

```bash
# í™˜ê²½ ë³€ìˆ˜ ìƒì„±
./generate_env_files.sh development

# ì›¹ ì„œë¹„ìŠ¤ ì„¤ì¹˜
./setup_web_services.sh development --auto-start
```

**íŠ¹ì§•**:
- HTTP (í¬íŠ¸ 80)
- SSO ë¹„í™œì„±í™”
- MOCK_MODE=true (Slurm ì—†ì´ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥)
- localhost ë„ë©”ì¸
- ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™”

**ì ‘ì† URL**: http://localhost:4431/

### Production í™˜ê²½

```bash
# 1. ì„¤ì • íŒŒì¼ í¸ì§‘
nano web_services_config.yaml
# â†’ domain: "hpc.example.com"
# â†’ JWT_SECRET_KEY ë³€ê²½
# â†’ SAML_IDP_METADATA_URL ì„¤ì •

# 2. í™˜ê²½ ë³€ìˆ˜ ìƒì„±
./generate_env_files.sh production

# 3. SSL ì¸ì¦ì„œ ì„¤ì •
./web_services/scripts/setup_letsencrypt.sh hpc.example.com admin@example.com

# 4. Nginx ì„¤ì •
./web_services/scripts/setup_nginx.sh production

# 5. ì›¹ ì„œë¹„ìŠ¤ ì„¤ì¹˜
./setup_web_services.sh production --auto-start

# 6. ë°©í™”ë²½ ì„¤ì •
sudo ufw allow 80/tcp
sudo ufw allow 443/tcp
```

**íŠ¹ì§•**:
- HTTPS (í¬íŠ¸ 443)
- SSO í™œì„±í™”
- MOCK_MODE=false (ì‹¤ì œ Slurm ì‚¬ìš©)
- ì‹¤ì œ ë„ë©”ì¸
- í”„ë¡œë•ì…˜ ëª¨ë“œ

**ì ‘ì† URL**: https://hpc.example.com/

---

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

### Slurm ê´€ë ¨
- [README.md](README.md) - Slurm ìë™ ì„¤ì¹˜ ê°œìš”
- `CGROUP_V2_INSTALLATION_GUIDE.md` - cgroup v2 ì„¤ì¹˜ ê°€ì´ë“œ
- `dashboard/SLURM_INTEGRATION_GUIDE.md` - Slurm í†µí•© ê°€ì´ë“œ

### ì›¹ ì„œë¹„ìŠ¤ ê´€ë ¨
- [QUICKSTART_WEB.md](QUICKSTART_WEB.md) - 5ë¶„ ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ
- [AUTOMATION_SUMMARY.md](AUTOMATION_SUMMARY.md) - ìë™í™” ê°œì„  ìš”ì•½
- [WEB_SLURM_INTEGRATION.md](WEB_SLURM_INTEGRATION.md) - ì›¹/Slurm ì—°ë™ ê°€ì´ë“œ
- [DEPLOYMENT.md](DEPLOYMENT.md) - ì›¹ ì„œë¹„ìŠ¤ ë°°í¬ ê°€ì´ë“œ
- [OPERATIONS.md](OPERATIONS.md) - ì›¹ ì„œë¹„ìŠ¤ ìš´ì˜ ê°€ì´ë“œ
- [TROUBLESHOOTING.md](TROUBLESHOOTING.md) - ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

---

## ğŸ’¡ í•µì‹¬ ìš”ì•½

### ì‚¬ìš©ìê°€ í•´ì•¼ í•  ì¼

| ë‹¨ê³„ | ì‘ì—… | íŒŒì¼ |
|------|------|------|
| 1 | Slurm ì„¤ì • í¸ì§‘ | `my_cluster.yaml` |
| 2 | Slurm ì„¤ì¹˜ ì‹¤í–‰ | `./setup_cluster_full.sh` |
| 3 | ì›¹ ì„œë¹„ìŠ¤ ì„¤ì • í¸ì§‘ (í”„ë¡œë•ì…˜ë§Œ) | `web_services_config.yaml` |
| 4 | ì›¹ ì„œë¹„ìŠ¤ ì„¤ì¹˜ ì‹¤í–‰ | `./setup_web_services.sh development --auto-start` |

**ì´ í¸ì§‘ íŒŒì¼**: 2ê°œ (my_cluster.yaml, web_services_config.yaml)
**ì´ ì‹¤í–‰ ëª…ë ¹**: 6ê°œ (ì´ˆê¸° ì„¤ì • 3ê°œ + Slurm 1ê°œ + ì›¹ ì„œë¹„ìŠ¤ 2ê°œ)

**ëª¨ë“  ëª…ë ¹ì€ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì‹¤í–‰!**

### ìë™ìœ¼ë¡œ ì²˜ë¦¬ë˜ëŠ” ê²ƒ

**Slurm í´ëŸ¬ìŠ¤í„°**:
- âœ… Munge ì¸ì¦ ì„¤ì¹˜
- âœ… Slurm ì»´íŒŒì¼ ë° ì„¤ì¹˜
- âœ… cgroup v2 ì„¤ì •
- âœ… slurm.conf ìë™ ìƒì„±
- âœ… ê³„ì‚° ë…¸ë“œ ì›ê²© ì„¤ì¹˜
- âœ… systemd ì„œë¹„ìŠ¤ ì„¤ì •
- âœ… Accounting (slurmdbd) ì„¤ì¹˜
- âœ… PATH ì˜êµ¬ ì„¤ì •

**ì›¹ ì„œë¹„ìŠ¤**:
- âœ… ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜ (Python3, Node.js, Redis)
- âœ… Python venv ìƒì„± (5ê°œ ì„œë¹„ìŠ¤)
- âœ… Node.js npm install (4ê°œ ì„œë¹„ìŠ¤)
- âœ… .env íŒŒì¼ ìƒì„± (11ê°œ ì„œë¹„ìŠ¤)
- âœ… ì„œë¹„ìŠ¤ ìë™ ì‹œì‘ (--auto-start ì˜µì…˜)
- âœ… Nginx ì„¤ì • ìƒì„±
- âœ… í—¬ìŠ¤ ì²´í¬

---

**ì‘ì„±ì¼**: 2025-10-20
**ë²„ì „**: 1.0
**ê²°ë¡ **: ì„¤ì • íŒŒì¼ 2ê°œë§Œ í¸ì§‘í•˜ë©´, ë‚˜ë¨¸ì§€ëŠ” **ì™„ì „ ìë™í™”**!
