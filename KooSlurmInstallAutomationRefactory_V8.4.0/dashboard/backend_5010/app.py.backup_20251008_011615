"""
Slurm Cluster Dashboard Backend API (Mock Mode ì§€ì›)
ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§, ì‘ì—… ê´€ë¦¬, 3D ì‹œê°í™” ì§€ì›
ğŸ†• Slurm í†µí•© ê¸°ëŠ¥ ì¶”ê°€
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import subprocess
import json
import os
from datetime import datetime
import random
import time
import tempfile

# Slurm ì„¤ì • ê´€ë¦¬ ëª¨ë“ˆ ì„í¬íŠ¸
from slurm_config_manager import (
    slurm_config,
    create_qos,
    update_partitions,
    reconfigure_slurm,
    apply_full_configuration
)

# Mock ëª¨ë“œ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ë¡œ ì œì–´)
MOCK_MODE = os.getenv('MOCK_MODE', 'true').lower() == 'true'

if MOCK_MODE:
    print("âš ï¸  Running in MOCK MODE - No actual Slurm commands will be executed")
else:
    print("âœ… Running in PRODUCTION MODE - Real Slurm commands will be executed")

# Storage ê´€ë¦¬ ìœ í‹¸ë¦¬í‹° ì„í¬íŠ¸ (Mock ëª¨ë“œì—ì„œëŠ” ì„ íƒì )
try:
    from storage_utils import (
        get_disk_usage,
        format_size,
        get_file_info,
        list_directory,
        count_files_recursive,
        get_directory_size,
        safe_path_join,
        is_path_accessible,
        search_files,
        get_slurm_nodes as get_storage_nodes,
        run_remote_command
    )
except ImportError as e:
    if not MOCK_MODE:
        print(f"âš ï¸  storage_utils import error: {e}")
    # Mock ëª¨ë“œì—ì„œëŠ” ë¬´ì‹œ
    pass

# ë¹„ë™ê¸° Storage ê´€ë¦¬ ìœ í‹¸ë¦¬í‹° ì„í¬íŠ¸ (Mock ëª¨ë“œì—ì„œëŠ” ì„ íƒì )
try:
    from storage_utils_async import (
        get_all_nodes_scratch_info_sync,
        get_scratch_storage_stats_sync,
        get_data_storage_stats_cached,
        clear_cache
    )
except ImportError as e:
    if not MOCK_MODE:
        print(f"âš ï¸  storage_utils_async import error: {e}")
    # Mock ëª¨ë“œì—ì„œëŠ” ë¬´ì‹œ
    pass

# v1.3.0 ì‹ ê·œ ê¸°ëŠ¥ Blueprint ì„í¬íŠ¸
from alerts_api import alerts_bp
from preview_api import preview_bp
from search_api import search_bp
from directory_api import directory_bp

# v3.0 ì‹ ê·œ ê¸°ëŠ¥ Blueprint ì„í¬íŠ¸
from notifications_api import notifications_bp
from prometheus_api import prometheus_bp
from templates_api import templates_bp

app = Flask(__name__)
CORS(app)

# v1.3.0 ì‹ ê·œ ê¸°ëŠ¥ Blueprint ë“±ë¡ (ì„ íƒì )
try:
    app.register_blueprint(alerts_bp)
    app.register_blueprint(preview_bp)
    app.register_blueprint(search_bp)
    app.register_blueprint(directory_bp)
except NameError:
    if not MOCK_MODE:
        print("âš ï¸  Some blueprints not available")
    pass

# v3.0 ì‹ ê·œ ê¸°ëŠ¥ Blueprint ë“±ë¡
app.register_blueprint(notifications_bp)
app.register_blueprint(prometheus_bp)
app.register_blueprint(templates_bp)

# Mock ë°ì´í„° ì €ì¥ì†Œ
mock_config = {
    'groups': [],
    'partitions': [],
    'qos_list': [],
    'jobs': [],
    'job_counter': 10000
}

@app.route('/api/health', methods=['GET'])
def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return jsonify({
        'status': 'healthy',
        'mode': 'mock' if MOCK_MODE else 'production',
        'timestamp': datetime.now().isoformat()
    })

# ==================== ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ API ====================

@app.route('/api/metrics/realtime', methods=['GET'])
def get_realtime_metrics():
    """ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
    try:
        if MOCK_MODE:
            # Mock ë°ì´í„° ìƒì„±
            metrics = {
                'timestamp': datetime.now().isoformat(),
                'cpuUsage': 45 + random.random() * 30,
                'memoryUsage': 60 + random.random() * 20,
                'gpuUsage': 30 + random.random() * 40,
                'activeJobs': random.randint(50, 80),
                'pendingJobs': random.randint(10, 30),
                'totalNodes': 370,
                'idleNodes': random.randint(100, 150),
                'allocatedNodes': random.randint(200, 250),
                'downNodes': random.randint(0, 5),
            }
            
            return jsonify({
                'success': True,
                'mode': 'mock',
                'data': metrics
            })
        else:
            # Production: ì‹¤ì œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            metrics = collect_real_metrics()
            return jsonify({
                'success': True,
                'mode': 'production',
                'data': metrics
            })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/slurm/nodes/<hostname>', methods=['GET'])
def get_node_detail(hostname):
    """íŠ¹ì • ë…¸ë“œì˜ ìƒì„¸ ì •ë³´"""
    try:
        if MOCK_MODE:
            return jsonify({
                'success': False,
                'mode': 'mock',
                'message': 'Node details only available in Production mode'
            }), 400
        
        from slurm_utils import get_node_details
        
        details = get_node_details(hostname)
        
        if not details:
            return jsonify({
                'success': False,
                'error': f'Node {hostname} not found'
            }), 404
        
        return jsonify({
            'success': True,
            'mode': 'production',
            'data': details
        })
        
    except Exception as e:
        print(f"âŒ Error in get_node_detail: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/slurm/sync-nodes', methods=['POST'])
def sync_nodes_to_dashboard():
    """
    ì‹¤ì œ Slurm ë…¸ë“œë¥¼ ëŒ€ì‹œë³´ë“œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    """
    try:
        if MOCK_MODE:
            return jsonify({
                'success': False,
                'mode': 'mock',
                'message': 'Node sync only available in Production mode'
            }), 400
        
        from slurm_utils import get_slurm_nodes, get_partitions
        
        nodes = get_slurm_nodes()
        partitions = get_partitions()
        
        # íŒŒí‹°ì…˜ì„ ê·¸ë£¹ìœ¼ë¡œ ë³€í™˜
        groups = []
        for idx, partition in enumerate(partitions, start=1):
            partition_nodes = [
                n for n in nodes 
                if n.get('partition') == partition['name']
            ]
            
            # ë…¸ë“œ ID ë° ê·¸ë£¹ ID ì„¤ì •
            for node in partition_nodes:
                node['id'] = f"{partition['name']}-{node['hostname']}"
                node['groupId'] = idx
            
            total_cores = sum(n['cores'] for n in partition_nodes)
            
            groups.append({
                'id': idx,
                'name': partition['name'],
                'description': f'Partition: {partition["name"]}',
                'color': ['#3b82f6', '#10b981', '#f59e0b', '#ef4444', '#8b5cf6', '#ec4899'][idx % 6],
                'qosName': f'{partition["name"]}_qos',
                'partitionName': partition['name'],
                'allowedCoreSizes': [128, 256, 512, 1024],
                'nodeCount': len(partition_nodes),
                'totalCores': total_cores,
                'nodes': partition_nodes
            })
        
        total_nodes = len(nodes)
        total_cores = sum(n['cores'] for n in nodes)
        
        dashboard_config = {
            'clusterName': 'Production Cluster',
            'controllerIp': '192.168.1.1',
            'totalNodes': total_nodes,
            'totalCores': total_cores,
            'groups': groups
        }
        
        return jsonify({
            'success': True,
            'mode': 'production',
            'message': f'Synced {total_nodes} nodes from Slurm',
            'data': dashboard_config
        })
        
    except Exception as e:
        print(f"âŒ Error in sync_nodes_to_dashboard: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

def collect_real_metrics():
    """ì‹¤ì œ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (ê°œì„ ë¨)"""
    try:
        # sinfoë¡œ ë…¸ë“œ ìƒíƒœ íŒŒì•…
        result = subprocess.run(
            ['sinfo', '-h', '-o', '%T'],
            capture_output=True,
            text=True,
            check=True,
            timeout=5
        )
        
        node_states = [s.strip() for s in result.stdout.strip().split('\n') if s.strip()]
        total_nodes = len(node_states)
        idle_nodes = sum(1 for s in node_states if 'idle' in s.lower())
        allocated_nodes = sum(1 for s in node_states if 'alloc' in s.lower() or 'mix' in s.lower())
        down_nodes = sum(1 for s in node_states if 'down' in s.lower() or 'drain' in s.lower())
        
        # squeueë¡œ ì‘ì—… ìˆ˜ íŒŒì•…
        result = subprocess.run(
            ['squeue', '-h', '-o', '%T'],
            capture_output=True,
            text=True,
            check=True,
            timeout=5
        )
        
        job_states = [s.strip() for s in result.stdout.strip().split('\n') if s.strip()]
        active_jobs = sum(1 for s in job_states if s == 'RUNNING')
        pending_jobs = sum(1 for s in job_states if s == 'PENDING')
        
        # CPU ì‚¬ìš©ë¥  ê³„ì‚° (allocated + mixed ë…¸ë“œ ë¹„ìœ¨)
        cpu_usage = (allocated_nodes / total_nodes * 100) if total_nodes > 0 else 0
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ê³„ì‚° (ê°„ë‹¨í•œ ì¶”ì •)
        memory_usage = cpu_usage * 0.9  # CPU ì‚¬ìš©ë¥ ê³¼ ë¹„ë¡€í•œë‹¤ê³  ê°€ì •
        
        # GPU ì‚¬ìš©ë¥  (sinfoì—ì„œ GRES ì •ë³´ë¡œ í™•ì¸ ê°€ëŠ¥, ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ì¶”ì •)
        gpu_usage = cpu_usage * 0.7 if allocated_nodes > 0 else 0
        
        print(f"ğŸ“Š Real Metrics: Nodes={total_nodes}, Jobs={active_jobs}/{pending_jobs}, CPU={cpu_usage:.1f}%")
        
        return {
            'timestamp': datetime.now().isoformat(),
            'cpuUsage': round(cpu_usage, 2),
            'memoryUsage': round(memory_usage, 2),
            'gpuUsage': round(gpu_usage, 2),
            'activeJobs': active_jobs,
            'pendingJobs': pending_jobs,
            'totalNodes': total_nodes,
            'idleNodes': idle_nodes,
            'allocatedNodes': allocated_nodes,
            'downNodes': down_nodes,
        }
    except subprocess.TimeoutExpired:
        print("âš ï¸  Slurm command timeout")
        raise Exception("Slurm command timeout - check if slurmctld is running")
    except subprocess.CalledProcessError as e:
        print(f"âš ï¸  Slurm command failed: {e}")
        raise Exception(f"Slurm command failed: {e.stderr if e.stderr else str(e)}")
    except Exception as e:
        print(f"âš ï¸  Error collecting metrics: {e}")
        raise

# ==================== ì‘ì—… ê´€ë¦¬ API ====================

@app.route('/api/slurm/jobs', methods=['GET'])
def get_slurm_jobs():
    """ì‘ì—… ëª©ë¡ ì¡°íšŒ (Mock ëª¨ë“œ ì§€ì›)"""
    try:
        if MOCK_MODE:
            # Mock ì‘ì—… ë°ì´í„° ìƒì„±
            states = ['RUNNING', 'PENDING', 'COMPLETED', 'FAILED']
            users = ['user01', 'user02', 'user03', 'admin', 'researcher']
            partitions = ['group1', 'group2', 'group3', 'gpu', 'debug']
            
            mock_jobs = [
                {
                    'jobId': str(10000 + i),
                    'partition': random.choice(partitions),
                    'jobName': f'job_{i}_{random.choice(["simulation", "training", "analysis"])}',
                    'userId': random.choice(users),
                    'state': random.choice(states),
                    'nodes': random.randint(1, 10),
                    'cpus': random.choice([128, 256, 512, 1024]),
                    'memory': f'{random.randint(16, 64)}GB',
                    'startTime': datetime.now().isoformat(),
                    'runTime': f'{random.randint(0, 23):02d}:{random.randint(0, 59):02d}:{random.randint(0, 59):02d}',
                    'priority': random.randint(100, 1000),
                    'account': 'research',
                    'qos': f'qos_{random.randint(1, 3)}'
                }
                for i in range(20)
            ]
            
            return jsonify({
                'success': True,
                'mode': 'mock',
                'jobs': mock_jobs,
                'count': len(mock_jobs),
                'timestamp': datetime.now().isoformat()
            })
        else:
            # Production: ì‹¤ì œ squeue ëª…ë ¹ ì‹¤í–‰ (ê°œì„ ë¨)
            result = subprocess.run(
                ['squeue', '-h', '-o', '%i|%P|%j|%u|%T|%D|%C|%m|%S|%M|%Q'],
                capture_output=True,
                text=True,
                check=True,
                timeout=5
            )
            
            jobs = []
            for line in result.stdout.strip().split('\n'):
                if not line:
                    continue
                    
                parts = line.split('|')
                if len(parts) >= 7:
                    try:
                        jobs.append({
                            'jobId': parts[0].strip(),
                            'partition': parts[1].strip(),
                            'jobName': parts[2].strip(),
                            'userId': parts[3].strip(),
                            'state': parts[4].strip(),
                            'nodes': int(parts[5].strip()),
                            'cpus': int(parts[6].strip()),
                            'memory': parts[7].strip() if len(parts) > 7 else 'N/A',
                            'startTime': parts[8].strip() if len(parts) > 8 else None,
                            'runTime': parts[9].strip() if len(parts) > 9 else '00:00:00',
                            'qos': parts[10].strip() if len(parts) > 10 else 'normal',
                            'priority': random.randint(100, 1000),
                            'account': 'research',
                        })
                    except (ValueError, IndexError) as e:
                        print(f"âš ï¸  Skipping malformed job line: {line}, error: {e}")
                        continue
            
            print(f"ğŸ“‹ Loaded {len(jobs)} jobs from Slurm")
            
            return jsonify({
                'success': True,
                'mode': 'production',
                'jobs': jobs,
                'count': len(jobs),
                'timestamp': datetime.now().isoformat()
            })
        
    except subprocess.TimeoutExpired:
        print("âš ï¸  squeue command timeout")
        return jsonify({
            'success': False,
            'error': 'Slurm command timeout'
        }), 500
    except subprocess.CalledProcessError as e:
        print(f"âŒ squeue command failed: {e}")
        return jsonify({
            'success': False,
            'error': f'squeue failed: {e.stderr if e.stderr else str(e)}'
        }), 500
    except Exception as e:
        print(f"âŒ Error in get_slurm_jobs: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/slurm/jobs/submit', methods=['POST'])
def submit_job():
    """ì‘ì—… ì œì¶œ"""
    try:
        data = request.json
        
        if MOCK_MODE:
            # Mock: ì‘ì—… ID ìƒì„± ë° ì €ì¥
            mock_config['job_counter'] += 1
            job_id = str(mock_config['job_counter'])
            
            mock_job = {
                'jobId': job_id,
                'jobName': data['jobName'],
                'partition': data['partition'],
                'nodes': data['nodes'],
                'cpus': data.get('cpus', 128),
                'memory': data.get('memory', '16GB'),
                'time': data.get('time', '01:00:00'),
                'state': 'PENDING',
                'userId': 'current_user',
                'submitTime': datetime.now().isoformat()
            }
            
            mock_config['jobs'].append(mock_job)
            
            return jsonify({
                'success': True,
                'mode': 'mock',
                'jobId': job_id,
                'message': f'Job {job_id} submitted successfully (Mock)'
            })
        else:
            # Production: ì‹¤ì œ sbatch ì‹¤í–‰
            script_content = data['script']
            
            # ì„ì‹œ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ìƒì„±
            with tempfile.NamedTemporaryFile(mode='w', suffix='.sh', delete=False) as f:
                f.write(f"#!/bin/bash\n")
                f.write(f"#SBATCH --job-name={data['jobName']}\n")
                f.write(f"#SBATCH --partition={data['partition']}\n")
                f.write(f"#SBATCH --nodes={data['nodes']}\n")
                if data.get('cpus'):
                    f.write(f"#SBATCH --cpus-per-task={data['cpus']}\n")
                if data.get('memory'):
                    f.write(f"#SBATCH --mem={data['memory']}\n")
                if data.get('time'):
                    f.write(f"#SBATCH --time={data['time']}\n")
                f.write(f"\n{script_content}\n")
                script_path = f.name
            
            # sbatch ì‹¤í–‰
            result = subprocess.run(
                ['sbatch', script_path],
                capture_output=True,
                text=True,
                check=True,
                timeout=10
            )
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            os.unlink(script_path)
            
            # Job ID ì¶”ì¶œ
            job_id = result.stdout.strip().split()[-1]
            
            print(f"âœ… Job {job_id} submitted successfully")
            
            return jsonify({
                'success': True,
                'mode': 'production',
                'jobId': job_id,
                'message': f'Job {job_id} submitted successfully'
            })
        
    except Exception as e:
        print(f"âŒ Error submitting job: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/slurm/jobs/<job_id>/cancel', methods=['POST'])
def cancel_job(job_id):
    """ì‘ì—… ì·¨ì†Œ"""
    try:
        if MOCK_MODE:
            return jsonify({
                'success': True,
                'mode': 'mock',
                'message': f'Job {job_id} cancelled (Mock)'
            })
        else:
            subprocess.run(['scancel', job_id], check=True, timeout=5)
            print(f"âœ… Job {job_id} cancelled")
            return jsonify({
                'success': True,
                'mode': 'production',
                'message': f'Job {job_id} cancelled'
            })
    except Exception as e:
        print(f"âŒ Error cancelling job: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/slurm/jobs/<job_id>/hold', methods=['POST'])
def hold_job(job_id):
    """ì‘ì—… í™€ë“œ"""
    try:
        if MOCK_MODE:
            return jsonify({
                'success': True,
                'mode': 'mock',
                'message': f'Job {job_id} held (Mock)'
            })
        else:
            subprocess.run(['scontrol', 'hold', job_id], check=True, timeout=5)
            print(f"âœ… Job {job_id} held")
            return jsonify({
                'success': True,
                'mode': 'production',
                'message': f'Job {job_id} held'
            })
    except Exception as e:
        print(f"âŒ Error holding job: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/slurm/jobs/<job_id>/release', methods=['POST'])
def release_job(job_id):
    """ì‘ì—… ë¦´ë¦¬ì¦ˆ"""
    try:
        if MOCK_MODE:
            return jsonify({
                'success': True,
                'mode': 'mock',
                'message': f'Job {job_id} released (Mock)'
            })
        else:
            subprocess.run(['scontrol', 'release', job_id], check=True, timeout=5)
            print(f"âœ… Job {job_id} released")
            return jsonify({
                'success': True,
                'mode': 'production',
                'message': f'Job {job_id} released'
            })
    except Exception as e:
        print(f"âŒ Error releasing job: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# ==================== ê¸°ì¡´ í´ëŸ¬ìŠ¤í„° ê´€ë¦¬ API ====================

@app.route('/api/slurm/apply-config', methods=['POST'])
def apply_slurm_config():
    """ì„¤ì • ì ìš© (Mock ëª¨ë“œ ì§€ì›)"""
    try:
        data = request.json
        groups = data.get('groups', [])
        dry_run = data.get('dryRun', False)
        
        if not groups:
            return jsonify({
                'success': False,
                'error': 'No groups provided'
            }), 400
        
        if MOCK_MODE:
            # Mock ëª¨ë“œ: ì‹¤ì œ ëª…ë ¹ ì‹¤í–‰ ì•ˆ í•¨
            return apply_mock_config(groups, dry_run)
        else:
            # Production ëª¨ë“œ: ì‹¤ì œ Slurm ëª…ë ¹ ì‹¤í–‰
            return apply_real_config(groups, dry_run)
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

def apply_mock_config(groups, dry_run):
    """Mock ëª¨ë“œ: ì‹¤ì œ ëª…ë ¹ ì—†ì´ ì‹œë®¬ë ˆì´ì…˜"""
    print("ğŸ­ Mock Mode: Simulating configuration apply...")
    
    # Mock ë°ì´í„° ì—…ë°ì´íŠ¸
    mock_config['groups'] = groups
    
    # ê°€ìƒì˜ QoS ìƒì„±
    for group in groups:
        qos_name = group['qosName']
        max_cores = max(group['allowedCoreSizes']) if group['allowedCoreSizes'] else 1024
        
        print(f"  ğŸ“ Mock: Creating QoS {qos_name} (MaxCores: {max_cores})")
        
        mock_config['qos_list'].append({
            'name': qos_name,
            'maxCores': max_cores,
            'priority': 1000 + group['id'] * 100
        })
    
    # ê°€ìƒì˜ Partition ìƒì„±
    for group in groups:
        partition_name = group['partitionName']
        node_count = len(group['nodes'])
        
        print(f"  ğŸ“ Mock: Creating Partition {partition_name} ({node_count} nodes)")
        
        mock_config['partitions'].append({
            'name': partition_name,
            'nodes': node_count,
            'state': 'UP'
        })
    
    print("  âœ… Mock: Configuration applied successfully!")
    
    return jsonify({
        'success': True,
        'mode': 'mock',
        'message': 'Configuration applied successfully (Mock Mode)',
        'changes': {
            'qos_created': len(groups),
            'partitions_updated': len(groups),
            'total_nodes': sum(len(g['nodes']) for g in groups)
        },
        'timestamp': datetime.now().isoformat()
    })

def apply_real_config(groups, dry_run):
    """Production ëª¨ë“œ: ì‹¤ì œ Slurm ëª…ë ¹ ì‹¤í–‰"""
    print("ğŸš€ Production Mode: Applying real configuration...")
    
    try:
        # ì „ì²´ ì„¤ì • ì ìš© (QoS + Partitions)
        results = apply_full_configuration(groups, dry_run)
        
        if dry_run:
            return jsonify({
                'success': True,
                'mode': 'production',
                'message': 'Dry run completed - no changes made',
                'changes': {
                    'qos': len(groups),
                    'partitions': len(groups),
                    'total_nodes': sum(len(g.get('nodes', [])) for g in groups)
                },
                'timestamp': datetime.now().isoformat()
            })
        
        # ì‹¤ì œ ì ìš© ê²°ê³¼
        return jsonify({
            'success': results['success'],
            'mode': 'production',
            'message': 'Configuration applied successfully' if results['success'] else 'Configuration apply failed',
            'details': {
                'qos_created': results['qos_created'],
                'qos_failed': results['qos_failed'],
                'partitions_updated': results['partitions_updated'],
                'errors': results.get('errors', [])
            },
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'mode': 'production',
            'error': f'Configuration apply failed: {str(e)}'
        }), 500

@app.route('/api/slurm/status', methods=['GET'])
def get_slurm_status():
    """Slurm ìƒíƒœ ì¡°íšŒ (Mock ëª¨ë“œ ì§€ì›)"""
    try:
        if MOCK_MODE:
            # Mock ë°ì´í„° ë°˜í™˜
            return jsonify({
                'success': True,
                'mode': 'mock',
                'partitions': mock_config.get('partitions', [
                    {'name': 'group1', 'nodes': 64, 'state': 'UP', 'availability': 'up'},
                    {'name': 'group2', 'nodes': 64, 'state': 'UP', 'availability': 'up'},
                    {'name': 'group3', 'nodes': 64, 'state': 'UP', 'availability': 'up'},
                    {'name': 'group4', 'nodes': 100, 'state': 'UP', 'availability': 'up'},
                    {'name': 'group5', 'nodes': 14, 'state': 'UP', 'availability': 'up'},
                    {'name': 'group6', 'nodes': 64, 'state': 'UP', 'availability': 'up'},
                ]),
                'timestamp': datetime.now().isoformat()
            })
        else:
            # ì‹¤ì œ sinfo ëª…ë ¹ ì‹¤í–‰
            result = subprocess.run(
                ['sinfo', '-h', '-o', '%P %a %l %D %T %N'],
                capture_output=True,
                text=True,
                check=True
            )
            
            partitions = []
            for line in result.stdout.strip().split('\n'):
                if line:
                    parts = line.split()
                    if len(parts) >= 5:
                        partitions.append({
                            'name': parts[0].rstrip('*'),
                            'availability': parts[1],
                            'timelimit': parts[2],
                            'nodes': int(parts[3]),
                            'state': parts[4],
                        })
            
            return jsonify({
                'success': True,
                'mode': 'production',
                'partitions': partitions,
                'timestamp': datetime.now().isoformat()
            })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/slurm/qos', methods=['GET'])
def get_qos_list():
    """QoS ëª©ë¡ ì¡°íšŒ (Mock ëª¨ë“œ ì§€ì›)"""
    try:
        if MOCK_MODE:
            return jsonify({
                'success': True,
                'mode': 'mock',
                'qos': mock_config.get('qos_list', [
                    {'name': 'group1_qos', 'priority': '1100'},
                    {'name': 'group2_qos', 'priority': '1200'},
                    {'name': 'group3_qos', 'priority': '1300'},
                    {'name': 'group4_qos', 'priority': '1400'},
                    {'name': 'group5_qos', 'priority': '1500'},
                    {'name': 'group6_qos', 'priority': '1600'},
                ])
            })
        else:
            result = subprocess.run(
                ['sacctmgr', 'show', 'qos', '-n', '-P'],
                capture_output=True,
                text=True,
                check=True
            )
            
            qos_list = []
            for line in result.stdout.strip().split('\n'):
                if line:
                    parts = line.split('|')
                    if parts:
                        qos_list.append({
                            'name': parts[0],
                            'priority': parts[1] if len(parts) > 1 else None,
                        })
            
            return jsonify({
                'success': True,
                'mode': 'production',
                'qos': qos_list
            })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# ==================== ğŸ†• ì‹¤ì œ ë…¸ë“œ ì •ë³´ ì¡°íšŒ API ====================

@app.route('/api/slurm/nodes/real', methods=['GET'])
def get_real_slurm_nodes():
    """
    ì‹¤ì œ Slurm í´ëŸ¬ìŠ¤í„°ì˜ ë…¸ë“œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    Production ëª¨ë“œì—ì„œë§Œ ì‹¤ì œ ë°ì´í„° ë°˜í™˜
    """
    try:
        if MOCK_MODE:
            return jsonify({
                'success': False,
                'mode': 'mock',
                'message': 'Real node information is only available in Production mode',
                'hint': 'Set MOCK_MODE=false to enable this feature'
            }), 400
        
        # Production ëª¨ë“œ: ì‹¤ì œ ë…¸ë“œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        from slurm_utils import get_slurm_nodes, get_partitions
        
        print("ğŸ”„ Syncing nodes from Slurm...")
        nodes = get_slurm_nodes()
        partitions = get_partitions()
        
        print(f"   Found {len(nodes)} nodes and {len(partitions)} partitions")
        
        # íŒŒí‹°ì…˜ë³„ë¡œ ë…¸ë“œ ê·¸ë£¹í™”
        nodes_by_partition = {}
        for node in nodes:
            partition = node.get('partition', 'default')
            if partition not in nodes_by_partition:
                nodes_by_partition[partition] = []
            nodes_by_partition[partition].append(node)
        
        return jsonify({
            'success': True,
            'mode': 'production',
            'data': {
                'nodes': nodes,
                'partitions': partitions,
                'nodes_by_partition': nodes_by_partition,
                'total_nodes': len(nodes),
                'timestamp': datetime.now().isoformat()
            }
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


# ==================== ğŸ’¾ Storage Management API ====================

# í—ˆìš©ëœ ê¸°ë³¸ ê²½ë¡œ
ALLOWED_PATHS = {
    'data': '/Data',
    'scratch': '/scratch'
}

@app.route('/api/storage/data/stats', methods=['GET'])
def get_shared_storage_stats():
    """ê³µìœ  ìŠ¤í† ë¦¬ì§€ í†µê³„"""
    try:
        if MOCK_MODE:
            # Mock ë°ì´í„°
            from data.mockStorageData import mockStorageStats
            return jsonify({
                'success': True,
                'mode': 'mock',
                'data': mockStorageStats
            })
        else:
            # Production: ì‹¤ì œ /Data ë””ë ‰í† ë¦¬ ìŠ¤ìº”
            data_path = ALLOWED_PATHS['data']
            
            if not os.path.exists(data_path):
                return jsonify({
                    'success': False,
                    'error': f'Path {data_path} does not exist'
                }), 404
            
            usage = get_disk_usage(data_path)
            file_count, dir_count = count_files_recursive(data_path)
            
            # ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ ìˆ˜ ê³„ì‚° (ì˜ˆ: /Data/datasets/ í•˜ìœ„)
            datasets_path = os.path.join(data_path, 'datasets')
            dataset_count = 0
            if os.path.exists(datasets_path):
                dataset_count = len([d for d in os.listdir(datasets_path) 
                                   if os.path.isdir(os.path.join(datasets_path, d))])
            
            stats = {
                'totalCapacity': usage['total'],
                'usedSpace': usage['used'],
                'availableSpace': usage['available'],
                'usagePercent': usage['usagePercent'],
                'datasetCount': dataset_count,
                'fileCount': file_count,
                'lastAnalysis': 'Just now'
            }
            
            return jsonify({
                'success': True,
                'mode': 'production',
                'data': stats
            })
            
    except Exception as e:
        print(f"âŒ Error getting storage stats: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/storage/data/datasets', methods=['GET'])
def get_datasets():
    """ë°ì´í„°ì…‹ ëª©ë¡ ì¡°íšŒ"""
    try:
        search = request.args.get('search', '')
        status = request.args.get('status', 'all')
        
        if MOCK_MODE:
            # Mock ë°ì´í„°
            return jsonify({
                'success': True,
                'mode': 'mock',
                'data': []  # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ mock ë°ì´í„° ì‚¬ìš©
            })
        else:
            # Production: ì‹¤ì œ /Data/datasets ìŠ¤ìº”
            data_path = ALLOWED_PATHS['data']
            datasets_path = os.path.join(data_path, 'datasets')
            
            if not os.path.exists(datasets_path):
                return jsonify({
                    'success': True,
                    'mode': 'production',
                    'data': []
                })
            
            datasets = []
            for entry in os.listdir(datasets_path):
                full_path = os.path.join(datasets_path, entry)
                if os.path.isdir(full_path):
                    file_info = get_file_info(full_path)
                    if file_info:
                        file_count, _ = count_files_recursive(full_path)
                        datasets.append({
                            'id': file_info['id'],
                            'name': file_info['name'],
                            'path': file_info['path'],
                            'size': file_info['size'],
                            'sizeBytes': file_info['sizeBytes'],
                            'fileCount': file_count,
                            'createdAt': file_info['modifiedAt'],
                            'lastAccessed': 'Recently',
                            'owner': file_info['owner'],
                            'group': file_info['group'],
                            'status': 'active',
                            'tags': []
                        })
            
            # ê²€ìƒ‰ í•„í„°
            if search:
                search_lower = search.lower()
                datasets = [d for d in datasets 
                          if search_lower in d['name'].lower() or search_lower in d['owner'].lower()]
            
            # ìƒíƒœ í•„í„°
            if status != 'all':
                datasets = [d for d in datasets if d['status'] == status]
            
            return jsonify({
                'success': True,
                'mode': 'production',
                'data': datasets
            })
            
    except Exception as e:
        print(f"âŒ Error getting datasets: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/storage/files', methods=['GET'])
def list_storage_files():
    """íŒŒì¼ ëª©ë¡ ì¡°íšŒ"""
    try:
        path = request.args.get('path', '')
        storage_type = request.args.get('type', 'data')  # 'data' or 'scratch'
        
        if not path:
            return jsonify({
                'success': False,
                'error': 'Path parameter is required'
            }), 400
        
        if MOCK_MODE:
            # Mock: í”„ë¡ íŠ¸ì—”ë“œì—ì„œ generateMockFiles ì‚¬ìš©
            return jsonify({
                'success': True,
                'mode': 'mock',
                'data': []  # í”„ë¡ íŠ¸ì—ì„œ ìƒì„±
            })
        else:
            # Production: ì‹¤ì œ íŒŒì¼ ëª©ë¡
            base_path = ALLOWED_PATHS.get(storage_type, ALLOWED_PATHS['data'])
            
            # ì•ˆì „í•œ ê²½ë¡œ ê²°í•©
            if path.startswith(base_path):
                full_path = path
            else:
                full_path = safe_path_join(base_path, path)
            
            if not full_path:
                return jsonify({
                    'success': False,
                    'error': 'Invalid path'
                }), 400
            
            if not is_path_accessible(full_path):
                return jsonify({
                    'success': False,
                    'error': 'Path not accessible'
                }), 403
            
            files = list_directory(full_path)
            
            return jsonify({
                'success': True,
                'mode': 'production',
                'data': files,
                'path': full_path
            })
            
    except Exception as e:
        print(f"âŒ Error listing files: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/storage/scratch/nodes', methods=['GET'])
def get_scratch_nodes():
    """ëª¨ë“  ë…¸ë“œì˜ /scratch ì •ë³´"""
    try:
        if MOCK_MODE:
            # Mock ë°ì´í„°
            return jsonify({
                'success': True,
                'mode': 'mock',
                'data': []  # í”„ë¡ íŠ¸ì—ì„œ mock ë°ì´í„° ì‚¬ìš©
            })
        else:
            # Production: Slurm ë…¸ë“œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            nodes = get_storage_nodes()
            
            if not nodes:
                return jsonify({
                    'success': True,
                    'mode': 'production',
                    'data': [],
                    'message': 'No nodes found'
                })
            
            scratch_data = []
            
            for node in nodes:
                # ì›ê²© ë…¸ë“œì—ì„œ /scratch ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                df_output = run_remote_command(node, "df -B1 /scratch | tail -1")
                
                if df_output:
                    parts = df_output.split()
                    if len(parts) >= 4:
                        total_bytes = int(parts[1])
                        used_bytes = int(parts[2])
                        avail_bytes = int(parts[3])
                        usage_percent = (used_bytes / total_bytes * 100) if total_bytes > 0 else 0
                        
                        # /scratch ë””ë ‰í† ë¦¬ ëª©ë¡
                        ls_output = run_remote_command(node, "ls -la /scratch | tail -n +2")
                        directories = []
                        
                        if ls_output:
                            for line in ls_output.strip().split('\n'):
                                if line and line.startswith('d'):
                                    parts = line.split()
                                    if len(parts) >= 9:
                                        dir_name = parts[8]
                                        if not dir_name.startswith('.'):
                                            directories.append({
                                                'id': f"{node}-{dir_name}",
                                                'name': dir_name,
                                                'path': f"/scratch/{dir_name}",
                                                'owner': parts[2],
                                                'group': parts[3],
                                                'size': 'Calculating...',
                                                'sizeBytes': 0,
                                                'fileCount': 0,
                                                'createdAt': f"{parts[5]} {parts[6]}",
                                                'lastModified': f"{parts[5]} {parts[6]}"
                                            })
                        
                        scratch_data.append({
                            'nodeId': node,
                            'nodeName': node,
                            'totalSpace': format_size(total_bytes),
                            'totalSpaceBytes': total_bytes,
                            'usedSpace': format_size(used_bytes),
                            'usedSpaceBytes': used_bytes,
                            'availableSpace': format_size(avail_bytes),
                            'availableSpaceBytes': avail_bytes,
                            'usagePercent': round(usage_percent, 1),
                            'fileCount': len(directories),
                            'directories': directories,
                            'status': 'online',
                            'lastUpdated': datetime.now().isoformat()
                        })
            
            return jsonify({
                'success': True,
                'mode': 'production',
                'data': scratch_data
            })
            
    except Exception as e:
        print(f"âŒ Error getting scratch nodes: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/storage/scratch/move', methods=['POST'])
def move_scratch_to_data():
    """/scratch â†’ /Data ì´ë™"""
    try:
        data = request.json
        directory_ids = data.get('directoryIds', [])
        destination = data.get('destination', '/Data/from_scratch/')
        
        if not directory_ids:
            return jsonify({
                'success': False,
                'error': 'No directories specified'
            }), 400
        
        if MOCK_MODE:
            # Mock: ì‹¤ì œ ì´ë™ ì•ˆ í•¨
            return jsonify({
                'success': True,
                'mode': 'mock',
                'message': f'Moved {len(directory_ids)} directories (Mock)',
                'taskId': f'task-{int(time.time())}'
            })
        else:
            # Production: ì‹¤ì œ rsync ì‹¤í–‰
            # TODO: ë¹„ë™ê¸° ì‘ì—…ìœ¼ë¡œ êµ¬í˜„ í•„ìš”
            task_id = f'task-{int(time.time())}'
            
            # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ êµ¬í˜„ë§Œ
            # ì‹¤ì œë¡œëŠ” Celery ë“±ì„ ì‚¬ìš©í•´ì•¼ í•¨
            
            return jsonify({
                'success': True,
                'mode': 'production',
                'message': f'Move task initiated for {len(directory_ids)} directories',
                'taskId': task_id
            })
            
    except Exception as e:
        print(f"âŒ Error moving directories: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/storage/scratch/delete', methods=['POST'])
def delete_scratch_directories():
    """/scratch ë””ë ‰í† ë¦¬ ì‚­ì œ"""
    try:
        data = request.json
        directory_ids = data.get('directoryIds', [])
        
        if not directory_ids:
            return jsonify({
                'success': False,
                'error': 'No directories specified'
            }), 400
        
        if MOCK_MODE:
            # Mock: ì‹¤ì œ ì‚­ì œ ì•ˆ í•¨
            return jsonify({
                'success': True,
                'mode': 'mock',
                'message': f'Deleted {len(directory_ids)} directories (Mock)'
            })
        else:
            # Production: ì‹¤ì œ rm -rf ì‹¤í–‰
            # âš ï¸ ë§¤ìš° ìœ„í—˜í•œ ì‘ì—…ì´ë¯€ë¡œ ì‹ ì¤‘í•˜ê²Œ êµ¬í˜„
            # TODO: ê¶Œí•œ í™•ì¸ ë° ì•ˆì „ ì¥ì¹˜ í•„ìš”
            
            return jsonify({
                'success': True,
                'mode': 'production',
                'message': f'Delete task initiated for {len(directory_ids)} directories',
                'warning': 'This operation cannot be undone'
            })
            
    except Exception as e:
        print(f"âŒ Error deleting directories: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/storage/search', methods=['GET'])
def search_storage():
    """íŒŒì¼ ê²€ìƒ‰"""
    try:
        query = request.args.get('q', '')
        path = request.args.get('path', '')
        storage_type = request.args.get('type', 'data')
        max_results = int(request.args.get('limit', 100))
        
        if not query:
            return jsonify({
                'success': False,
                'error': 'Query parameter is required'
            }), 400
        
        if MOCK_MODE:
            return jsonify({
                'success': True,
                'mode': 'mock',
                'data': []
            })
        else:
            base_path = ALLOWED_PATHS.get(storage_type, ALLOWED_PATHS['data'])
            search_path = safe_path_join(base_path, path) if path else base_path
            
            if not search_path or not is_path_accessible(search_path):
                return jsonify({
                    'success': False,
                    'error': 'Invalid or inaccessible path'
                }), 400
            
            results = search_files(search_path, query, max_results)
            
            return jsonify({
                'success': True,
                'mode': 'production',
                'data': results,
                'count': len(results)
            })
            
    except Exception as e:
        print(f"âŒ Error searching files: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# create_qos, update_partitions, reconfigure_slurm í•¨ìˆ˜ëŠ”
# slurm_config_manager.pyì—ì„œ ì„í¬íŠ¸í•˜ì—¬ ì‚¬ìš©

if __name__ == '__main__':
    print("=" * 60)
    print("Slurm Dashboard Backend API v2.0")
    print("=" * 60)
    print(f"Mode: {'ğŸ­ MOCK (Demo)' if MOCK_MODE else 'ğŸš€ PRODUCTION (Real Slurm)'}")
    print("")
    print("Available Endpoints:")
    print("  GET  /api/health")
    print("  GET  /api/metrics/realtime")
    print("  GET  /api/slurm/jobs")
    print("  POST /api/slurm/jobs/submit")
    print("  POST /api/slurm/jobs/<id>/cancel")
    print("  POST /api/slurm/jobs/<id>/hold")
    print("  POST /api/slurm/jobs/<id>/release")
    print("  POST /api/slurm/apply-config")
    print("  GET  /api/slurm/status")
    print("  GET  /api/slurm/qos")
    print("  ğŸ†• GET  /api/slurm/nodes/real")
    print("  ğŸ†• GET  /api/slurm/nodes/<hostname>")
    print("  ğŸ†• POST /api/slurm/sync-nodes")
    print("")
    print("ğŸ’¾ Storage Management:")
    print("  GET  /api/storage/data/stats")
    print("  GET  /api/storage/data/datasets")
    print("  GET  /api/storage/files")
    print("  GET  /api/storage/scratch/nodes")
    print("  POST /api/storage/scratch/move")
    print("  POST /api/storage/scratch/delete")
    print("  GET  /api/storage/search")
    print("")
    print("ğŸ†• v1.3.0 New Features:")
    print("  âš ï¸  Disk Alerts:")
    print("    POST /api/alerts/disk/check")
    print("    GET  /api/alerts/disk")
    print("    POST /api/alerts/disk/clear")
    print("    PUT  /api/alerts/disk/thresholds")
    print("  ğŸ‘ï¸  File Preview:")
    print("    POST /api/preview/type")
    print("    POST /api/preview/text")
    print("    GET  /api/preview/image")
    print("    POST /api/preview/tail")
    print("  ğŸ” File Search:")
    print("    POST /api/search/files")
    print("    POST /api/search/content")
    print("  ğŸ“Š Directory Analysis:")
    print("    POST /api/directory/size")
    print("    POST /api/directory/breakdown")
    print("")
    print("To switch modes:")
    print("  Mock:       export MOCK_MODE=true")
    print("  Production: export MOCK_MODE=false")
    print("")
    print("Starting server on http://0.0.0.0:5010")
    print("=" * 60)
    
    app.run(host='0.0.0.0', port=5010, debug=True)
