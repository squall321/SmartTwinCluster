#!/usr/bin/env python3
"""
Slurm ì™„ì „ ìžë™ ì„¤ì¹˜ ë³´ì™„ ëª¨ë“ˆ
ëˆ„ë½ëœ í•„ìˆ˜ ì„¤ì •ë“¤ì„ ìžë™ìœ¼ë¡œ ì²˜ë¦¬
"""

import sys
from pathlib import Path
from typing import Dict, Any

# src ë””ë ‰í† ë¦¬ ê²½ë¡œ ì¶”ê°€
src_path = Path(__file__).parent / 'src'
sys.path.insert(0, str(src_path))

# ê°œë³„ importë¡œ ìˆœí™˜ ì°¸ì¡° ë°©ì§€
import ssh_manager


class SlurmAutoSetup:
    """Slurm ìžë™ ì„¤ì¹˜ ë³´ì™„ í´ëž˜ìŠ¤"""
    
    def __init__(self, config: Dict[str, Any], ssh_mgr):
        self.config = config
        self.ssh_manager = ssh_mgr
        self.all_nodes = [config['nodes']['controller']] + config['nodes']['compute_nodes']
    
    def complete_setup(self) -> bool:
        """ì™„ì „ ìžë™ ì„¤ì¹˜ - ëˆ„ë½ëœ ëª¨ë“  ë‹¨ê³„ ì²˜ë¦¬"""
        print("\nðŸ”§ Slurm ì™„ì „ ìžë™ ì„¤ì¹˜ ì‹œìž‘...")
        
        steps = [
            ("SSH í‚¤ ìžë™ ì„¤ì •", self.setup_ssh_keys),
            ("ë°©í™”ë²½ ì„¤ì •", self.configure_firewall),
            ("SELinux ì„¤ì •", self.configure_selinux),
            ("NTP ì‹œê°„ ë™ê¸°í™”", self.setup_ntp),
            ("í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜", self.install_dependencies),
            ("Munge ì¸ì¦ ì„¤ì •", self.setup_munge),
            ("NFS ê³µìœ  ìŠ¤í† ë¦¬ì§€", self.setup_nfs),
            ("slurm.conf ìƒì„±", self.generate_slurm_conf),
            ("cgroup ì„¤ì •", self.setup_cgroup),
            ("í™˜ê²½ë³€ìˆ˜ ì„¤ì •", self.setup_environment),
        ]
        
        for step_name, step_func in steps:
            print(f"\nðŸ“Œ {step_name}...")
            try:
                if not step_func():
                    print(f"  âš ï¸  {step_name} ì‹¤íŒ¨ (ê³„ì† ì§„í–‰)")
            except Exception as e:
                print(f"  âŒ {step_name} ì˜¤ë¥˜: {e}")
        
        print("\nâœ… Slurm ì™„ì „ ìžë™ ì„¤ì¹˜ ì™„ë£Œ!")
        return True
    
    def setup_ssh_keys(self) -> bool:
        """ëª¨ë“  ë…¸ë“œì— í˜¸ìŠ¤íŠ¸ëª… ë° SSH í‚¤ ìžë™ ì„¤ì • (íŒ¨ìŠ¤ì›Œë“œ ì—†ëŠ” ë¡œê·¸ì¸)"""
        print("  ðŸ”‘ SSH í‚¤ ì„¤ì • ì¤‘...")
        
        # 1. /etc/hostsì— ëª¨ë“  ë…¸ë“œ ì¶”ê°€
        print("    ðŸ“ /etc/hosts íŒŒì¼ ì—…ë°ì´íŠ¸ ì¤‘...")

        # ëª¨ë“  í˜¸ìŠ¤íŠ¸ ì—”íŠ¸ë¦¬ë¥¼ ì¤€ë¹„
        host_entries = []
        for node in self.all_nodes:
            hostname = node['hostname']
            ip_address = node.get('ip_address', hostname)
            host_entries.append(f"{ip_address} {hostname}")

        # ê° ë…¸ë“œì˜ /etc/hosts ì—…ë°ì´íŠ¸
        for target_node in self.all_nodes:
            target_hostname = target_node['hostname']
            target_ip = target_node.get('ip_address', target_hostname)

            print(f"      â†’ {target_hostname} /etc/hosts ì—…ë°ì´íŠ¸ ì¤‘...")

            # ëª¨ë“  í˜¸ìŠ¤íŠ¸ ì—”íŠ¸ë¦¬ë¥¼ í•œ ë²ˆì— ì¶”ê°€
            for entry in host_entries:
                hostname_in_entry = entry.split()[1]
                ip_in_entry = entry.split()[0]

                # í•´ë‹¹ í˜¸ìŠ¤íŠ¸ëª…ì´ ì´ë¯¸ ìžˆëŠ”ì§€ í™•ì¸ í›„ ì¶”ê°€
                check_cmd = f"grep -q '{hostname_in_entry}' /etc/hosts"
                exit_code, _, _ = self.ssh_manager.execute_command(
                    target_hostname,
                    check_cmd,
                    show_output=False
                )

                if exit_code != 0:  # ì—†ìœ¼ë©´ ì¶”ê°€
                    add_cmd = f"sudo bash -c 'echo \"{ip_in_entry} {hostname_in_entry}\" >> /etc/hosts'"
                    self.ssh_manager.execute_command(
                        target_hostname,
                        add_cmd,
                        show_output=False
                    )

        print("    âœ… /etc/hosts ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        
        controller = self.config['nodes']['controller']
        controller_hostname = controller['hostname']
        ssh_user = controller['ssh_user']
        
        # 2. ì»¨íŠ¸ë¡¤ëŸ¬ì— SSH í‚¤ê°€ ì—†ìœ¼ë©´ ìƒì„±
        exit_code, _, _ = self.ssh_manager.execute_command(
            controller_hostname,
            f"test -f ~/.ssh/id_rsa",
            show_output=False
        )
        
        if exit_code != 0:
            print(f"    ðŸ“ SSH í‚¤ ìƒì„± ì¤‘...")
            self.ssh_manager.execute_command(
                controller_hostname,
                f"ssh-keygen -t rsa -b 4096 -f ~/.ssh/id_rsa -N ''",
                show_output=False
            )
        
        # 3. ê³µê°œí‚¤ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
        exit_code, pubkey, _ = self.ssh_manager.execute_command(
            controller_hostname,
            f"cat ~/.ssh/id_rsa.pub",
            show_output=False
        )
        
        if exit_code != 0 or not pubkey.strip():
            print(f"    âš ï¸  ê³µê°œí‚¤ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        # 4. ëª¨ë“  ë…¸ë“œì— ê³µê°œí‚¤ ì¶”ê°€
        for node in self.all_nodes:
            hostname = node['hostname']
            print(f"    ðŸ” {hostname}: SSH í‚¤ ë°°í¬ ì¤‘...")
            
            # authorized_keysì— ì¶”ê°€
            self.ssh_manager.execute_command(
                hostname,
                f"""
                mkdir -p ~/.ssh
                chmod 700 ~/.ssh
                echo '{pubkey.strip()}' >> ~/.ssh/authorized_keys
                chmod 600 ~/.ssh/authorized_keys
                """,
                show_output=False
            )
            
            # StrictHostKeyChecking ë¹„í™œì„±í™”
            self.ssh_manager.execute_command(
                hostname,
                f"""
                mkdir -p ~/.ssh
                echo 'Host *' > ~/.ssh/config
                echo '    StrictHostKeyChecking no' >> ~/.ssh/config
                echo '    UserKnownHostsFile=/dev/null' >> ~/.ssh/config
                chmod 600 ~/.ssh/config
                """,
                show_output=False
            )
        
        print(f"    âœ… SSH í‚¤ ì„¤ì • ì™„ë£Œ")
        return True
    
    def configure_firewall(self) -> bool:
        """ë°©í™”ë²½ ì„¤ì • (Slurm í¬íŠ¸ ê°œë°©)"""
        print("  ðŸ”¥ ë°©í™”ë²½ ì„¤ì • ì¤‘...")
        
        firewall_config = self.config.get('network', {}).get('firewall', {})
        if not firewall_config.get('enabled', True):
            print("    â­ï¸  ë°©í™”ë²½ ì„¤ì • ê±´ë„ˆëœ€ (ë¹„í™œì„±í™”ë¨)")
            return True
        
        ports = firewall_config.get('ports', {})
        
        for node in self.all_nodes:
            hostname = node['hostname']
            node_type = node.get('node_type', 'compute')
            
            print(f"    ðŸ” {hostname}: ë°©í™”ë²½ ê·œì¹™ ì¶”ê°€ ì¤‘...")
            
            # í•„ìš”í•œ í¬íŠ¸ ê²°ì •
            required_ports = [ports.get('ssh', 22)]
            
            if node_type == 'controller':
                required_ports.extend([
                    ports.get('slurmctld', 6817),
                    ports.get('slurmdbd', 6819)
                ])
            else:
                required_ports.append(ports.get('slurmd', 6818))
            
            # firewalld ì‚¬ìš© (CentOS/RHEL)
            for port in required_ports:
                self.ssh_manager.execute_command(
                    hostname,
                    f"firewall-cmd --permanent --add-port={port}/tcp 2>/dev/null || true",
                    show_output=False
                )
            
            self.ssh_manager.execute_command(
                hostname,
                "firewall-cmd --reload 2>/dev/null || true",
                show_output=False
            )
            
            # ufw ì‚¬ìš© (Ubuntu)
            for port in required_ports:
                self.ssh_manager.execute_command(
                    hostname,
                    f"ufw allow {port}/tcp 2>/dev/null || true",
                    show_output=False
                )
        
        print(f"    âœ… ë°©í™”ë²½ ì„¤ì • ì™„ë£Œ")
        return True
    
    def configure_selinux(self) -> bool:
        """SELinux ì„¤ì •"""
        print("  ðŸ›¡ï¸  SELinux ì„¤ì • ì¤‘...")
        
        selinux_config = self.config.get('security', {}).get('selinux', {})
        if not selinux_config.get('enabled', True):
            # SELinux ë¹„í™œì„±í™”
            for node in self.all_nodes:
                hostname = node['hostname']
                self.ssh_manager.execute_command(
                    hostname,
                    "setenforce 0 2>/dev/null || true",
                    show_output=False
                )
                self.ssh_manager.execute_command(
                    hostname,
                    "sed -i 's/^SELINUX=enforcing/SELINUX=disabled/' /etc/selinux/config 2>/dev/null || true",
                    show_output=False
                )
            print(f"    âœ… SELinux ë¹„í™œì„±í™” ì™„ë£Œ")
        else:
            mode = selinux_config.get('mode', 'permissive')
            for node in self.all_nodes:
                hostname = node['hostname']
                self.ssh_manager.execute_command(
                    hostname,
                    f"setenforce {1 if mode == 'enforcing' else 0} 2>/dev/null || true",
                    show_output=False
                )
            print(f"    âœ… SELinux {mode} ëª¨ë“œ ì„¤ì • ì™„ë£Œ")
        
        return True
    
    def setup_ntp(self) -> bool:
        """NTP ì‹œê°„ ë™ê¸°í™” ì„¤ì •"""
        print("  â° NTP ì‹œê°„ ë™ê¸°í™” ì„¤ì • ì¤‘...")
        
        time_config = self.config.get('time_synchronization', {})
        if not time_config.get('enabled', True):
            print("    â­ï¸  NTP ì„¤ì • ê±´ë„ˆëœ€")
            return True
        
        ntp_servers = time_config.get('ntp_servers', ['time.google.com'])
        timezone = time_config.get('timezone', 'Asia/Seoul')
        
        for node in self.all_nodes:
            hostname = node['hostname']
            os_type = node.get('os_type', 'ubuntu22')
            
            print(f"    â° {hostname}: NTP ì„¤ì • ì¤‘...")
            
            # íƒ€ìž„ì¡´ ì„¤ì •
            self.ssh_manager.execute_command(
                hostname,
                f"timedatectl set-timezone {timezone} 2>/dev/null || true",
                show_output=False
            )
            
            # systemd-timesyncd ë˜ëŠ” chrony ì‚¬ìš©
            if 'ubuntu' in os_type or 'debian' in os_type:
                # systemd-timesyncd
                self.ssh_manager.execute_command(
                    hostname,
                    "apt install -y systemd-timesyncd 2>/dev/null || true",
                    show_output=False
                )
                
                self.ssh_manager.execute_command(
                    hostname,
                    "systemctl restart systemd-timesyncd && systemctl enable systemd-timesyncd",
                    show_output=False
                )
            else:
                # chrony (CentOS/RHEL)
                self.ssh_manager.execute_command(
                    hostname,
                    "yum install -y chrony 2>/dev/null || true",
                    show_output=False
                )
                
                self.ssh_manager.execute_command(
                    hostname,
                    "systemctl restart chronyd && systemctl enable chronyd",
                    show_output=False
                )
        
        print(f"    âœ… NTP ì„¤ì • ì™„ë£Œ")
        return True
    
    def install_dependencies(self) -> bool:
        """í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜"""
        print("  ðŸ“¦ í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘...")
        
        for node in self.all_nodes:
            hostname = node['hostname']
            os_type = node.get('os_type', 'ubuntu22')
            
            print(f"    ðŸ“¦ {hostname}: íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘...")
            
            if 'ubuntu' in os_type or 'debian' in os_type:
                packages = [
                    "build-essential", "gcc", "g++", "make",
                    "libmunge-dev", "libmunge2",
                    "libpam0g-dev", "libreadline-dev",
                    "libssl-dev", "libnuma-dev",
                    "libhwloc-dev",
                    "python3", "python3-pip",
                    "rsync", "wget", "curl", "vim",
                    "munge", "nfs-common"
                ]
                
                self.ssh_manager.execute_command(
                    hostname,
                    f"apt update && apt install -y {' '.join(packages)}",
                    show_output=False,
                    timeout=600
                )
            else:
                # CentOS/RHEL
                packages = [
                    "gcc", "gcc-c++", "make",
                    "munge", "munge-devel", "munge-libs",
                    "pam-devel", "readline-devel",
                    "openssl-devel", "numactl-devel",
                    "hwloc-devel",
                    "python3", "python3-pip",
                    "rsync", "wget", "curl", "vim",
                    "nfs-utils", "rpcbind"
                ]
                
                self.ssh_manager.execute_command(
                    hostname,
                    f"yum install -y {' '.join(packages)}",
                    show_output=False,
                    timeout=600
                )
        
        print(f"    âœ… í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ")
        return True
    
    def setup_munge(self) -> bool:
        """Munge ì¸ì¦ ì‹œìŠ¤í…œ ì„¤ì •"""
        print("  ðŸ” Munge ì„¤ì • ì¤‘...")
        
        # munge_validator importë¥¼ ì—¬ê¸°ì„œ í•¨
        import munge_validator
        
        validator = munge_validator.MungeValidator(self.config, self.ssh_manager)
        return validator.setup_and_validate_munge()
    
    def setup_nfs(self) -> bool:
        """NFS ê³µìœ  ìŠ¤í† ë¦¬ì§€ ì„¤ì •"""
        print("  ðŸ’¾ NFS ê³µìœ  ìŠ¤í† ë¦¬ì§€ ì„¤ì • ì¤‘...")
        
        nfs_config = self.config.get('shared_storage', {})
        if not nfs_config:
            print("    â­ï¸  NFS ì„¤ì • ê±´ë„ˆëœ€")
            return True
        
        controller = self.config['nodes']['controller']
        controller_hostname = controller['hostname']
        nfs_server = nfs_config.get('nfs_server', controller['ip_address'])
        mount_points = nfs_config.get('mount_points', [])
        
        # 1. ì»¨íŠ¸ë¡¤ëŸ¬ë¥¼ NFS ì„œë²„ë¡œ ì„¤ì •
        print(f"    ðŸ“¤ {controller_hostname}: NFS ì„œë²„ ì„¤ì • ì¤‘...")
        
        os_type = controller.get('os_type', 'ubuntu22')
        
        if 'ubuntu' in os_type:
            self.ssh_manager.execute_command(
                controller_hostname,
                "apt install -y nfs-kernel-server",
                show_output=False
            )
        else:
            self.ssh_manager.execute_command(
                controller_hostname,
                "yum install -y nfs-utils rpcbind",
                show_output=False
            )
        
        # 2. Export ë””ë ‰í† ë¦¬ ìƒì„± ë° /etc/exports ì„¤ì •
        exports_lines = []
        
        for mount in mount_points:
            source = mount['source']
            options = mount.get('options', 'rw,sync,no_root_squash')
            
            # ë””ë ‰í† ë¦¬ ìƒì„±
            self.ssh_manager.execute_command(
                controller_hostname,
                f"mkdir -p {source} && chmod 755 {source}",
                show_output=False
            )
            
            # exports ë¼ì¸ ì¶”ê°€
            network = self.config.get('network', {}).get('management_network', '192.168.0.0/24')
            exports_lines.append(f"{source} {network}({options})")
        
        # /etc/exports íŒŒì¼ ìƒì„±
        exports_content = '\\n'.join(exports_lines)
        self.ssh_manager.execute_command(
            controller_hostname,
            f"echo '{exports_content}' >> /etc/exports",
            show_output=False
        )
        
        # NFS ì„œë¹„ìŠ¤ ìž¬ì‹œìž‘
        self.ssh_manager.execute_command(
            controller_hostname,
            "exportfs -ra && systemctl restart nfs-server && systemctl enable nfs-server 2>/dev/null || systemctl restart nfs-kernel-server && systemctl enable nfs-kernel-server 2>/dev/null",
            show_output=False
        )
        
        # 3. ê³„ì‚° ë…¸ë“œì—ì„œ ë§ˆìš´íŠ¸
        for node in self.config['nodes']['compute_nodes']:
            hostname = node['hostname']
            print(f"    ðŸ“¥ {hostname}: NFS ë§ˆìš´íŠ¸ ì¤‘...")
            
            for mount in mount_points:
                source = mount['source']
                target = mount['target']
                options = mount.get('options', 'rw,sync,hard,intr')
                
                # ë§ˆìš´íŠ¸ í¬ì¸íŠ¸ ìƒì„±
                self.ssh_manager.execute_command(
                    hostname,
                    f"mkdir -p {target}",
                    show_output=False
                )
                
                # ë§ˆìš´íŠ¸
                self.ssh_manager.execute_command(
                    hostname,
                    f"mount -t nfs -o {options} {nfs_server}:{source} {target} 2>/dev/null || true",
                    show_output=False
                )
                
                # /etc/fstabì— ì¶”ê°€ (ìž¬ë¶€íŒ… í›„ì—ë„ ìžë™ ë§ˆìš´íŠ¸)
                fstab_line = f"{nfs_server}:{source} {target} nfs {options} 0 0"
                self.ssh_manager.execute_command(
                    hostname,
                    f"grep -q '{nfs_server}:{source}' /etc/fstab || echo '{fstab_line}' >> /etc/fstab",
                    show_output=False
                )
        
        print(f"    âœ… NFS ì„¤ì • ì™„ë£Œ")
        return True
    
    def generate_slurm_conf(self) -> bool:
        """slurm.conf íŒŒì¼ ìƒì„±"""
        print("  ðŸ“ slurm.conf ìƒì„± ì¤‘...")
        
        controller = self.config['nodes']['controller']
        controller_hostname = controller['hostname']
        cluster_name = self.config['cluster_info']['cluster_name']
        
        # slurm.conf ë‚´ìš© ìƒì„±
        slurm_conf = f"""# slurm.conf - Auto-generated by KooSlurmInstallAutomation
ClusterName={cluster_name}
SlurmctldHost={controller_hostname}

# Authentication
AuthType=auth/munge
CryptoType=crypto/munge

# Reboot Program
RebootProgram={self.config['slurm_config'].get('reboot_program', '/sbin/reboot')}

# Scheduler
SchedulerType={self.config['slurm_config']['scheduler']['type']}
SelectType=select/cons_tres
SelectTypeParameters=CR_Core_Memory

# Logging
SlurmctldLogFile=/var/log/slurm/slurmctld.log
SlurmdLogFile=/var/log/slurm/slurmd.log
SlurmSchedLogFile=/var/log/slurm/slurmsched.log

# State
StateSaveLocation=/var/spool/slurm/state
SlurmdSpoolDir=/var/spool/slurm/d

# Timeouts
SlurmctldTimeout=300
SlurmdTimeout=300
InactiveLimit=0
MinJobAge=300
KillWait=30
Waittime=0

# Process Tracking
ProctrackType=proctrack/cgroup
TaskPlugin=task/cgroup

# Accounting
AccountingStorageType={self.config['slurm_config']['accounting']['storage_type']}
JobAcctGatherType=jobacct_gather/cgroup

# Compute Nodes
"""
        
        # ê³„ì‚° ë…¸ë“œ ì¶”ê°€
        for node in self.config['nodes']['compute_nodes']:
            hostname = node['hostname']
            ip_address = node.get('ip_address', hostname)
            hardware = node['hardware']
            cpus = hardware.get('cpus', 1)
            sockets = hardware.get('sockets', 1)
            cores_per_socket = hardware.get('cores_per_socket', cpus // sockets)
            threads_per_core = hardware.get('threads_per_core', 1)
            memory_mb = hardware.get('memory_mb', 1024)
            
            slurm_conf += f"NodeName={hostname} NodeAddr={ip_address} CPUs={cpus} Sockets={sockets} CoresPerSocket={cores_per_socket} ThreadsPerCore={threads_per_core} RealMemory={memory_mb} State=UNKNOWN\n"
        
        # íŒŒí‹°ì…˜ ì¶”ê°€
        slurm_conf += "\n# Partitions\n"
        for partition in self.config['slurm_config']['partitions']:
            name = partition['name']
            nodes = partition['nodes']
            default = "YES" if partition.get('default', False) else "NO"
            max_time = partition.get('max_time', 'INFINITE')
            state = partition.get('state', 'UP')
            
            slurm_conf += f"PartitionName={name} Nodes={nodes} Default={default} MaxTime={max_time} State={state}\n"
        
        # ì»¨íŠ¸ë¡¤ëŸ¬ì— ë””ë ‰í† ë¦¬ ìƒì„± ë° slurm.conf ì—…ë¡œë“œ
        config_path = self.config['slurm_config']['config_path']
        
        print(f"    ðŸ“ ì»¨íŠ¸ë¡¤ëŸ¬ ë””ë ‰í† ë¦¬ ìƒì„±: {config_path}")
        self.ssh_manager.execute_command(
            controller_hostname,
            f"sudo mkdir -p {config_path} /var/log/slurm /var/spool/slurm/state",
            show_output=False
        )
        
        print(f"    ðŸ“ ì»¨íŠ¸ë¡¤ëŸ¬ì— slurm.conf ìƒì„±")
        # íŒŒì¼ ë‚´ìš©ì„ ìž„ì‹œ íŒŒì¼ë¡œ ì €ìž¥ í›„ ë³µì‚¬
        import tempfile
        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.conf') as f:
            f.write(slurm_conf)
            temp_file = f.name
        
        try:
            # ì»¨íŠ¸ë¡¤ëŸ¬ë¡œ íŒŒì¼ ì—…ë¡œë“œ
            self.ssh_manager.connections[controller_hostname].upload_file(
                temp_file, f"/tmp/slurm.conf"
            )
            # sudoë¡œ ì´ë™ ë° ê¶Œí•œ ì„¤ì •
            self.ssh_manager.execute_command(
                controller_hostname,
                f"sudo mv /tmp/slurm.conf {config_path}/slurm.conf && sudo chown slurm:slurm {config_path}/slurm.conf && sudo chmod 644 {config_path}/slurm.conf",
                show_output=False
            )
        except:
            # ì—…ë¡œë“œ ì‹¤íŒ¨ì‹œ echo ëª…ë ¹ì–´ ì‚¬ìš©
            self.ssh_manager.execute_command(
                controller_hostname,
                f"sudo bash -c 'cat > {config_path}/slurm.conf << \'EOFSLURM\'\n{slurm_conf}\nEOFSLURM' && sudo chown slurm:slurm {config_path}/slurm.conf && sudo chmod 644 {config_path}/slurm.conf",
                show_output=False
            )
        finally:
            import os
            os.unlink(temp_file)
        
        # ëª¨ë“  ê³„ì‚° ë…¸ë“œì— ë³µì‚¬ (IP ì£¼ì†Œ ì‚¬ìš©)
        for node in self.config['nodes']['compute_nodes']:
            hostname = node['hostname']
            ip_address = node.get('ip_address', hostname)
            
            print(f"    ðŸ“¤ {hostname} ({ip_address})ì— ë³µì‚¬ ì¤‘...")
            
            # 1. ëŒ€ìƒ ë…¸ë“œì— ë””ë ‰í† ë¦¬ ìƒì„±
            self.ssh_manager.execute_command(
                hostname,
                f"sudo mkdir -p {config_path} /var/log/slurm /var/spool/slurm/d && sudo chown -R slurm:slurm /var/log/slurm /var/spool/slurm",
                show_output=False,
                timeout=10
            )
            
            # 2. ì»¨íŠ¸ë¡¤ëŸ¬ì—ì„œ scpë¡œ ë³µì‚¬ (IP ì£¼ì†Œ ì‚¬ìš©, SSH ì˜µì…˜ ì¶”ê°€)
            self.ssh_manager.execute_command(
                controller_hostname,
                f"scp -o StrictHostKeyChecking=no -o ConnectTimeout=10 {config_path}/slurm.conf {ip_address}:/tmp/slurm.conf 2>&1",
                show_output=False,
                timeout=30
            )
            
            # 3. sudoë¡œ ì´ë™ ë° ê¶Œí•œ ì„¤ì •
            self.ssh_manager.execute_command(
                hostname,
                f"sudo mv /tmp/slurm.conf {config_path}/slurm.conf && sudo chown slurm:slurm {config_path}/slurm.conf && sudo chmod 644 {config_path}/slurm.conf",
                show_output=False
            )
        
        print(f"    âœ… slurm.conf ìƒì„± ì™„ë£Œ")
        return True
    
    def setup_cgroup(self) -> bool:
        """cgroup ì„¤ì •"""
        print("  âš™ï¸  cgroup ì„¤ì • ì¤‘...")
        
        cgroup_conf = """CgroupAutomount=yes
ConstrainCores=yes
ConstrainRAMSpace=yes
ConstrainSwapSpace=yes
"""
        
        config_path = self.config['slurm_config']['config_path']
        
        for node in self.all_nodes:
            hostname = node['hostname']
            
            self.ssh_manager.execute_command(
                hostname,
                f"sudo bash -c 'cat > {config_path}/cgroup.conf << \'EOF\'\n{cgroup_conf}\nEOF' && sudo chown slurm:slurm {config_path}/cgroup.conf && sudo chmod 644 {config_path}/cgroup.conf",
                show_output=False
            )
        
        print(f"    âœ… cgroup ì„¤ì • ì™„ë£Œ")
        return True
    
    def setup_environment(self) -> bool:
        """í™˜ê²½ë³€ìˆ˜ ì„¤ì •"""
        print("  ðŸŒ í™˜ê²½ë³€ìˆ˜ ì„¤ì • ì¤‘...")
        
        install_path = self.config['slurm_config']['install_path']
        
        env_script = f"""# Slurm Environment
export PATH={install_path}/bin:{install_path}/sbin:$PATH
export LD_LIBRARY_PATH={install_path}/lib:$LD_LIBRARY_PATH
export MANPATH={install_path}/share/man:$MANPATH
"""
        
        for node in self.all_nodes:
            hostname = node['hostname']
            
            self.ssh_manager.execute_command(
                hostname,
                f"sudo bash -c 'cat > /etc/profile.d/slurm.sh << \'EOF\'\n{env_script}\nEOF' && sudo chmod 644 /etc/profile.d/slurm.sh",
                show_output=False
            )
        
        print(f"    âœ… í™˜ê²½ë³€ìˆ˜ ì„¤ì • ì™„ë£Œ")
        return True


def main():
    """í…ŒìŠ¤íŠ¸ ë©”ì¸"""
    import yaml
    import argparse

    # ì»¤ë§¨ë“œë¼ì¸ ì¸ìž íŒŒì‹±
    parser = argparse.ArgumentParser(description='Slurm ì™„ì „ ìžë™ ì„¤ì¹˜ ë³´ì™„ ëª¨ë“ˆ')
    parser.add_argument('--only-hosts', action='store_true',
                        help='/etc/hosts ì„¤ì •ë§Œ ìˆ˜í–‰ (SSH í‚¤ ì„¤ì • í¬í•¨)')
    parser.add_argument('--skip-munge', action='store_true',
                        help='Munge ì„¤ì • ê±´ë„ˆë›°ê¸° (ì´ë¯¸ ì„¤ì¹˜ëœ ê²½ìš°)')
    parser.add_argument('--skip-slurm-conf', action='store_true',
                        help='slurm.conf ìƒì„± ê±´ë„ˆë›°ê¸° (ì´ë¯¸ ìƒì„±ëœ ê²½ìš°)')
    parser.add_argument('--skip-cgroup', action='store_true',
                        help='cgroup ì„¤ì • ê±´ë„ˆë›°ê¸° (ì´ë¯¸ ì„¤ì •ëœ ê²½ìš°)')
    parser.add_argument('--skip-nfs', action='store_true',
                        help='NFS ì„¤ì • ê±´ë„ˆë›°ê¸°')
    args = parser.parse_args()

    config_file = Path("my_cluster.yaml")
    if not config_file.exists():
        print("âŒ my_cluster.yaml íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    with open(config_file, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)

    # SSHManager ìƒì„± ë° ë…¸ë“œ ì¶”ê°€
    ssh_mgr = ssh_manager.SSHManager()

    # ëª¨ë“  ë…¸ë“œ ì¶”ê°€
    all_nodes = [config['nodes']['controller']] + config['nodes']['compute_nodes']

    # viz-nodeì´ ìžˆìœ¼ë©´ ì¶”ê°€
    if 'viz_nodes' in config['nodes']:
        all_nodes += config['nodes']['viz_nodes']

    for node in all_nodes:
        ssh_mgr.add_node(node)

    # ì—°ê²°
    ssh_mgr.connect_all_nodes()

    setup = SlurmAutoSetup(config, ssh_mgr)

    # --only-hosts ì˜µì…˜: /etc/hosts ì„¤ì •ë§Œ ìˆ˜í–‰
    if args.only_hosts:
        print("\nðŸ”§ /etc/hosts ì„¤ì •ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤...")
        setup.setup_ssh_keys()  # SSH í‚¤ ì„¤ì • (ë‚´ë¶€ì— /etc/hosts í¬í•¨)
    else:
        # ì „ì²´ ì„¤ì • ìˆ˜í–‰ (ì„ íƒì ìœ¼ë¡œ ë‹¨ê³„ ê±´ë„ˆë›°ê¸°)
        print("\nðŸ”§ Slurm ì™„ì „ ìžë™ ì„¤ì¹˜ ì‹œìž‘...")

        steps = [
            ("SSH í‚¤ ìžë™ ì„¤ì •", setup.setup_ssh_keys, False),
            ("ë°©í™”ë²½ ì„¤ì •", setup.configure_firewall, False),
            ("SELinux ì„¤ì •", setup.configure_selinux, False),
            ("NTP ì‹œê°„ ë™ê¸°í™”", setup.setup_ntp, False),
            ("í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜", setup.install_dependencies, False),
            ("Munge ì¸ì¦ ì„¤ì •", setup.setup_munge, args.skip_munge),
            ("NFS ê³µìœ  ìŠ¤í† ë¦¬ì§€", setup.setup_nfs, args.skip_nfs),
            ("slurm.conf ìƒì„±", setup.generate_slurm_conf, args.skip_slurm_conf),
            ("cgroup ì„¤ì •", setup.setup_cgroup, args.skip_cgroup),
            ("í™˜ê²½ë³€ìˆ˜ ì„¤ì •", setup.setup_environment, False),
        ]

        for step_name, step_func, skip in steps:
            if skip:
                print(f"\nâ­ï¸  {step_name} (ê±´ë„ˆëœ€)")
                continue

            print(f"\nðŸ“Œ {step_name}...")
            try:
                if not step_func():
                    print(f"  âš ï¸  {step_name} ì‹¤íŒ¨ (ê³„ì† ì§„í–‰)")
            except Exception as e:
                print(f"  âŒ {step_name} ì˜¤ë¥˜: {e}")

        print("\nâœ… Slurm ì™„ì „ ìžë™ ì„¤ì¹˜ ì™„ë£Œ!")

    # ì—°ê²° ì¢…ë£Œ
    ssh_mgr.disconnect_all()


if __name__ == '__main__':
    main()
