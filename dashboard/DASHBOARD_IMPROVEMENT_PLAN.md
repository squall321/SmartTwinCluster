# ğŸ“‹ Dashboard í”„ë¡œì íŠ¸ ê°œì„  ê³„íš (Phase 1-6)

> **í”„ë¡œì íŠ¸:** Slurm Cluster Management Dashboard
> **ë²„ì „:** v4.0 â†’ v5.0
> **ì‘ì„±ì¼:** 2025-11-05
> **ëª©í‘œ:** Apptainer í†µí•©, Template ì²´ê³„í™”, ë³´ì•ˆ/ì¸í”„ë¼ ê°•í™”

---

## âš ï¸ ê°œë°œ ê·œì¹™ ë° ê°€ì´ë“œë¼ì¸

### ğŸ”’ í•µì‹¬ ì›ì¹™ (MUST FOLLOW)

#### 1. ì‹œìŠ¤í…œ ì•ˆì •ì„± ë³´ì¥
- âœ… **ê¸°ì¡´ ì‹œìŠ¤í…œ ë³´í˜¸**: í˜„ì¬ ì˜ ë™ì‘í•˜ëŠ” ì‹œìŠ¤í…œì— ì˜í–¥ì„ ì£¼ì§€ ì•Šë„ë¡ ìµœëŒ€í•œ ì£¼ì˜
- âœ… **ì ì§„ì  ê°œì„ **: í•œ ë²ˆì— í•˜ë‚˜ì˜ ê¸°ëŠ¥ë§Œ ìˆ˜ì •í•˜ê³  ì² ì €íˆ í…ŒìŠ¤íŠ¸
- âœ… **ë¡¤ë°± ê°€ëŠ¥ì„±**: ëª¨ë“  ë³€ê²½ì‚¬í•­ì€ ë¡¤ë°± ê°€ëŠ¥í•˜ë„ë¡ ë°±ì—… ìœ ì§€
- âœ… **ì˜ì¡´ì„± ìµœì†Œí™”**: ìƒˆë¡œìš´ ê¸°ëŠ¥ì´ ê¸°ì¡´ ê¸°ëŠ¥ì— ì˜ì¡´í•˜ì§€ ì•Šë„ë¡ ë…ë¦½ì ìœ¼ë¡œ ì„¤ê³„

#### 2. ê·¼ë³¸ ì›ì¸ ë¶„ì„ ë° í•´ê²°
- âŒ **ì„ì‹œë°©í¸ ê¸ˆì§€**: "ë¹¨ë¦¬ ëŒì•„ê°€ê²Œ" í•˜ëŠ” ì„ì‹œ í•´ë²• ê¸ˆì§€
- âœ… **ê·¼ë³¸ ì›ì¸ ë¶„ì„**: ë¬¸ì œì˜ ê·¼ë³¸ ì›ì¸ì„ íŒŒì•…í•˜ê³  ê·¼ë³¸ì ìœ¼ë¡œ í•´ê²°
- âœ… **ë¬¸ì„œí™”**: ë¬¸ì œ ë°œìƒ ì›ì¸ê³¼ í•´ê²° ë°©ë²•ì„ ìƒì„¸íˆ ë¬¸ì„œí™”
- âœ… **ì¬ë°œ ë°©ì§€**: ë™ì¼í•œ ë¬¸ì œê°€ ë‹¤ì‹œ ë°œìƒí•˜ì§€ ì•Šë„ë¡ êµ¬ì¡°ì  ê°œì„ 

#### 3. ì†ŒìŠ¤ ì½”ë“œ ê¸°ë°˜ ìˆ˜ì •
- âŒ **ìš´ì˜ ì„œë²„ ì§ì ‘ ìˆ˜ì • ê¸ˆì§€**: ë°°í¬ëœ ì„œë²„ì˜ íŒŒì¼ì„ ì§ì ‘ ìˆ˜ì •í•˜ì§€ ë§ê²ƒ
- âœ… **ì†ŒìŠ¤ ì½”ë“œ ìˆ˜ì •**: ë¹Œë“œ ì „ ì†ŒìŠ¤ ì½”ë“œ ìˆ˜ì • (frontend_3010, backend_5010, websocket_5011)
- âœ… **Setup ìŠ¤í¬ë¦½íŠ¸ ìˆ˜ì •**: ë°°í¬ ê³¼ì • ë³€ê²½ì€ setup ìŠ¤í¬ë¦½íŠ¸ ìˆ˜ì • (phase*.sh)
- âœ… **ë²„ì „ ê´€ë¦¬**: ëª¨ë“  ë³€ê²½ì‚¬í•­ì€ Gitìœ¼ë¡œ ê´€ë¦¬

#### 4. ìë™ ë°°í¬ ì‹œìŠ¤í…œ í†µí•©
- âœ… **setup_cluster_full_multihead.sh í†µí•©**: ëª¨ë“  ë³€ê²½ì‚¬í•­ì´ ìë™ ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ì— ë°˜ì˜
- âœ… **ë©±ë“±ì„± ë³´ì¥**: ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰í•´ë„ ë™ì¼í•œ ê²°ê³¼ ë³´ì¥
- âœ… **ì—ëŸ¬ í•¸ë“¤ë§**: ê° Phaseì—ì„œ ì‹¤íŒ¨ ì‹œ ì ì ˆí•œ exit code ë°˜í™˜ ë° ë¡¤ë°±
- âœ… **ì˜ì¡´ì„± ê²€ì¦**: ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì „ í•„ìˆ˜ ì˜ì¡´ì„± ê²€ì¦

#### 5. ì‹ ê·œ ì„œë²„ ë°°í¬ ëŒ€ì‘
- âœ… **í—¤ë“œë…¸ë“œ ë…ë¦½ì„±**: í—¤ë“œë…¸ë“œ ì„¤ì •ë„ setup íŒŒì¼ì— í¬í•¨í•˜ì—¬ ìë™í™”
- âœ… **í™˜ê²½ ì„¤ì • íŒŒì¼í™”**: í•˜ë“œì½”ë”©ëœ ê²½ë¡œ/í¬íŠ¸/IP ëŒ€ì‹  í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” ì„¤ì • íŒŒì¼ ì‚¬ìš©
- âœ… **ì˜ì¡´ì„± ìë™ ì„¤ì¹˜**: í•„ìš”í•œ íŒ¨í‚¤ì§€, ë¼ì´ë¸ŒëŸ¬ë¦¬ ìë™ ì„¤ì¹˜
- âœ… **ì´ˆê¸° ë°ì´í„° ìƒì„±**: DB ì´ˆê¸°í™”, ìƒ˜í”Œ ë°ì´í„°, ê¸°ë³¸ í…œí”Œë¦¿ ìë™ ìƒì„±

#### 6. Job Submit ê°œì„  ìš°ì„ ìˆœìœ„
- âš ï¸ **í˜„ì¬ ìƒíƒœ**: Job submitì„ ì œì™¸í•œ ëŒ€ë¶€ë¶„ì˜ ê¸°ëŠ¥ì€ ì •ìƒ ë™ì‘
- âœ… **ì˜í–¥ ë²”ìœ„ íŒŒì•…**: ìˆ˜ì •ì´ ë‹¤ë¥¸ ì‹œìŠ¤í…œì— ë¯¸ì¹  ì˜í–¥ ì‚¬ì „ ë¶„ì„
- âœ… **ë‹¨ê³„ì  ê²€ì¦**: ê° ë‹¨ê³„ë§ˆë‹¤ Job submit ê¸°ëŠ¥ì´ ì œëŒ€ë¡œ ë™ì‘í•˜ëŠ”ì§€ ê²€ì¦
- âœ… **í†µí•© í…ŒìŠ¤íŠ¸**: Template â†’ File Upload â†’ Job Submit â†’ Monitoring ì „ì²´ í”Œë¡œìš° í…ŒìŠ¤íŠ¸

---

### ğŸ“ ê°œë°œ ì›Œí¬í”Œë¡œìš°

#### Phase ì‹œì‘ ì „
```bash
# 1. í˜„ì¬ ì‹œìŠ¤í…œ ìƒíƒœ ë°±ì—…
cd /home/koopark/claude/KooSlurmInstallAutomationRefactory
git add -A
git commit -m "Backup before Phase X implementation"

# 2. ê°œë°œ ë¸Œëœì¹˜ ìƒì„±
git checkout -b phase-X-feature-name

# 3. í˜„ì¬ ì‹œìŠ¤í…œ ë™ì‘ í™•ì¸
./cluster/tests/verify_system_health.sh  # ì¶”í›„ ìƒì„±
```

#### Phase ê°œë°œ ì¤‘
```bash
# 1. ì†ŒìŠ¤ ì½”ë“œ ìˆ˜ì • (frontend/backend/websocket)
# 2. Setup ìŠ¤í¬ë¦½íŠ¸ ìˆ˜ì • (í•„ìš” ì‹œ)
# 3. ë¡œì»¬ ë¹Œë“œ í…ŒìŠ¤íŠ¸
cd dashboard/frontend_3010 && npm run build
cd dashboard/backend_5010 && python -m pytest tests/

# 4. ë³€ê²½ì‚¬í•­ ì»¤ë°‹
git add modified_files
git commit -m "Phase X: Implement feature Y"
```

#### Phase ë°°í¬ ì „ ê²€ì¦
```bash
# 1. ìë™ ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ í…ŒìŠ¤íŠ¸ (Dry-run)
sudo ./cluster/setup/setup_cluster_full_multihead.sh --dry-run

# 2. ë‹¨ì¼ Phaseë§Œ í…ŒìŠ¤íŠ¸ (ì˜ˆ: Phase 5)
sudo ./cluster/setup/phase5_web_services.sh

# 3. ì „ì²´ ì‹œìŠ¤í…œ ë°°í¬
sudo ./cluster/setup/setup_cluster_full_multihead.sh

# 4. ë°°í¬ í›„ ê²€ì¦
./cluster/tests/verify_system_health.sh
curl http://192.168.0.201:5010/api/health
curl http://192.168.0.201:3010/
```

#### ë¡¤ë°± í”„ë¡œì„¸ìŠ¤
```bash
# ë¬¸ì œ ë°œìƒ ì‹œ ì´ì „ ë²„ì „ìœ¼ë¡œ ë¡¤ë°±
git checkout main
sudo ./cluster/setup/setup_cluster_full_multihead.sh
```

---

### ğŸ—‚ï¸ íŒŒì¼ ìˆ˜ì • ê°€ì´ë“œë¼ì¸

#### Frontend ìˆ˜ì • ì‹œ (frontend_3010)
```
âœ… ìˆ˜ì •í•´ì•¼ í•  ìœ„ì¹˜:
  - /home/koopark/claude/KooSlurmInstallAutomationRefactory/dashboard/frontend_3010/src/

âŒ ìˆ˜ì •í•˜ë©´ ì•ˆë˜ëŠ” ìœ„ì¹˜:
  - /home/koopark/web_services/frontend/  (ë°°í¬ëœ ë¹Œë“œ íŒŒì¼)

âœ… ë°°í¬ ë°©ë²•:
  1. frontend_3010ì—ì„œ ì†ŒìŠ¤ ìˆ˜ì •
  2. npm run build
  3. phase5_web_services.sh ì‹¤í–‰ (ìë™ìœ¼ë¡œ /home/koopark/web_services/frontend/ ë¡œ ë³µì‚¬)
```

#### Backend ìˆ˜ì • ì‹œ (backend_5010)
```
âœ… ìˆ˜ì •í•´ì•¼ í•  ìœ„ì¹˜:
  - /home/koopark/claude/KooSlurmInstallAutomationRefactory/dashboard/backend_5010/

âŒ ìˆ˜ì •í•˜ë©´ ì•ˆë˜ëŠ” ìœ„ì¹˜:
  - /home/koopark/web_services/backend/  (ë°°í¬ëœ ì„œë¹„ìŠ¤ íŒŒì¼)

âœ… ë°°í¬ ë°©ë²•:
  1. backend_5010ì—ì„œ ì†ŒìŠ¤ ìˆ˜ì •
  2. requirements.txt ì—…ë°ì´íŠ¸ (í•„ìš” ì‹œ)
  3. phase5_web_services.sh ì‹¤í–‰ (ìë™ìœ¼ë¡œ /home/koopark/web_services/backend/ ë¡œ ë³µì‚¬)
  4. sudo systemctl restart auth_backend (ë˜ëŠ” í•´ë‹¹ ì„œë¹„ìŠ¤)
```

#### Setup ìŠ¤í¬ë¦½íŠ¸ ìˆ˜ì • ì‹œ
```
âœ… ìˆ˜ì •í•´ì•¼ í•  ìœ„ì¹˜:
  - /home/koopark/claude/KooSlurmInstallAutomationRefactory/cluster/setup/phase*.sh

âœ… ìˆ˜ì • ê°€ì´ë“œ:
  1. ì—ëŸ¬ í•¸ë“¤ë§ ì¶”ê°€ (set -euo pipefail)
  2. ë¡œê·¸ í•¨ìˆ˜ ì‚¬ìš© (log_info, log_success, log_error)
  3. ì‹¤íŒ¨ ì‹œ exit 1 ë°˜í™˜
  4. ë©±ë“±ì„± ë³´ì¥ (ì´ë¯¸ ì„¤ì¹˜ëœ ê²½ìš° ìŠ¤í‚µ)
```

#### DB Schema ìˆ˜ì • ì‹œ
```
âœ… ìˆ˜ì • ìœ„ì¹˜:
  - dashboard/backend_5010/migrations/ (ìƒˆ ë§ˆì´ê·¸ë ˆì´ì…˜ íŒŒì¼ ìƒì„±)

âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒì„±:
  1. migrations/vX.X.X_feature_name.sql ìƒì„±
  2. UP migration (í…Œì´ë¸” ìƒì„±/ìˆ˜ì •)
  3. DOWN migration (ë¡¤ë°± ì¿¼ë¦¬)
  4. phase5_web_services.shì— ë§ˆì´ê·¸ë ˆì´ì…˜ ìë™ ì‹¤í–‰ ì¶”ê°€
```

---

### ğŸ§ª í…ŒìŠ¤íŠ¸ ê°€ì´ë“œë¼ì¸

#### í•„ìˆ˜ í…ŒìŠ¤íŠ¸ í•­ëª©
```bash
# 1. API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
curl -X GET http://192.168.0.201:5010/api/health
curl -X GET http://192.168.0.201:5010/api/nodes
curl -X POST http://192.168.0.201:5010/api/jobs/submit \
  -H "Authorization: Bearer $JWT_TOKEN" \
  -H "Content-Type: application/json" \
  -d @test_job.json

# 2. WebSocket ì—°ê²° í…ŒìŠ¤íŠ¸
wscat -c ws://192.168.0.201:5011

# 3. Frontend ì ‘ì† í…ŒìŠ¤íŠ¸
curl http://192.168.0.201:3010/

# 4. ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
sudo systemctl status auth_backend
sudo systemctl status prometheus

# 5. ë¡œê·¸ í™•ì¸
tail -f /var/log/web_services/auth_backend/app.log
tail -f /var/log/web_services/prometheus/prometheus.log
```

#### Phaseë³„ ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸
```markdown
Phase 1 (Apptainer Discovery):
- [ ] Compute Node ì´ë¯¸ì§€ ìŠ¤ìº” ì •ìƒ ë™ì‘
- [ ] ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì •ìƒ
- [ ] DBì— ì´ë¯¸ì§€ ì •ë³´ ì €ì¥ í™•ì¸
- [ ] API ì—”ë“œí¬ì¸íŠ¸ ì‘ë‹µ í™•ì¸
- [ ] ê¸°ì¡´ Job Submit ê¸°ëŠ¥ ì •ìƒ ë™ì‘

Phase 2 (Template Management):
- [ ] í…œí”Œë¦¿ ë””ë ‰í† ë¦¬ ìƒì„± í™•ì¸ (/shared/templates)
- [ ] YAML í…œí”Œë¦¿ íŒŒì¼ íŒŒì‹± ì •ìƒ
- [ ] DBì™€ íŒŒì¼ ì‹œìŠ¤í…œ ë™ê¸°í™” í™•ì¸
- [ ] Hot Reload ë™ì‘ í™•ì¸
- [ ] ê¸°ì¡´ Job Submit ê¸°ëŠ¥ ì •ìƒ ë™ì‘

Phase 3 (File Upload API):
- [ ] ì²­í¬ ì—…ë¡œë“œ ì •ìƒ ë™ì‘
- [ ] íŒŒì¼ ë¶„ë¥˜ (data/config) ì •ìƒ
- [ ] ëŒ€ìš©ëŸ‰ íŒŒì¼ (5GB+) ì—…ë¡œë“œ ì„±ê³µ
- [ ] ì—…ë¡œë“œ ì§„í–‰ë¥  WebSocket ì „ì†¡ í™•ì¸
- [ ] ê¸°ì¡´ Job Submit ê¸°ëŠ¥ ì •ìƒ ë™ì‘

... (ê° Phaseë§ˆë‹¤ ì²´í¬ë¦¬ìŠ¤íŠ¸ ì‘ì„±)
```

---

### ğŸ“ ë¬¸ì„œí™” ê·œì¹™

#### ì½”ë“œ ì£¼ì„
```python
# âœ… Good: ì™œ(Why) ì´ë ‡ê²Œ í–ˆëŠ”ì§€ ì„¤ëª…
def scan_apptainer_images(node: str):
    """
    íŠ¹ì • ë…¸ë“œì˜ Apptainer ì´ë¯¸ì§€ë¥¼ ìŠ¤ìº”í•©ë‹ˆë‹¤.

    SSH ì—°ê²° ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ë¥¼ 3ë²ˆ ìˆ˜í–‰í•˜ëŠ” ì´ìœ :
    - ë„¤íŠ¸ì›Œí¬ ì¼ì‹œì  ì¥ì•  ëŒ€ì‘
    - Compute Nodeì˜ ë¶€íŒ… ì¤‘ì¼ ê°€ëŠ¥ì„±

    Args:
        node: ìŠ¤ìº”í•  ë…¸ë“œ í˜¸ìŠ¤íŠ¸ëª… (ì˜ˆ: compute-node001)

    Returns:
        List[ApptainerImage]: ë°œê²¬ëœ ì´ë¯¸ì§€ ëª©ë¡

    Raises:
        SSHConnectionError: 3ë²ˆ ì¬ì‹œë„ í›„ì—ë„ ì—°ê²° ì‹¤íŒ¨
    """
```

#### Git ì»¤ë°‹ ë©”ì‹œì§€
```bash
# âœ… Good: êµ¬ì¡°í™”ëœ ì»¤ë°‹ ë©”ì‹œì§€
git commit -m "Phase 2: Add external template storage system

- Create /shared/templates directory structure
- Implement TemplateLoader with YAML parsing
- Add hot reload with watchdog
- Update phase5_web_services.sh to initialize template storage

Fixes: #123
Related: Phase 2.2 in DASHBOARD_IMPROVEMENT_PLAN.md"

# âŒ Bad: ëª¨í˜¸í•œ ì»¤ë°‹ ë©”ì‹œì§€
git commit -m "update files"
git commit -m "fix bug"
```

#### ë³€ê²½ ë¡œê·¸ (CHANGELOG.md)
```markdown
## [v4.1.0] - 2025-11-05

### Added
- External template storage system at /shared/templates
- TemplateLoader service for YAML template management
- Hot reload functionality for template changes

### Changed
- phase5_web_services.sh now initializes template directories
- Template API endpoints updated to v2

### Fixed
- Job submit failure when template contains special characters

### Migration Guide
1. Run: sudo ./cluster/setup/init_template_storage.sh
2. Restart backend: sudo systemctl restart auth_backend
3. Verify: curl http://192.168.0.201:5010/api/v2/templates/scan
```

---

## ğŸ¯ ê°œì„  ëª©í‘œ ìš”ì•½

### í•µì‹¬ ê°œì„  ì‚¬í•­
1. **Apptainer í†µí•©** - Compute Nodeì˜ .sif ì´ë¯¸ì§€ë¥¼ ë™ì ìœ¼ë¡œ ìŠ¤í¬ë¦½íŠ¸ì— í™œìš©
2. **Template ê´€ë¦¬ ì²´ê³„í™”** - ì‹œë®¬ë ˆì´ì…˜ íŒŒì¼, ì˜µì…˜ íŒŒì¼ ë¶„ë¥˜ ë° ê´€ë¦¬
3. **íŒŒì¼ ì—…ë¡œë“œ API ì²´ê³„í™”** - ë‹¤ì–‘í•œ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ í†µí•© API
4. **ë³´ì•ˆ ê°•í™”** - CORS, JWT Refresh, Rate Limiting, Input Validation
5. **ì¸í”„ë¼ ê°œì„ ** - Redis ìºì‹±, Nginx ìµœì í™”, ë¡œê¹… ì²´ê³„
6. **ì„±ëŠ¥ ìµœì í™”** - ë¹„ë™ê¸° ì²˜ë¦¬, ìºì‹± ì „ëµ, ì½”ë“œ ìŠ¤í”Œë¦¬íŒ…

---

## ğŸ“Š Phaseë³„ ê°œì„  ê³„íš

### Phase 1: Apptainer Discovery & Integration (2ì£¼)
**ëª©í‘œ:** Compute Nodeì˜ Apptainer ì´ë¯¸ì§€ë¥¼ ìë™ìœ¼ë¡œ ë°œê²¬í•˜ê³  ì‘ì—… ìŠ¤í¬ë¦½íŠ¸ì— í†µí•©

#### 1.1 Apptainer Discovery Service (Backend)
**ìƒˆ íŒŒì¼:** `backend_5010/apptainer_service.py`

```python
"""
Apptainer Discovery Service
Compute Nodeì˜ .sif ì´ë¯¸ì§€ë¥¼ ìŠ¤ìº”í•˜ê³  ë©”íƒ€ë°ì´í„°ë¥¼ ê´€ë¦¬
"""

class ApptainerService:
    def scan_node_images(self, node: str) -> List[ApptainerImage]:
        """ë…¸ë“œì˜ /opt/apptainers/ ìŠ¤ìº”"""

    def get_image_metadata(self, image_path: str) -> dict:
        """ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (apptainer inspect)"""

    def list_available_images(self, partition: str = None) -> List[ApptainerImage]:
        """íŒŒí‹°ì…˜ë³„ ì‚¬ìš© ê°€ëŠ¥í•œ ì´ë¯¸ì§€ ëª©ë¡"""

    def validate_image(self, image_path: str) -> bool:
        """ì´ë¯¸ì§€ ìœ íš¨ì„± ê²€ì¦"""

    def get_image_apps(self, image_path: str) -> List[str]:
        """ì´ë¯¸ì§€ ë‚´ë¶€ ì•± ëª©ë¡ ì¡°íšŒ"""
```

**ì£¼ìš” ê¸°ëŠ¥:**
- âœ… SSHë¥¼ í†µí•œ ì›ê²© ë…¸ë“œ ì´ë¯¸ì§€ ìŠ¤ìº”
- âœ… Apptainer inspect ëª…ë ¹ìœ¼ë¡œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
- âœ… ì´ë¯¸ì§€ ë¶„ë¥˜ (viz, compute, custom)
- âœ… ì´ë¯¸ì§€ ìºì‹± (Redis, TTL 1ì‹œê°„)
- âœ… ì´ë¯¸ì§€ ë²„ì „ ê´€ë¦¬

**API ì—”ë“œí¬ì¸íŠ¸:** `apptainer_api.py`
```
GET  /api/apptainer/images              # ëª¨ë“  ì´ë¯¸ì§€ ëª©ë¡
GET  /api/apptainer/images/{node}       # íŠ¹ì • ë…¸ë“œ ì´ë¯¸ì§€
GET  /api/apptainer/images/{id}/metadata # ì´ë¯¸ì§€ ìƒì„¸ ì •ë³´
GET  /api/apptainer/images/{id}/apps    # ì´ë¯¸ì§€ ë‚´ë¶€ ì•± ëª©ë¡
POST /api/apptainer/scan                # ì „ì²´ ë…¸ë“œ ìŠ¤ìº” íŠ¸ë¦¬ê±°
```

#### 1.2 Database Schema í™•ì¥
**í…Œì´ë¸”:** `apptainer_images`

```sql
CREATE TABLE apptainer_images (
    id TEXT PRIMARY KEY,                      -- UUID
    name TEXT NOT NULL,                       -- vnc_gnome.sif
    path TEXT NOT NULL,                       -- /opt/apptainers/vnc_gnome.sif
    node TEXT NOT NULL,                       -- viz-node001
    partition TEXT,                           -- viz, compute
    type TEXT CHECK(type IN ('viz', 'compute', 'custom')),
    size INTEGER,                             -- bytes
    version TEXT,                             -- 1.0.0
    description TEXT,
    labels TEXT,                              -- JSON: {"gpu": "required", "mpi": "true"}
    apps TEXT,                                -- JSON: ["python", "jupyter", "gedit"]
    runscript TEXT,                           -- Default runscript
    env_vars TEXT,                            -- JSON: environment variables
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    last_scanned DATETIME,
    is_active BOOLEAN DEFAULT 1
);

CREATE INDEX idx_images_node ON apptainer_images(node);
CREATE INDEX idx_images_partition ON apptainer_images(partition);
CREATE INDEX idx_images_type ON apptainer_images(type);
CREATE INDEX idx_images_active ON apptainer_images(is_active);
```

#### 1.3 Frontend Integration
**ìƒˆ ì»´í¬ë„ŒíŠ¸:** `frontend_3010/src/components/ApptainerSelector.tsx`

```typescript
interface ApptainerImage {
  id: string;
  name: string;
  path: string;
  node: string;
  partition: string;
  type: 'viz' | 'compute' | 'custom';
  apps: string[];
  description?: string;
  labels?: Record<string, string>;
}

interface ApptainerSelectorProps {
  partition?: string;
  onSelect: (image: ApptainerImage, app?: string) => void;
  selectedImage?: ApptainerImage;
}

export const ApptainerSelector: React.FC<ApptainerSelectorProps> = ({
  partition,
  onSelect,
  selectedImage
}) => {
  // ì´ë¯¸ì§€ ëª©ë¡ ì¡°íšŒ
  // íŒŒí‹°ì…˜ í•„í„°ë§
  // ì•± ì„ íƒ UI
  // ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° í‘œì‹œ
};
```

**ì£¼ìš” ê¸°ëŠ¥:**
- âœ… íŒŒí‹°ì…˜ë³„ ì´ë¯¸ì§€ í•„í„°ë§
- âœ… ì´ë¯¸ì§€ ë‚´ë¶€ ì•± ì„ íƒ (dropdown)
- âœ… ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° íˆ´íŒ
- âœ… GPU ìš”êµ¬ì‚¬í•­ í‘œì‹œ
- âœ… ìµœê·¼ ì‚¬ìš© ì´ë¯¸ì§€ ìš°ì„  í‘œì‹œ

#### 1.4 Slurm Script Template í†µí•©
**ìˆ˜ì •:** `backend_5010/templates_api.py`

```python
class JobScriptGenerator:
    def generate_script(self, template: dict, apptainer_image: str = None, app: str = None) -> str:
        """
        Slurm ì‘ì—… ìŠ¤í¬ë¦½íŠ¸ ìƒì„± (Apptainer í†µí•©)
        """
        script = "#!/bin/bash\n"
        script += f"#SBATCH --job-name={template['job_name']}\n"
        # ... ê¸°íƒ€ SBATCH ì˜µì…˜

        if apptainer_image:
            script += f"\n# Apptainer Container\n"
            script += f"CONTAINER={apptainer_image}\n"

            if app:
                # íŠ¹ì • ì•± ì‹¤í–‰
                script += f"apptainer exec $CONTAINER {app} $@\n"
            else:
                # Runscript ì‹¤í–‰
                script += f"apptainer run $CONTAINER $@\n"
        else:
            # ì¼ë°˜ ëª…ë ¹ì–´ ì‹¤í–‰
            script += template['command']

        return script
```

**ìŠ¤í¬ë¦½íŠ¸ ì˜ˆì‹œ:**
```bash
#!/bin/bash
#SBATCH --job-name=simulation_job
#SBATCH --partition=compute
#SBATCH --nodes=1
#SBATCH --ntasks=8
#SBATCH --time=01:00:00

# Apptainer Container
CONTAINER=/opt/apptainers/KooSimulationPython313.sif

# ì…ë ¥ íŒŒì¼ ë³µì‚¬
cp input_files/* $SLURM_SUBMIT_DIR/

# ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
apptainer exec $CONTAINER python simulation.py \
  --config config.json \
  --input input.dat \
  --output results/

# ê²°ê³¼ íŒŒì¼ ë³µì‚¬
cp results/* /shared/results/$SLURM_JOB_ID/
```

---

### Phase 2: Template Management System (2ì£¼)
**ëª©í‘œ:** ì²´ê³„ì ì¸ Template ê´€ë¦¬ ë° íŒŒì¼ ë¶„ë¥˜ ì‹œìŠ¤í…œ êµ¬ì¶•

#### 2.1 Template Schema í™•ì¥
**í…Œì´ë¸”:** `job_templates_v2`

```sql
CREATE TABLE job_templates_v2 (
    id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    display_name TEXT NOT NULL,           -- ì‚¬ìš©ì ì¹œí™”ì  ì´ë¦„
    description TEXT,
    category TEXT CHECK(category IN ('ml', 'cfd', 'structural', 'molecular', 'data', 'custom')),
    tags TEXT,                             -- JSON: ["gpu", "mpi", "openfoam"]

    -- Slurm ì„¤ì •
    partition TEXT,
    nodes INTEGER DEFAULT 1,
    ntasks INTEGER DEFAULT 1,
    cpus_per_task INTEGER DEFAULT 1,
    mem TEXT,                              -- "4G", "8G", etc.
    time TEXT DEFAULT "01:00:00",
    gres TEXT,                             -- "gpu:1"
    constraint TEXT,                       -- Node constraints

    -- Apptainer ì„¤ì •
    apptainer_image_id TEXT,               -- FK to apptainer_images
    apptainer_app TEXT,                    -- íŠ¹ì • ì•± (optional)
    apptainer_bind TEXT,                   -- JSON: bind mounts

    -- íŒŒì¼ ë¶„ë¥˜
    input_file_schema TEXT,                -- JSON: ì…ë ¥ íŒŒì¼ ìŠ¤í‚¤ë§ˆ
    option_file_schema TEXT,               -- JSON: ì˜µì…˜ íŒŒì¼ ìŠ¤í‚¤ë§ˆ
    output_file_pattern TEXT,              -- ì¶œë ¥ íŒŒì¼ íŒ¨í„´

    -- ìŠ¤í¬ë¦½íŠ¸
    pre_script TEXT,                       -- ì‹¤í–‰ ì „ ìŠ¤í¬ë¦½íŠ¸
    main_script TEXT,                      -- ë©”ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (í…œí”Œë¦¿)
    post_script TEXT,                      -- ì‹¤í–‰ í›„ ìŠ¤í¬ë¦½íŠ¸

    -- ë©”íƒ€ë°ì´í„°
    created_by TEXT,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    usage_count INTEGER DEFAULT 0,
    is_public BOOLEAN DEFAULT 0,
    version TEXT DEFAULT "1.0.0",

    FOREIGN KEY (apptainer_image_id) REFERENCES apptainer_images(id)
);

CREATE INDEX idx_templates_v2_category ON job_templates_v2(category);
CREATE INDEX idx_templates_v2_tags ON job_templates_v2(tags);
CREATE INDEX idx_templates_v2_public ON job_templates_v2(is_public);
```

#### 2.2 External Template Storage
**ëª©í‘œ:** í”„ë¡ íŠ¸ì—”ë“œ ë¹Œë“œì™€ ë…ë¦½ì ìœ¼ë¡œ í…œí”Œë¦¿ì„ ì™¸ë¶€ì—ì„œ ê´€ë¦¬

**í…œí”Œë¦¿ ì €ì¥ ìœ„ì¹˜:**
```
/shared/templates/
â”œâ”€â”€ official/              # ê³µì‹ í…œí”Œë¦¿ (ê´€ë¦¬ìë§Œ ìˆ˜ì •)
â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â”œâ”€â”€ pytorch_training.yaml
â”‚   â”‚   â”œâ”€â”€ tensorflow_training.yaml
â”‚   â”‚   â””â”€â”€ jupyter_notebook.yaml
â”‚   â”œâ”€â”€ cfd/
â”‚   â”‚   â”œâ”€â”€ openfoam_simulation.yaml
â”‚   â”‚   â””â”€â”€ fluent_simulation.yaml
â”‚   â”œâ”€â”€ structural/
â”‚   â”‚   â”œâ”€â”€ abaqus_analysis.yaml
â”‚   â”‚   â””â”€â”€ ansys_mechanical.yaml
â”‚   â””â”€â”€ molecular/
â”‚       â””â”€â”€ gromacs_simulation.yaml
â”œâ”€â”€ community/             # ì»¤ë®¤ë‹ˆí‹° í…œí”Œë¦¿ (ê³µìœ ëœ ì‚¬ìš©ì í…œí”Œë¦¿)
â”‚   â””â”€â”€ user_shared_*.yaml
â”œâ”€â”€ private/               # ê°œì¸ í…œí”Œë¦¿
â”‚   â”œâ”€â”€ user1/
â”‚   â”‚   â””â”€â”€ my_template.yaml
â”‚   â””â”€â”€ user2/
â”‚       â””â”€â”€ custom_workflow.yaml
â””â”€â”€ archived/              # ì•„ì¹´ì´ë¸Œëœ í…œí”Œë¦¿
    â””â”€â”€ old_templates/
```

**í…œí”Œë¦¿ íŒŒì¼ í˜•ì‹ (YAML):**
```yaml
# /shared/templates/official/ml/pytorch_training.yaml
template:
  id: pytorch-training-v1
  name: pytorch_training
  display_name: "PyTorch ëª¨ë¸ í•™ìŠµ"
  description: "PyTorchë¥¼ ì´ìš©í•œ ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ í…œí”Œë¦¿"
  category: ml
  tags: [gpu, pytorch, ml, deep-learning]
  version: "1.0.0"
  author: admin
  is_public: true

slurm:
  partition: gpu
  nodes: 1
  ntasks: 1
  cpus_per_task: 8
  mem: 32G
  time: "04:00:00"
  gres: gpu:1
  constraint: "gpu_v100|gpu_a100"

apptainer:
  image_name: "pytorch_cuda.sif"  # ì´ë¯¸ì§€ ì´ë¦„ìœ¼ë¡œ ìë™ ë§¤ì¹­
  app: python                      # íŠ¹ì • ì•± ì‹¤í–‰ (optional)
  bind:
    - /shared/datasets:/datasets:ro
    - /shared/models:/models:rw

files:
  input_schema:
    required:
      - name: training_script
        pattern: "*.py"
        description: "í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸"
        type: code
        max_size: 10MB
      - name: dataset
        pattern: "*.tar.gz"
        description: "ë°ì´í„°ì…‹ ì•„ì¹´ì´ë¸Œ"
        type: data
        max_size: 10GB
    optional:
      - name: pretrained_model
        pattern: "*.pth"
        description: "ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸"
        type: model
        max_size: 2GB

  config_schema:
    required:
      - name: config
        pattern: config.yaml
        format: yaml
        schema:
          type: object
          properties:
            learning_rate: {type: number, minimum: 0.0001, maximum: 1}
            batch_size: {type: integer, minimum: 1, maximum: 1024}
            epochs: {type: integer, minimum: 1}
            optimizer: {type: string, enum: [adam, sgd, rmsprop]}
          required: [learning_rate, batch_size, epochs]

  output_pattern: "checkpoints/*.pth"

script:
  pre_exec: |
    #!/bin/bash
    # ë°ì´í„°ì…‹ ì••ì¶• í•´ì œ
    mkdir -p $SLURM_SUBMIT_DIR/data
    tar -xzf dataset.tar.gz -C $SLURM_SUBMIT_DIR/data

    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
    export CUDA_VISIBLE_DEVICES=$SLURM_LOCALID

  main_exec: |
    #!/bin/bash
    # PyTorch í•™ìŠµ ì‹¤í–‰
    apptainer exec --nv $APPTAINER_IMAGE \
      python training_script.py \
        --config config.yaml \
        --data $SLURM_SUBMIT_DIR/data \
        --output $SLURM_SUBMIT_DIR/checkpoints

  post_exec: |
    #!/bin/bash
    # ê²°ê³¼ íŒŒì¼ ì •ë¦¬
    mkdir -p /shared/results/$SLURM_JOB_ID
    cp -r checkpoints /shared/results/$SLURM_JOB_ID/

    # ì„ì‹œ íŒŒì¼ ì •ë¦¬
    rm -rf $SLURM_SUBMIT_DIR/data

validation:
  pre_submit:
    - check_gpu_availability
    - validate_dataset_size
  post_submit:
    - notify_user
    - log_submission
```

**Template Loader Service:**
```python
# backend_5010/template_loader.py
import os
import yaml
import glob
from pathlib import Path
from typing import List, Dict, Optional
import hashlib

class TemplateLoader:
    def __init__(self, base_path: str = "/shared/templates"):
        self.base_path = Path(base_path)
        self.cache = {}  # ë©”ëª¨ë¦¬ ìºì‹œ
        self.cache_ttl = 300  # 5ë¶„

    def scan_templates(self, category: str = None) -> List[Dict]:
        """í…œí”Œë¦¿ ë””ë ‰í† ë¦¬ ìŠ¤ìº”"""
        templates = []

        # Official templates
        templates.extend(self._scan_directory(self.base_path / "official", "official"))

        # Community templates
        templates.extend(self._scan_directory(self.base_path / "community", "community"))

        if category:
            templates = [t for t in templates if t['category'] == category]

        return templates

    def _scan_directory(self, path: Path, source: str) -> List[Dict]:
        """ë””ë ‰í† ë¦¬ ë‚´ YAML í…œí”Œë¦¿ ìŠ¤ìº”"""
        templates = []

        for yaml_file in path.rglob("*.yaml"):
            try:
                template = self.load_template_file(yaml_file)
                template['source'] = source
                template['file_path'] = str(yaml_file)
                templates.append(template)
            except Exception as e:
                print(f"Failed to load template {yaml_file}: {e}")

        return templates

    def load_template_file(self, file_path: Path) -> Dict:
        """YAML í…œí”Œë¦¿ íŒŒì¼ ë¡œë“œ ë° íŒŒì‹±"""
        with open(file_path, 'r', encoding='utf-8') as f:
            data = yaml.safe_load(f)

        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        if 'template' not in data:
            raise ValueError("Missing 'template' section")

        # íŒŒì¼ í•´ì‹œ (ë²„ì „ ê´€ë¦¬)
        data['file_hash'] = self._calculate_hash(file_path)
        data['last_modified'] = file_path.stat().st_mtime

        return data

    def _calculate_hash(self, file_path: Path) -> str:
        """íŒŒì¼ í•´ì‹œ ê³„ì‚°"""
        with open(file_path, 'rb') as f:
            return hashlib.sha256(f.read()).hexdigest()

    def get_template(self, template_id: str) -> Optional[Dict]:
        """í…œí”Œë¦¿ IDë¡œ ì¡°íšŒ"""
        templates = self.scan_templates()
        for template in templates:
            if template['template']['id'] == template_id:
                return template
        return None

    def save_template(self, template_data: Dict, user_id: str, is_public: bool = False):
        """ìƒˆ í…œí”Œë¦¿ ì €ì¥"""
        category = template_data['template']['category']

        if is_public:
            # Community í…œí”Œë¦¿
            save_path = self.base_path / "community" / f"{template_data['template']['id']}.yaml"
        else:
            # Private í…œí”Œë¦¿
            user_dir = self.base_path / "private" / user_id
            user_dir.mkdir(parents=True, exist_ok=True)
            save_path = user_dir / f"{template_data['template']['id']}.yaml"

        with open(save_path, 'w', encoding='utf-8') as f:
            yaml.dump(template_data, f, default_flow_style=False, allow_unicode=True)

        return str(save_path)

    def update_template(self, template_id: str, template_data: Dict):
        """ê¸°ì¡´ í…œí”Œë¦¿ ì—…ë°ì´íŠ¸"""
        template = self.get_template(template_id)
        if not template:
            raise ValueError(f"Template {template_id} not found")

        file_path = Path(template['file_path'])

        with open(file_path, 'w', encoding='utf-8') as f:
            yaml.dump(template_data, f, default_flow_style=False, allow_unicode=True)

    def delete_template(self, template_id: str, user_id: str):
        """í…œí”Œë¦¿ ì‚­ì œ (ì•„ì¹´ì´ë¸Œë¡œ ì´ë™)"""
        template = self.get_template(template_id)
        if not template:
            raise ValueError(f"Template {template_id} not found")

        file_path = Path(template['file_path'])

        # Official í…œí”Œë¦¿ì€ ì‚­ì œ ë¶ˆê°€
        if 'official' in str(file_path):
            raise PermissionError("Cannot delete official templates")

        # ì•„ì¹´ì´ë¸Œë¡œ ì´ë™
        archive_path = self.base_path / "archived" / file_path.name
        archive_path.parent.mkdir(parents=True, exist_ok=True)
        file_path.rename(archive_path)

    def sync_to_database(self):
        """íŒŒì¼ ì‹œìŠ¤í…œì˜ í…œí”Œë¦¿ì„ DBì™€ ë™ê¸°í™”"""
        templates = self.scan_templates()

        # DBì— ìˆëŠ” í…œí”Œë¦¿ ëª©ë¡
        db_templates = get_all_templates_from_db()
        db_template_ids = {t['id'] for t in db_templates}

        # íŒŒì¼ì— ìˆëŠ” í…œí”Œë¦¿ ëª©ë¡
        file_template_ids = {t['template']['id'] for t in templates}

        # ìƒˆë¡œ ì¶”ê°€ëœ í…œí”Œë¦¿
        new_templates = file_template_ids - db_template_ids
        for template in templates:
            if template['template']['id'] in new_templates:
                insert_template_to_db(template)

        # ì‚­ì œëœ í…œí”Œë¦¿
        deleted_templates = db_template_ids - file_template_ids
        for template_id in deleted_templates:
            mark_template_as_deleted_in_db(template_id)

        # ìˆ˜ì •ëœ í…œí”Œë¦¿
        for template in templates:
            template_id = template['template']['id']
            if template_id in db_template_ids:
                db_template = get_template_from_db(template_id)
                if db_template['file_hash'] != template['file_hash']:
                    update_template_in_db(template)
```

**API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€:**
```python
# backend_5010/templates_api_v2.py

from template_loader import TemplateLoader

template_loader = TemplateLoader()

@app.route('/api/v2/templates/scan', methods=['POST'])
@jwt_required
def scan_templates():
    """í…œí”Œë¦¿ ë””ë ‰í† ë¦¬ ìŠ¤ìº” ë° DB ë™ê¸°í™”"""
    try:
        template_loader.sync_to_database()
        templates = template_loader.scan_templates()
        return jsonify({
            'message': 'Templates scanned successfully',
            'count': len(templates)
        }), 200
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/v2/templates/export/{id}', methods=['GET'])
@jwt_required
def export_template(id):
    """í…œí”Œë¦¿ì„ YAML íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
    template = template_loader.get_template(id)
    if not template:
        return jsonify({'error': 'Template not found'}), 404

    yaml_content = yaml.dump(template, default_flow_style=False, allow_unicode=True)

    return Response(
        yaml_content,
        mimetype='application/x-yaml',
        headers={'Content-Disposition': f'attachment;filename={id}.yaml'}
    )

@app.route('/api/v2/templates/import', methods=['POST'])
@jwt_required
def import_template():
    """YAML íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ í…œí”Œë¦¿ ê°€ì ¸ì˜¤ê¸°"""
    if 'file' not in request.files:
        return jsonify({'error': 'No file provided'}), 400

    file = request.files['file']
    is_public = request.form.get('is_public', 'false').lower() == 'true'

    try:
        template_data = yaml.safe_load(file.read())
        file_path = template_loader.save_template(
            template_data,
            g.user_id,
            is_public
        )

        return jsonify({
            'message': 'Template imported successfully',
            'file_path': file_path
        }), 201
    except Exception as e:
        return jsonify({'error': str(e)}), 400
```

**Template Hot Reload:**
```python
# backend_5010/template_watcher.py
import time
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

class TemplateFileHandler(FileSystemEventHandler):
    def __init__(self, template_loader: TemplateLoader):
        self.template_loader = template_loader

    def on_modified(self, event):
        if event.src_path.endswith('.yaml'):
            print(f"Template modified: {event.src_path}")
            self.template_loader.sync_to_database()

    def on_created(self, event):
        if event.src_path.endswith('.yaml'):
            print(f"New template: {event.src_path}")
            self.template_loader.sync_to_database()

    def on_deleted(self, event):
        if event.src_path.endswith('.yaml'):
            print(f"Template deleted: {event.src_path}")
            self.template_loader.sync_to_database()

def start_template_watcher():
    """í…œí”Œë¦¿ ë””ë ‰í† ë¦¬ ë³€ê²½ ê°ì§€"""
    event_handler = TemplateFileHandler(template_loader)
    observer = Observer()
    observer.schedule(event_handler, "/shared/templates", recursive=True)
    observer.start()

    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        observer.stop()

    observer.join()

# Flask ì•± ì‹œì‘ ì‹œ ë°±ê·¸ë¼ìš´ë“œë¡œ ì‹¤í–‰
import threading
watcher_thread = threading.Thread(target=start_template_watcher, daemon=True)
watcher_thread.start()
```

**ë””ë ‰í† ë¦¬ êµ¬ì¡° ì´ˆê¸°í™” ìŠ¤í¬ë¦½íŠ¸:**
```bash
#!/bin/bash
# cluster/setup/init_template_storage.sh

TEMPLATE_DIR="/shared/templates"

echo "Initializing template storage at $TEMPLATE_DIR"

# ë””ë ‰í† ë¦¬ ìƒì„±
sudo mkdir -p $TEMPLATE_DIR/{official,community,private,archived}
sudo mkdir -p $TEMPLATE_DIR/official/{ml,cfd,structural,molecular,data,custom}

# ê¶Œí•œ ì„¤ì •
sudo chown -R slurm:slurm $TEMPLATE_DIR
sudo chmod 755 $TEMPLATE_DIR
sudo chmod 755 $TEMPLATE_DIR/official
sudo chmod 777 $TEMPLATE_DIR/community
sudo chmod 777 $TEMPLATE_DIR/private
sudo chmod 755 $TEMPLATE_DIR/archived

# Official í…œí”Œë¦¿ì€ ì½ê¸° ì „ìš©
sudo chmod 644 $TEMPLATE_DIR/official/**/*.yaml 2>/dev/null || true

echo "Template storage initialized successfully"
echo "  - Official: $TEMPLATE_DIR/official (read-only)"
echo "  - Community: $TEMPLATE_DIR/community (shared)"
echo "  - Private: $TEMPLATE_DIR/private (user-specific)"
```

**ì¥ì :**
- âœ… í”„ë¡ íŠ¸ì—”ë“œ ë¹Œë“œ ì—†ì´ í…œí”Œë¦¿ ìˆ˜ì •/ì¶”ê°€ ê°€ëŠ¥
- âœ… Gitìœ¼ë¡œ í…œí”Œë¦¿ ë²„ì „ ê´€ë¦¬ ê°€ëŠ¥
- âœ… ë‹¤ì–‘í•œ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë™ì¼í•œ í…œí”Œë¦¿ ì‚¬ìš©
- âœ… ê´€ë¦¬ìê°€ SSHë¡œ í…œí”Œë¦¿ ì§ì ‘ ìˆ˜ì • ê°€ëŠ¥
- âœ… íŒŒì¼ ì‹œìŠ¤í…œ ê°ì‹œë¡œ ì‹¤ì‹œê°„ ë™ê¸°í™”
- âœ… YAML í˜•ì‹ìœ¼ë¡œ ê°€ë…ì„± ë†’ìŒ
- âœ… Import/Exportë¡œ í…œí”Œë¦¿ ê³µìœ  ê°€ëŠ¥

#### 2.3 File Schema Definition
**íŒŒì¼ ë¶„ë¥˜ JSON ìŠ¤í‚¤ë§ˆ:**

```json
{
  "input_file_schema": {
    "required_files": [
      {
        "name": "input_data",
        "pattern": "*.dat",
        "description": "ì‹œë®¬ë ˆì´ì…˜ ì…ë ¥ ë°ì´í„°",
        "type": "data",
        "max_size": "100MB",
        "validation": "validate_dat_format"
      },
      {
        "name": "mesh_file",
        "pattern": "*.msh",
        "description": "ë©”ì‰¬ íŒŒì¼",
        "type": "data",
        "max_size": "500MB"
      }
    ],
    "optional_files": [
      {
        "name": "initial_condition",
        "pattern": "init_*.dat",
        "description": "ì´ˆê¸° ì¡°ê±´ íŒŒì¼",
        "type": "data"
      }
    ]
  },
  "option_file_schema": {
    "required_files": [
      {
        "name": "config",
        "pattern": "config.json",
        "description": "ì‹œë®¬ë ˆì´ì…˜ ì„¤ì •",
        "type": "config",
        "format": "json",
        "schema": {
          "type": "object",
          "properties": {
            "timestep": {"type": "number"},
            "iterations": {"type": "integer"},
            "solver": {"type": "string", "enum": ["gmres", "cg"]}
          },
          "required": ["timestep", "iterations"]
        }
      }
    ],
    "optional_files": [
      {
        "name": "parameters",
        "pattern": "params.yaml",
        "description": "ì¶”ê°€ íŒŒë¼ë¯¸í„°",
        "type": "config",
        "format": "yaml"
      }
    ]
  },
  "output_file_pattern": "results_*.vtk"
}
```

#### 2.4 Template Manager API
**ìƒˆ íŒŒì¼:** `backend_5010/template_manager.py`

```python
class TemplateManager:
    def create_template(self, template_data: dict) -> str:
        """í…œí”Œë¦¿ ìƒì„± ë° íŒŒì¼ ìŠ¤í‚¤ë§ˆ ê²€ì¦"""

    def validate_input_files(self, template_id: str, files: List[FileUpload]) -> dict:
        """ì—…ë¡œë“œëœ íŒŒì¼ì´ ìŠ¤í‚¤ë§ˆì™€ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€ì¦"""

    def classify_files(self, files: List[FileUpload]) -> dict:
        """íŒŒì¼ì„ data/configë¡œ ë¶„ë¥˜"""

    def generate_job_script(self, template_id: str, files: dict, options: dict) -> str:
        """íŒŒì¼ê³¼ ì˜µì…˜ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì—… ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""

    def get_template_by_category(self, category: str) -> List[Template]:
        """ì¹´í…Œê³ ë¦¬ë³„ í…œí”Œë¦¿ ì¡°íšŒ"""

    def clone_template(self, template_id: str, new_name: str) -> str:
        """í…œí”Œë¦¿ ë³µì œ"""
```

**API ì—”ë“œí¬ì¸íŠ¸:** `templates_api_v2.py`
```
# Template CRUD
GET    /api/v2/templates                  # í…œí”Œë¦¿ ëª©ë¡
GET    /api/v2/templates/{id}             # í…œí”Œë¦¿ ìƒì„¸
POST   /api/v2/templates                  # í…œí”Œë¦¿ ìƒì„±
PUT    /api/v2/templates/{id}             # í…œí”Œë¦¿ ìˆ˜ì •
DELETE /api/v2/templates/{id}             # í…œí”Œë¦¿ ì‚­ì œ

# Template Operations
POST   /api/v2/templates/{id}/clone       # í…œí”Œë¦¿ ë³µì œ
POST   /api/v2/templates/{id}/validate    # íŒŒì¼ ê²€ì¦
POST   /api/v2/templates/{id}/generate    # ìŠ¤í¬ë¦½íŠ¸ ìƒì„±

# File Management
POST   /api/v2/templates/{id}/files       # íŒŒì¼ ì—…ë¡œë“œ
GET    /api/v2/templates/{id}/files       # íŒŒì¼ ëª©ë¡
DELETE /api/v2/templates/{id}/files/{name} # íŒŒì¼ ì‚­ì œ

# Categories & Tags
GET    /api/v2/templates/categories       # ì¹´í…Œê³ ë¦¬ ëª©ë¡
GET    /api/v2/templates/tags             # íƒœê·¸ ëª©ë¡
GET    /api/v2/templates/search?q=openfoam # ê²€ìƒ‰
```

#### 2.5 Frontend Template Manager
**ìƒˆ ì»´í¬ë„ŒíŠ¸:** `frontend_3010/src/components/TemplateManager/`

```typescript
// TemplateEditor.tsx - í…œí”Œë¦¿ ìƒì„±/ìˆ˜ì •
interface TemplateEditorProps {
  templateId?: string;
  onSave: (template: Template) => void;
}

// FileSchemaEditor.tsx - íŒŒì¼ ìŠ¤í‚¤ë§ˆ ì •ì˜
interface FileSchemaEditorProps {
  schema: FileSchema;
  onChange: (schema: FileSchema) => void;
}

// TemplatePreview.tsx - ìƒì„±ë  ìŠ¤í¬ë¦½íŠ¸ ë¯¸ë¦¬ë³´ê¸°
interface TemplatePreviewProps {
  template: Template;
  files: File[];
  options: Record<string, any>;
}

// TemplateLibrary.tsx - í…œí”Œë¦¿ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì¹´í…Œê³ ë¦¬ë³„ ë¸Œë¼ìš°ì§•)
interface TemplateLibraryProps {
  onSelect: (template: Template) => void;
}
```

**ì£¼ìš” ê¸°ëŠ¥:**
- âœ… Drag & Drop íŒŒì¼ ìŠ¤í‚¤ë§ˆ ë¹Œë”
- âœ… JSON Schema ê¸°ë°˜ ì˜µì…˜ íŒŒì¼ ê²€ì¦
- âœ… ì‹¤ì‹œê°„ ìŠ¤í¬ë¦½íŠ¸ ë¯¸ë¦¬ë³´ê¸°
- âœ… í…œí”Œë¦¿ ë²„ì „ ê´€ë¦¬
- âœ… í…œí”Œë¦¿ ê³µìœ  (public/private)

---

### Phase 3: Unified File Upload API (1.5ì£¼)
**ëª©í‘œ:** ë‹¤ì–‘í•œ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ í†µí•© íŒŒì¼ ì—…ë¡œë“œ API êµ¬ì¶•

#### 3.1 File Upload Service
**ìƒˆ íŒŒì¼:** `backend_5010/file_upload_service.py`

```python
class FileUploadService:
    def __init__(self):
        self.storage_root = "/shared/uploads"
        self.temp_dir = "/tmp/uploads"
        self.max_file_size = 5 * 1024 * 1024 * 1024  # 5GB

    def create_upload_session(self, user_id: str, template_id: str = None) -> str:
        """ì—…ë¡œë“œ ì„¸ì…˜ ìƒì„± (UUID ë°˜í™˜)"""

    def upload_chunk(self, session_id: str, chunk: bytes, chunk_index: int) -> dict:
        """ì²­í¬ ì—…ë¡œë“œ (ëŒ€ìš©ëŸ‰ íŒŒì¼ ì§€ì›)"""

    def finalize_upload(self, session_id: str) -> List[UploadedFile]:
        """ì—…ë¡œë“œ ì™„ë£Œ ë° íŒŒì¼ ë³‘í•©"""

    def validate_files(self, session_id: str, template_id: str) -> dict:
        """í…œí”Œë¦¿ ìŠ¤í‚¤ë§ˆì™€ íŒŒì¼ ê²€ì¦"""

    def organize_files(self, session_id: str) -> dict:
        """íŒŒì¼ ë¶„ë¥˜ (data/config)"""

    def get_upload_status(self, session_id: str) -> dict:
        """ì—…ë¡œë“œ ì§„í–‰ ìƒíƒœ"""

    def cleanup_session(self, session_id: str):
        """ì„¸ì…˜ ì •ë¦¬ (ì„ì‹œ íŒŒì¼ ì‚­ì œ)"""
```

#### 3.2 Upload API Endpoints
**ìƒˆ íŒŒì¼:** `backend_5010/upload_api_v2.py`

```python
# Session Management
POST   /api/v2/upload/sessions
    â†’ { "session_id": "uuid", "expires_at": "timestamp" }

GET    /api/v2/upload/sessions/{session_id}
    â†’ { "status": "active", "files": [...], "progress": 75 }

DELETE /api/v2/upload/sessions/{session_id}
    â†’ { "message": "Session cleaned up" }

# File Upload
POST   /api/v2/upload/sessions/{session_id}/files
    Content-Type: multipart/form-data
    Body: { "file": File, "file_type": "data|config" }
    â†’ { "file_id": "uuid", "name": "file.dat", "size": 1024 }

POST   /api/v2/upload/sessions/{session_id}/chunks
    Content-Type: application/octet-stream
    Headers: {
        "X-Chunk-Index": 0,
        "X-Total-Chunks": 10,
        "X-File-Name": "large_file.dat",
        "X-File-Type": "data"
    }
    â†’ { "chunk_id": "uuid", "received": true }

POST   /api/v2/upload/sessions/{session_id}/finalize
    â†’ { "files": [...], "total_size": 1024000 }

# Validation
POST   /api/v2/upload/sessions/{session_id}/validate
    Body: { "template_id": "uuid" }
    â†’ {
        "valid": true,
        "classified_files": {
            "data": ["input.dat", "mesh.msh"],
            "config": ["config.json"]
        },
        "errors": []
    }

# External Frontend Support
POST   /api/v2/upload/external
    Headers: { "Authorization": "Bearer <JWT>" }
    Body: {
        "template_id": "uuid",
        "files": [
            { "name": "file1.dat", "url": "https://..." },
            { "name": "config.json", "content": "{...}" }
        ]
    }
    â†’ { "job_id": "uuid", "status": "submitted" }
```

#### 3.3 Upload Progress WebSocket
**ì¶”ê°€:** `websocket_5011/upload_events.py`

```python
# WebSocket ì´ë²¤íŠ¸
{
    "type": "upload_progress",
    "session_id": "uuid",
    "file_name": "large_file.dat",
    "progress": 45,  # 0-100
    "uploaded_bytes": 450000000,
    "total_bytes": 1000000000,
    "speed": "10 MB/s",
    "eta": "00:05:30"
}

{
    "type": "upload_complete",
    "session_id": "uuid",
    "files": [...]
}

{
    "type": "upload_error",
    "session_id": "uuid",
    "error": "File validation failed"
}
```

#### 3.4 Frontend Upload Component
**ìƒˆ ì»´í¬ë„ŒíŠ¸:** `frontend_3010/src/components/FileUpload/`

```typescript
// UnifiedUploader.tsx
interface UnifiedUploaderProps {
  templateId?: string;
  onComplete: (files: UploadedFile[]) => void;
  maxFileSize?: number;
  acceptedTypes?: string[];
}

export const UnifiedUploader: React.FC<UnifiedUploaderProps> = ({
  templateId,
  onComplete,
  maxFileSize = 5 * 1024 * 1024 * 1024, // 5GB
  acceptedTypes
}) => {
  // Drag & Drop ì§€ì›
  // ë‹¤ì¤‘ íŒŒì¼ ì—…ë¡œë“œ
  // ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²­í¬ ì—…ë¡œë“œ
  // ì‹¤ì‹œê°„ ì§„í–‰ë¥  í‘œì‹œ (WebSocket)
  // íŒŒì¼ ë¶„ë¥˜ UI (data/config)
  // íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°
  // ì—…ë¡œë“œ ì·¨ì†Œ/ì¬ì‹œë„
};

// ChunkUploader.ts - ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²­í¬ ì—…ë¡œë“œ ìœ í‹¸ë¦¬í‹°
class ChunkUploader {
  async uploadFile(file: File, sessionId: string, onProgress: (progress: number) => void) {
    const chunkSize = 10 * 1024 * 1024; // 10MB chunks
    const totalChunks = Math.ceil(file.size / chunkSize);

    for (let i = 0; i < totalChunks; i++) {
      const chunk = file.slice(i * chunkSize, (i + 1) * chunkSize);
      await this.uploadChunk(sessionId, chunk, i, totalChunks, file.name);
      onProgress((i + 1) / totalChunks * 100);
    }
  }
}
```

#### 3.5 External Frontend Integration Example
**ì™¸ë¶€ í”„ë¡ íŠ¸ì—”ë“œ (React/Vue/Angular)ì—ì„œ ì‚¬ìš©:**

```javascript
// Example: External App Integration
const uploadFiles = async (files, templateId, jwtToken) => {
  // 1. Create upload session
  const sessionResponse = await fetch('http://api.example.com/api/v2/upload/sessions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${jwtToken}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({ template_id: templateId })
  });
  const { session_id } = await sessionResponse.json();

  // 2. Upload files
  for (const file of files) {
    const formData = new FormData();
    formData.append('file', file);
    formData.append('file_type', detectFileType(file.name));

    await fetch(`http://api.example.com/api/v2/upload/sessions/${session_id}/files`, {
      method: 'POST',
      headers: { 'Authorization': `Bearer ${jwtToken}` },
      body: formData
    });
  }

  // 3. Validate and submit
  const validateResponse = await fetch(`http://api.example.com/api/v2/upload/sessions/${session_id}/validate`, {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${jwtToken}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({ template_id: templateId })
  });

  return validateResponse.json();
};
```

---

### Phase 4: Security & Infrastructure (2ì£¼)
**ëª©í‘œ:** ë³´ì•ˆ ê°•í™” ë° ì¸í”„ë¼ ìµœì í™”

#### 4.1 JWT Refresh Token System
**ìƒˆ íŒŒì¼:** `auth_portal_4430/token_service.py`

```python
class TokenService:
    def generate_access_token(self, user_id: str, permissions: List[str]) -> str:
        """Access Token (15ë¶„ ìœ íš¨)"""
        return jwt.encode({
            'user_id': user_id,
            'permissions': permissions,
            'type': 'access',
            'exp': datetime.utcnow() + timedelta(minutes=15)
        }, SECRET_KEY, algorithm='HS256')

    def generate_refresh_token(self, user_id: str) -> str:
        """Refresh Token (7ì¼ ìœ íš¨, Redis ì €ì¥)"""
        token = jwt.encode({
            'user_id': user_id,
            'type': 'refresh',
            'exp': datetime.utcnow() + timedelta(days=7)
        }, SECRET_KEY, algorithm='HS256')

        # Redisì— ì €ì¥ (token revocation ì§€ì›)
        redis_client.setex(f"refresh_token:{user_id}", 7*24*3600, token)
        return token

    def refresh_access_token(self, refresh_token: str) -> str:
        """Refresh Tokenìœ¼ë¡œ ìƒˆ Access Token ë°œê¸‰"""
        payload = jwt.decode(refresh_token, SECRET_KEY, algorithms=['HS256'])
        user_id = payload['user_id']

        # Redisì—ì„œ ê²€ì¦
        stored_token = redis_client.get(f"refresh_token:{user_id}")
        if stored_token != refresh_token:
            raise InvalidTokenError("Token revoked or invalid")

        return self.generate_access_token(user_id, get_user_permissions(user_id))

    def revoke_refresh_token(self, user_id: str):
        """Refresh Token ë¬´íš¨í™” (ë¡œê·¸ì•„ì›ƒ)"""
        redis_client.delete(f"refresh_token:{user_id}")
```

**API ì—”ë“œí¬ì¸íŠ¸:**
```
POST /api/auth/refresh
    Body: { "refresh_token": "..." }
    â†’ { "access_token": "...", "expires_in": 900 }

POST /api/auth/logout
    Headers: { "Authorization": "Bearer <access_token>" }
    â†’ { "message": "Logged out successfully" }
```

#### 4.2 CORS Configuration (Production)
**ìˆ˜ì •:** `backend_5010/app.py`

```python
from flask_cors import CORS

# Development
if os.getenv('FLASK_ENV') == 'development':
    CORS(app, origins='*')
else:
    # Production - íŠ¹ì • originë§Œ í—ˆìš©
    CORS(app,
         origins=[
             'https://dashboard.example.com',
             'https://cae.example.com',
             'https://auth.example.com'
         ],
         supports_credentials=True,
         allow_headers=['Content-Type', 'Authorization'],
         expose_headers=['X-Total-Count', 'X-Page-Count'],
         max_age=3600)  # Preflight cache 1ì‹œê°„
```

**Nginx CORS ì„¤ì •:**
```nginx
# /etc/nginx/sites-available/dashboard
location /api/ {
    # Preflight OPTIONS ì²˜ë¦¬
    if ($request_method = 'OPTIONS') {
        add_header 'Access-Control-Allow-Origin' 'https://dashboard.example.com';
        add_header 'Access-Control-Allow-Methods' 'GET, POST, PUT, DELETE, OPTIONS';
        add_header 'Access-Control-Allow-Headers' 'Authorization, Content-Type';
        add_header 'Access-Control-Max-Age' 3600;
        add_header 'Content-Length' 0;
        add_header 'Content-Type' 'text/plain';
        return 204;
    }

    proxy_pass http://localhost:5010;
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
}
```

#### 4.3 Rate Limiting
**ìƒˆ íŒŒì¼:** `backend_5010/middleware/rate_limiter.py`

```python
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address

limiter = Limiter(
    app,
    key_func=get_remote_address,
    storage_uri="redis://localhost:6379",
    default_limits=["200 per day", "50 per hour"]
)

# APIë³„ ì œí•œ
@app.route('/api/jobs/submit')
@limiter.limit("10 per minute")  # ì‘ì—… ì œì¶œ: ë¶„ë‹¹ 10íšŒ
def submit_job():
    pass

@app.route('/api/nodes/<node>/reboot')
@limiter.limit("5 per hour")  # ë…¸ë“œ ì¬ë¶€íŒ…: ì‹œê°„ë‹¹ 5íšŒ
def reboot_node(node):
    pass

@app.route('/api/upload/sessions/<session_id>/files')
@limiter.limit("100 per hour")  # íŒŒì¼ ì—…ë¡œë“œ: ì‹œê°„ë‹¹ 100ê°œ
def upload_file(session_id):
    pass
```

#### 4.4 Input Validation
**ìƒˆ íŒŒì¼:** `backend_5010/validators.py`

```python
from marshmallow import Schema, fields, validate, ValidationError

class JobSubmitSchema(Schema):
    job_name = fields.Str(required=True, validate=validate.Length(min=1, max=100))
    partition = fields.Str(required=True, validate=validate.OneOf(['compute', 'gpu', 'viz']))
    nodes = fields.Int(required=True, validate=validate.Range(min=1, max=100))
    ntasks = fields.Int(validate=validate.Range(min=1, max=1000))
    time = fields.Str(validate=validate.Regexp(r'^\d{2}:\d{2}:\d{2}$'))
    script = fields.Str(required=True, validate=validate.Length(min=1, max=10000))

class NodeActionSchema(Schema):
    action = fields.Str(required=True, validate=validate.OneOf(['drain', 'resume', 'reboot']))
    reason = fields.Str(validate=validate.Length(max=500))

# ì‚¬ìš© ì˜ˆì‹œ
@app.route('/api/jobs/submit', methods=['POST'])
@jwt_required
def submit_job():
    schema = JobSubmitSchema()
    try:
        data = schema.load(request.json)
    except ValidationError as err:
        return jsonify({'errors': err.messages}), 400

    # ì•ˆì „í•œ ë°ì´í„° ì‚¬ìš©
    job_id = submit_slurm_job(data)
    return jsonify({'job_id': job_id}), 201
```

#### 4.5 Redis Caching Strategy
**ìƒˆ íŒŒì¼:** `backend_5010/cache_manager.py`

```python
import redis
import json
from functools import wraps

redis_client = redis.Redis(
    host=os.getenv('REDIS_HOST', 'localhost'),
    port=int(os.getenv('REDIS_PORT', 6379)),
    password=os.getenv('REDIS_PASSWORD'),
    decode_responses=True
)

def cache_result(key_prefix: str, ttl: int = 300):
    """Redis ìºì‹± ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            # ìºì‹œ í‚¤ ìƒì„±
            cache_key = f"{key_prefix}:{':'.join(map(str, args))}"

            # ìºì‹œ í™•ì¸
            cached = redis_client.get(cache_key)
            if cached:
                return json.loads(cached)

            # í•¨ìˆ˜ ì‹¤í–‰
            result = func(*args, **kwargs)

            # ìºì‹œ ì €ì¥
            redis_client.setex(cache_key, ttl, json.dumps(result))
            return result
        return wrapper
    return decorator

# ì‚¬ìš© ì˜ˆì‹œ
@cache_result('sinfo', ttl=10)  # 10ì´ˆ ìºì‹±
def get_node_info():
    return subprocess.check_output(['sinfo', '-o', '%N,%C,%m,%t'], text=True)

@cache_result('squeue', ttl=5)  # 5ì´ˆ ìºì‹±
def get_job_queue():
    return subprocess.check_output(['squeue', '-o', '%i,%j,%u,%t,%M'], text=True)

@cache_result('apptainer_images', ttl=3600)  # 1ì‹œê°„ ìºì‹±
def get_apptainer_images(partition):
    return scan_apptainer_images(partition)
```

#### 4.6 Nginx Optimization
**Nginx ì„¤ì •:** `/etc/nginx/sites-available/dashboard`

```nginx
# Gzip ì••ì¶•
gzip on;
gzip_vary on;
gzip_proxied any;
gzip_comp_level 6;
gzip_types text/plain text/css text/xml text/javascript
           application/json application/javascript application/xml+rss;

# ì •ì  íŒŒì¼ ìºì‹±
location /assets/ {
    alias /var/www/html/dashboard_3010/assets/;
    expires 1y;
    add_header Cache-Control "public, immutable";
    access_log off;
}

location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2|ttf|eot)$ {
    expires 30d;
    add_header Cache-Control "public, immutable";
    access_log off;
}

# API í”„ë¡ì‹œ (ìºì‹± ì—†ìŒ)
location /api/ {
    proxy_pass http://localhost:5010;
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection 'upgrade';
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;

    # íƒ€ì„ì•„ì›ƒ ì„¤ì •
    proxy_connect_timeout 60s;
    proxy_send_timeout 60s;
    proxy_read_timeout 60s;

    # ë²„í¼ë§
    proxy_buffering on;
    proxy_buffer_size 4k;
    proxy_buffers 8 4k;
}

# WebSocket í”„ë¡ì‹œ
location /ws {
    proxy_pass http://localhost:5011;
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection "upgrade";
    proxy_set_header Host $host;

    # WebSocket íƒ€ì„ì•„ì›ƒ
    proxy_read_timeout 3600s;
    proxy_send_timeout 3600s;
}

# ì—…ë¡œë“œ í¬ê¸° ì œí•œ
client_max_body_size 5G;
client_body_buffer_size 128k;
client_body_timeout 300s;
```

#### 4.7 Logging System
**ìƒˆ íŒŒì¼:** `backend_5010/logger_config.py`

```python
import logging
import logging.handlers
import json
from datetime import datetime

class JSONFormatter(logging.Formatter):
    def format(self, record):
        log_data = {
            'timestamp': datetime.utcnow().isoformat(),
            'level': record.levelname,
            'logger': record.name,
            'message': record.getMessage(),
            'module': record.module,
            'function': record.funcName,
            'line': record.lineno
        }

        if record.exc_info:
            log_data['exception'] = self.formatException(record.exc_info)

        return json.dumps(log_data)

def setup_logging():
    # ë£¨íŠ¸ ë¡œê±°
    logger = logging.getLogger()
    logger.setLevel(logging.DEBUG if os.getenv('FLASK_DEBUG') else logging.INFO)

    # ì½˜ì†” í•¸ë“¤ëŸ¬
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(JSONFormatter())
    logger.addHandler(console_handler)

    # íŒŒì¼ í•¸ë“¤ëŸ¬ (ì¼ë³„ ë¡œí…Œì´ì…˜)
    file_handler = logging.handlers.TimedRotatingFileHandler(
        '/var/log/dashboard/app.log',
        when='midnight',
        interval=1,
        backupCount=30
    )
    file_handler.setFormatter(JSONFormatter())
    logger.addHandler(file_handler)

    # APIë³„ ë¡œê±°
    api_logger = logging.getLogger('api')
    api_file_handler = logging.handlers.TimedRotatingFileHandler(
        '/var/log/dashboard/api.log',
        when='midnight',
        interval=1,
        backupCount=30
    )
    api_file_handler.setFormatter(JSONFormatter())
    api_logger.addHandler(api_file_handler)

    return logger

# ì‚¬ìš© ì˜ˆì‹œ
logger = setup_logging()
api_logger = logging.getLogger('api')

@app.route('/api/jobs/submit', methods=['POST'])
def submit_job():
    api_logger.info('Job submission request', extra={
        'user_id': g.user_id,
        'ip': request.remote_addr,
        'template_id': request.json.get('template_id')
    })

    try:
        job_id = submit_slurm_job(request.json)
        api_logger.info('Job submitted successfully', extra={'job_id': job_id})
        return jsonify({'job_id': job_id}), 201
    except Exception as e:
        api_logger.error('Job submission failed', extra={'error': str(e)}, exc_info=True)
        return jsonify({'error': str(e)}), 500
```

---

### Phase 5: Performance Optimization (1.5ì£¼)
**ëª©í‘œ:** ë°±ì—”ë“œ/í”„ë¡ íŠ¸ì—”ë“œ ì„±ëŠ¥ ìµœì í™”

#### 5.1 Backend Async Processing
**ìˆ˜ì •:** `backend_5010/slurm_utils.py`

```python
import asyncio
import asyncssh

class AsyncSlurmClient:
    async def get_node_info_async(self, nodes: List[str]) -> dict:
        """ë³‘ë ¬ ë…¸ë“œ ì •ë³´ ì¡°íšŒ"""
        tasks = [self._query_node(node) for node in nodes]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        return {
            node: result if not isinstance(result, Exception) else None
            for node, result in zip(nodes, results)
        }

    async def _query_node(self, node: str) -> dict:
        """ë‹¨ì¼ ë…¸ë“œ ì •ë³´ ì¡°íšŒ"""
        async with asyncssh.connect(node, username='slurm') as conn:
            result = await conn.run('sinfo -n {} -o "%C,%m,%t"'.format(node))
            return self._parse_sinfo(result.stdout)

    async def submit_multiple_jobs(self, jobs: List[dict]) -> List[str]:
        """ë³‘ë ¬ ì‘ì—… ì œì¶œ"""
        tasks = [self._submit_job(job) for job in jobs]
        job_ids = await asyncio.gather(*tasks)
        return job_ids

    async def _submit_job(self, job: dict) -> str:
        """ë‹¨ì¼ ì‘ì—… ì œì¶œ"""
        script = generate_job_script(job)
        async with asyncssh.connect('slurmctld', username='slurm') as conn:
            result = await conn.run(f'sbatch', input=script)
            return extract_job_id(result.stdout)

# Flaskì—ì„œ ì‚¬ìš©
@app.route('/api/nodes/status', methods=['GET'])
async def get_nodes_status():
    client = AsyncSlurmClient()
    nodes = ['node001', 'node002', 'viz-node001', 'viz-node002']
    results = await client.get_node_info_async(nodes)
    return jsonify(results)
```

#### 5.2 Database Optimization
**ì¸ë±ìŠ¤ ì¶”ê°€ ë° ì¿¼ë¦¬ ìµœì í™”:**

```sql
-- ë³µí•© ì¸ë±ìŠ¤
CREATE INDEX idx_notifications_user_read ON notifications(created_by, read, timestamp DESC);
CREATE INDEX idx_templates_category_public ON job_templates_v2(category, is_public);
CREATE INDEX idx_jobs_user_status ON job_history(user_id, status, submit_time DESC);

-- ì¿¼ë¦¬ ìµœì í™”
EXPLAIN QUERY PLAN
SELECT * FROM notifications
WHERE created_by = 'user123' AND read = 0
ORDER BY timestamp DESC
LIMIT 20;

-- íŒŒí‹°ì…˜ ì¶”ê°€ (ëŒ€ìš©ëŸ‰ ë°ì´í„°)
-- job_history í…Œì´ë¸”ì„ ì›”ë³„ë¡œ íŒŒí‹°ì…˜
```

#### 5.3 Frontend Code Splitting
**ìˆ˜ì •:** `frontend_3010/vite.config.ts`

```typescript
import { defineConfig } from 'vite';
import react from '@vitejs/plugin-react';

export default defineConfig({
  plugins: [react()],
  build: {
    rollupOptions: {
      output: {
        manualChunks: {
          // Vendor chunks
          'react-vendor': ['react', 'react-dom', 'react-router-dom'],
          'ui-vendor': ['lucide-react', '@heroicons/react'],
          'state-vendor': ['zustand'],
          'chart-vendor': ['recharts'],
          '3d-vendor': ['three', '@react-three/fiber', '@react-three/drei'],

          // Feature chunks
          'job-management': [
            './src/components/JobManagement.tsx',
            './src/components/JobTemplates'
          ],
          'node-management': ['./src/components/NodeManagement'],
          'ssh-vnc': [
            './src/components/SSHSessionManager.tsx',
            './src/components/VNCSessionManager.tsx'
          ],
          'data-management': ['./src/components/DataManagement'],
          'reports': ['./src/components/Reports']
        }
      }
    },
    chunkSizeWarningLimit: 1000
  }
});
```

**Lazy Loading:**
```typescript
// frontend_3010/src/App.tsx
import { lazy, Suspense } from 'react';

const Dashboard = lazy(() => import('./components/Dashboard'));
const JobManagement = lazy(() => import('./components/JobManagement'));
const NodeManagement = lazy(() => import('./components/NodeManagement'));
const SSHSessionManager = lazy(() => import('./components/SSHSessionManager'));
const VNCSessionManager = lazy(() => import('./components/VNCSessionManager'));

function App() {
  return (
    <Suspense fallback={<LoadingSpinner />}>
      <Routes>
        <Route path="/" element={<Dashboard />} />
        <Route path="/jobs" element={<JobManagement />} />
        <Route path="/nodes" element={<NodeManagement />} />
        <Route path="/ssh" element={<SSHSessionManager />} />
        <Route path="/vnc" element={<VNCSessionManager />} />
      </Routes>
    </Suspense>
  );
}
```

#### 5.4 React Performance
**ìµœì í™” ì˜ˆì‹œ:**

```typescript
// Memoization
import { memo, useMemo, useCallback } from 'react';

export const JobCard = memo<JobCardProps>(({ job }) => {
  const formattedTime = useMemo(() => formatTime(job.time), [job.time]);

  const handleCancel = useCallback(() => {
    cancelJob(job.id);
  }, [job.id]);

  return (
    <div>
      <h3>{job.name}</h3>
      <p>{formattedTime}</p>
      <button onClick={handleCancel}>Cancel</button>
    </div>
  );
});

// Virtual Scrolling (react-window)
import { FixedSizeList } from 'react-window';

const JobList: React.FC<{ jobs: Job[] }> = ({ jobs }) => {
  const Row = ({ index, style }) => (
    <div style={style}>
      <JobCard job={jobs[index]} />
    </div>
  );

  return (
    <FixedSizeList
      height={600}
      itemCount={jobs.length}
      itemSize={80}
      width="100%"
    >
      {Row}
    </FixedSizeList>
  );
};
```

#### 5.5 WebSocket Optimization
**ìˆ˜ì •:** `websocket_5011/websocket_server.py`

```python
# ë©”ì‹œì§€ ë°°ì¹­
class MessageBatcher:
    def __init__(self, interval=1.0):
        self.buffer = []
        self.interval = interval

    async def add_message(self, message: dict):
        self.buffer.append(message)

        if len(self.buffer) >= 10:  # 10ê°œ ëª¨ì´ë©´ ì¦‰ì‹œ ì „ì†¡
            await self.flush()

    async def flush(self):
        if not self.buffer:
            return

        batch = {
            'type': 'batch',
            'messages': self.buffer,
            'timestamp': datetime.now().isoformat()
        }

        await broadcast_to_all(batch)
        self.buffer = []

# ì„ íƒì  ë¸Œë¡œë“œìºìŠ¤íŠ¸ (ì±„ë„ ê¸°ë°˜)
subscriptions = {}  # {client_id: Set[channel]}

async def broadcast_to_channel(channel: str, message: dict):
    """íŠ¹ì • ì±„ë„ êµ¬ë…ìì—ê²Œë§Œ ë©”ì‹œì§€ ì „ì†¡"""
    for client_id, channels in subscriptions.items():
        if channel in channels:
            await send_to_client(client_id, message)

# ì••ì¶• ì „ì†¡ (ëŒ€ìš©ëŸ‰ ë°ì´í„°)
import zlib

async def send_compressed(ws: web.WebSocketResponse, data: dict):
    json_str = json.dumps(data)
    compressed = zlib.compress(json_str.encode('utf-8'))

    await ws.send_bytes(compressed)
```

---

### Phase 6: Testing & Documentation (1ì£¼)
**ëª©í‘œ:** í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‘ì„± ë° ë¬¸ì„œí™”

#### 6.1 Backend Tests
**ìƒˆ ë””ë ‰í† ë¦¬:** `backend_5010/tests/`

```python
# tests/test_apptainer_service.py
import pytest
from apptainer_service import ApptainerService

@pytest.fixture
def apptainer_service():
    return ApptainerService()

def test_scan_node_images(apptainer_service):
    images = apptainer_service.scan_node_images('node001')
    assert len(images) > 0
    assert all(img.path.endswith('.sif') for img in images)

def test_get_image_metadata(apptainer_service):
    metadata = apptainer_service.get_image_metadata('/opt/apptainers/test.sif')
    assert 'name' in metadata
    assert 'size' in metadata

# tests/test_template_manager.py
def test_create_template():
    template_data = {
        'name': 'test_template',
        'category': 'ml',
        'input_file_schema': {...}
    }
    template_id = template_manager.create_template(template_data)
    assert template_id is not None

def test_validate_input_files():
    files = [...]
    result = template_manager.validate_input_files('template_id', files)
    assert result['valid'] == True

# tests/test_upload_service.py
def test_create_upload_session():
    session_id = upload_service.create_upload_session('user123')
    assert len(session_id) == 36  # UUID

def test_upload_chunk():
    chunk = b'test data'
    result = upload_service.upload_chunk('session_id', chunk, 0)
    assert result['received'] == True
```

**ì‹¤í–‰:**
```bash
cd backend_5010
pytest tests/ --cov=. --cov-report=html
```

#### 6.2 Frontend Tests
**ìƒˆ ë””ë ‰í† ë¦¬:** `frontend_3010/src/__tests__/`

```typescript
// __tests__/ApptainerSelector.test.tsx
import { render, screen, fireEvent } from '@testing-library/react';
import { ApptainerSelector } from '../components/ApptainerSelector';

describe('ApptainerSelector', () => {
  it('renders image list', async () => {
    render(<ApptainerSelector partition="compute" onSelect={jest.fn()} />);

    const images = await screen.findAllByRole('listitem');
    expect(images.length).toBeGreaterThan(0);
  });

  it('filters by partition', () => {
    const { rerender } = render(
      <ApptainerSelector partition="compute" onSelect={jest.fn()} />
    );

    expect(screen.queryByText('vnc_gnome.sif')).not.toBeInTheDocument();

    rerender(<ApptainerSelector partition="viz" onSelect={jest.fn()} />);
    expect(screen.getByText('vnc_gnome.sif')).toBeInTheDocument();
  });

  it('calls onSelect when image is selected', () => {
    const onSelect = jest.fn();
    render(<ApptainerSelector onSelect={onSelect} />);

    const firstImage = screen.getAllByRole('button')[0];
    fireEvent.click(firstImage);

    expect(onSelect).toHaveBeenCalledWith(expect.objectContaining({
      name: expect.any(String),
      path: expect.any(String)
    }));
  });
});

// __tests__/UnifiedUploader.test.tsx
describe('UnifiedUploader', () => {
  it('uploads files successfully', async () => {
    const onComplete = jest.fn();
    render(<UnifiedUploader onComplete={onComplete} />);

    const file = new File(['test'], 'test.dat', { type: 'application/octet-stream' });
    const input = screen.getByLabelText('Upload files');

    fireEvent.change(input, { target: { files: [file] } });

    await waitFor(() => {
      expect(onComplete).toHaveBeenCalled();
    });
  });
});
```

#### 6.3 E2E Tests
**ìƒˆ ë””ë ‰í† ë¦¬:** `frontend_3010/e2e/`

```typescript
// e2e/job-submission.spec.ts
import { test, expect } from '@playwright/test';

test.describe('Job Submission Flow', () => {
  test('complete job submission with apptainer', async ({ page }) => {
    await page.goto('http://localhost:3010');

    // Login
    await page.fill('input[name="username"]', 'testuser');
    await page.fill('input[name="password"]', 'password');
    await page.click('button[type="submit"]');

    // Navigate to job submission
    await page.click('text=Submit Job');

    // Select template
    await page.click('text=ML Training');

    // Select apptainer image
    await page.click('[data-testid="apptainer-selector"]');
    await page.click('text=KooSimulationPython313.sif');

    // Upload files
    await page.setInputFiles('input[type="file"]', ['test-files/input.dat']);

    // Fill job options
    await page.fill('input[name="job_name"]', 'test_job');
    await page.selectOption('select[name="partition"]', 'compute');

    // Submit
    await page.click('button:has-text("Submit")');

    // Verify success
    await expect(page.locator('text=Job submitted successfully')).toBeVisible();
  });
});
```

#### 6.4 API Documentation
**ìƒˆ íŒŒì¼:** `backend_5010/docs/API_REFERENCE.md`

```markdown
# API Reference

## Apptainer APIs

### List Apptainer Images
\`\`\`http
GET /api/apptainer/images?partition={partition}
\`\`\`

**Query Parameters:**
- `partition` (optional): Filter by partition (compute, viz)
- `type` (optional): Filter by type (viz, compute, custom)

**Response:**
\`\`\`json
{
  "images": [
    {
      "id": "uuid",
      "name": "KooSimulationPython313.sif",
      "path": "/opt/apptainers/KooSimulationPython313.sif",
      "node": "node001",
      "partition": "compute",
      "type": "compute",
      "size": 453000000,
      "apps": ["python", "jupyter"],
      "created_at": "2025-11-05T12:00:00Z"
    }
  ],
  "total": 10
}
\`\`\`

## Template APIs

### Create Template
\`\`\`http
POST /api/v2/templates
\`\`\`

**Request Body:**
\`\`\`json
{
  "name": "ml_training",
  "display_name": "ML Training Template",
  "category": "ml",
  "partition": "compute",
  "apptainer_image_id": "uuid",
  "input_file_schema": { ... },
  "main_script": "#!/bin/bash\n..."
}
\`\`\`

## Upload APIs

### Create Upload Session
\`\`\`http
POST /api/v2/upload/sessions
\`\`\`

**Request Body:**
\`\`\`json
{
  "template_id": "uuid"
}
\`\`\`

**Response:**
\`\`\`json
{
  "session_id": "uuid",
  "expires_at": "2025-11-05T13:00:00Z"
}
\`\`\`
```

#### 6.5 User Documentation
**ìƒˆ íŒŒì¼:** `frontend_3010/docs/USER_GUIDE.md`

```markdown
# User Guide

## Job Submission with Apptainer

### Step 1: Select Template
1. Navigate to "Submit Job" page
2. Browse templates by category
3. Select a template (e.g., "ML Training")

### Step 2: Select Apptainer Image
1. Click "Select Container"
2. Choose an image from the list
3. (Optional) Select a specific app within the container

### Step 3: Upload Files
1. Drag & drop files or click "Browse"
2. Files are automatically classified:
   - **Data files**: .dat, .csv, .msh
   - **Config files**: .json, .yaml, .xml
3. Wait for upload to complete

### Step 4: Configure Job
1. Set job name
2. Select partition
3. Adjust resources (nodes, CPUs, memory)
4. Set time limit

### Step 5: Submit
1. Review script preview
2. Click "Submit Job"
3. Monitor job status in Dashboard
```

---

## ğŸ“Š Implementation Timeline

### Phase 1: Apptainer Integration (2ì£¼)
- Week 1: Backend service + Database schema
- Week 2: Frontend components + Integration tests

### Phase 2: Template Management (2ì£¼)
- Week 1: Template schema + API
- Week 2: Frontend template manager

### Phase 3: File Upload API (1.5ì£¼)
- Week 1: Upload service + Chunking
- Week 2: Frontend uploader + External integration

### Phase 4: Security & Infrastructure (2ì£¼)
- Week 1: JWT refresh + CORS + Rate limiting
- Week 2: Redis caching + Nginx optimization + Logging

### Phase 5: Performance Optimization (1.5ì£¼)
- Week 1: Backend async + Database optimization
- Week 2: Frontend code splitting + React optimization

### Phase 6: Testing & Documentation (1ì£¼)
- Days 1-3: Backend tests
- Days 4-5: Frontend tests
- Days 6-7: Documentation

**Total Duration: 10 weeks (~2.5 months)**

---

## ğŸš€ Deployment Strategy

### Phase ë³„ ë°°í¬ ì „ëµ

#### Phase 1-3: Feature Branches
```bash
git checkout -b feature/apptainer-integration
git checkout -b feature/template-management
git checkout -b feature/file-upload-api
```

#### Phase 4-5: Staging Environment
```bash
# Staging ë°°í¬
./deploy.sh staging

# ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
ab -n 1000 -c 100 http://staging.example.com/api/nodes

# ë¶€í•˜ í…ŒìŠ¤íŠ¸
locust -f loadtest.py --host=http://staging.example.com
```

#### Phase 6: Production Rollout
```bash
# Blue-Green Deployment
./deploy.sh production --strategy=blue-green

# Canary Release (10% traffic)
./deploy.sh production --strategy=canary --traffic=10

# Full rollout
./deploy.sh production --strategy=canary --traffic=100
```

---

## ğŸ“ˆ Success Metrics

### Performance Metrics
- API ì‘ë‹µ ì‹œê°„: < 200ms (P95)
- WebSocket ì§€ì—°: < 50ms
- í˜ì´ì§€ ë¡œë“œ: < 2ì´ˆ
- ëŒ€ìš©ëŸ‰ íŒŒì¼ ì—…ë¡œë“œ: > 50 MB/s

### Reliability Metrics
- API ê°€ìš©ì„±: > 99.9%
- WebSocket ì—°ê²° ì„±ê³µë¥ : > 99%
- ì‘ì—… ì œì¶œ ì„±ê³µë¥ : > 99.5%

### Security Metrics
- JWT í† í° ë¬´íš¨í™” ì‘ë‹µ: < 100ms
- Rate limit ì ìš©ë¥ : 100%
- Input validation ì„±ê³µë¥ : 100%

### User Metrics
- Template ì‚¬ìš©ë¥ : > 80% (ì‘ì—…ì˜ 80%ê°€ í…œí”Œë¦¿ ì‚¬ìš©)
- Apptainer ì‚¬ìš©ë¥ : > 70%
- í‰ê·  íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨ìœ¨: < 1%

---

## ğŸ”§ Migration Guide

### ê¸°ì¡´ ì‹œìŠ¤í…œì—ì„œ ë§ˆì´ê·¸ë ˆì´ì…˜

#### 1. Database Migration
```bash
# ë°±ì—…
sqlite3 dashboard.db ".backup dashboard.db.backup"

# ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜
python migrate_database.py --from v3.0 --to v4.0

# ê²€ì¦
python verify_migration.py
```

#### 2. API ë§ˆì´ê·¸ë ˆì´ì…˜
```bash
# v1 API â†’ v2 API
# v1ì€ 6ê°œì›”ê°„ ìœ ì§€ (Deprecation Period)
# í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ê²½ê³  í—¤ë” ì „ì†¡
X-API-Version: v1 (deprecated, use v2)
X-Deprecation-Date: 2026-05-01
```

#### 3. Frontend ë§ˆì´ê·¸ë ˆì´ì…˜
```bash
# ê¸°ì¡´ ì»´í¬ë„ŒíŠ¸ ìœ ì§€í•˜ë©° ìƒˆ ì»´í¬ë„ŒíŠ¸ ì¶”ê°€
# Feature Flagë¡œ ì ì§„ì  ë¡¤ì•„ì›ƒ
VITE_ENABLE_APPTAINER=true
VITE_ENABLE_V2_TEMPLATES=true
VITE_ENABLE_UNIFIED_UPLOAD=true
```

---

## ğŸ“ Notes

### ì£¼ì˜ì‚¬í•­
1. **Redis í•„ìˆ˜**: Phase 4ë¶€í„° Redis í•„ìˆ˜ ì˜ì¡´ì„±
2. **Breaking Changes**: v2 APIëŠ” v1ê³¼ í˜¸í™˜ë˜ì§€ ì•ŠìŒ (6ê°œì›” deprecation ê¸°ê°„ ì œê³µ)
3. **Database Migration**: ë‹¤ìš´íƒ€ì„ ìµœì†Œí™”ë¥¼ ìœ„í•´ ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜ ê¶Œì¥
4. **Apptainer ë²„ì „**: Apptainer 1.0+ í•„ìš”

### ì¶”ê°€ ê°œì„  ê³ ë ¤ì‚¬í•­
- **GraphQL API**: REST API ëŒ€ì‹  GraphQL ë„ì… ê²€í† 
- **gRPC**: ë…¸ë“œ ê°„ í†µì‹ ì„ gRPCë¡œ ì „í™˜ ê²€í† 
- **Kubernetes**: ì»¨í…Œì´ë„ˆ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë„ì… ê²€í† 
- **Service Mesh**: Istio/Linkerd ë„ì… ê²€í† 

---

## ğŸš€ Phase-by-Phase ì‹¤í–‰ ê°€ì´ë“œ (Quick Reference)

### Phase 1: Apptainer Discovery & Integration

#### ì‹¤í–‰ ìˆœì„œ
```bash
# 1. ë°±ì—…
cd /home/koopark/claude/KooSlurmInstallAutomationRefactory
git add -A && git commit -m "Backup before Phase 1"

# 2. Backend êµ¬í˜„
# - backend_5010/apptainer_service.py ìƒì„±
# - backend_5010/apptainer_api.py ìƒì„±
# - backend_5010/migrations/v4.1.0_apptainer_images.sql ìƒì„±

# 3. Frontend êµ¬í˜„
# - frontend_3010/src/components/ApptainerSelector.tsx ìƒì„±
# - frontend_3010/src/hooks/useApptainerImages.ts ìƒì„±

# 4. ë¹Œë“œ ë° ë°°í¬
cd dashboard/frontend_3010 && npm run build
sudo ./cluster/setup/phase5_web_services.sh

# 5. ê²€ì¦
curl http://192.168.0.201:5010/api/apptainer/images
curl http://192.168.0.201:5010/api/health
```

#### ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] `backend_5010/apptainer_service.py` ìƒì„± ì™„ë£Œ
- [ ] `backend_5010/apptainer_api.py` ìƒì„± ì™„ë£Œ
- [ ] DB ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ
- [ ] Frontend ApptainerSelector ì»´í¬ë„ŒíŠ¸ ìƒì„± ì™„ë£Œ
- [ ] phase5_web_services.shì— ë§ˆì´ê·¸ë ˆì´ì…˜ ì¶”ê°€ ì™„ë£Œ
- [ ] ë¹Œë“œ ì„±ê³µ í™•ì¸
- [ ] API ì—”ë“œí¬ì¸íŠ¸ ì •ìƒ ì‘ë‹µ í™•ì¸
- [ ] ê¸°ì¡´ Job Submit ê¸°ëŠ¥ ì •ìƒ ë™ì‘ í™•ì¸

---

### Phase 2: Template Management System

#### ì‹¤í–‰ ìˆœì„œ
```bash
# 1. ë°±ì—…
git add -A && git commit -m "Backup before Phase 2"

# 2. Template Storage ì´ˆê¸°í™”
sudo ./cluster/setup/init_template_storage.sh

# 3. Backend êµ¬í˜„
# - backend_5010/template_loader.py ìƒì„±
# - backend_5010/template_watcher.py ìƒì„±
# - backend_5010/templates_api_v2.py ìƒì„±
# - backend_5010/template_manager.py ìƒì„±
# - backend_5010/migrations/v4.2.0_templates_v2.sql ìƒì„±

# 4. requirements.txt ì—…ë°ì´íŠ¸
# watchdog>=3.0.0 ì¶”ê°€

# 5. Frontend êµ¬í˜„
# - frontend_3010/src/components/TemplateManager/ ë””ë ‰í† ë¦¬ ìƒì„±
# - TemplateEditor.tsx, TemplateList.tsx, TemplateImportExport.tsx ìƒì„±

# 6. ë¹Œë“œ ë° ë°°í¬
cd dashboard/frontend_3010 && npm run build
sudo ./cluster/setup/phase5_web_services.sh

# 7. ê²€ì¦
curl http://192.168.0.201:5010/api/v2/templates
curl http://192.168.0.201:5010/api/v2/templates/scan -X POST
ls -la /shared/templates/official/
```

#### ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] `/shared/templates/` ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± ì™„ë£Œ
- [ ] `template_loader.py` êµ¬í˜„ ì™„ë£Œ
- [ ] `template_watcher.py` êµ¬í˜„ ì™„ë£Œ
- [ ] `templates_api_v2.py` êµ¬í˜„ ì™„ë£Œ
- [ ] DB ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ
- [ ] Frontend TemplateManager ì»´í¬ë„ŒíŠ¸ êµ¬í˜„ ì™„ë£Œ
- [ ] requirements.txt ì—…ë°ì´íŠ¸ ì™„ë£Œ
- [ ] YAML í…œí”Œë¦¿ íŒŒì¼ íŒŒì‹± ì •ìƒ ë™ì‘ í™•ì¸
- [ ] Hot Reload ë™ì‘ í™•ì¸
- [ ] ê¸°ì¡´ Job Submit ê¸°ëŠ¥ ì •ìƒ ë™ì‘ í™•ì¸

---

### Phase 3: Unified File Upload API

#### ì‹¤í–‰ ìˆœì„œ
```bash
# 1. ë°±ì—…
git add -A && git commit -m "Backup before Phase 3"

# 2. Backend êµ¬í˜„
# - backend_5010/file_upload_api.py ìƒì„±
# - backend_5010/file_classifier.py ìƒì„±
# - backend_5010/migrations/v4.3.0_file_uploads.sql ìƒì„±

# 3. WebSocket ì—…ë°ì´íŠ¸
# - websocket_5011/websocket_server.py ì—…ë°ì´íŠ¸ (progress ì±„ë„ ì¶”ê°€)

# 4. Frontend êµ¬í˜„
# - frontend_3010/src/components/UnifiedUploader.tsx ìƒì„±
# - frontend_3010/src/hooks/useFileUpload.ts ìƒì„±

# 5. ë¹Œë“œ ë° ë°°í¬
cd dashboard/frontend_3010 && npm run build
sudo ./cluster/setup/phase5_web_services.sh
sudo systemctl restart websocket_5011

# 6. ê²€ì¦
# - ì‘ì€ íŒŒì¼ ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸
# - ëŒ€ìš©ëŸ‰ íŒŒì¼ (1GB+) ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸
curl http://192.168.0.201:5010/api/v2/files/upload -X POST -F "file=@test.dat"
```

#### ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] `file_upload_api.py` êµ¬í˜„ ì™„ë£Œ
- [ ] `file_classifier.py` êµ¬í˜„ ì™„ë£Œ
- [ ] DB ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ
- [ ] WebSocket progress ì±„ë„ ì¶”ê°€ ì™„ë£Œ
- [ ] Frontend UnifiedUploader ì»´í¬ë„ŒíŠ¸ êµ¬í˜„ ì™„ë£Œ
- [ ] ì²­í¬ ì—…ë¡œë“œ ì •ìƒ ë™ì‘ í™•ì¸
- [ ] íŒŒì¼ ë¶„ë¥˜ (data/config) ì •ìƒ ë™ì‘ í™•ì¸
- [ ] ëŒ€ìš©ëŸ‰ íŒŒì¼ ì—…ë¡œë“œ ì„±ê³µ í™•ì¸
- [ ] ì—…ë¡œë“œ ì§„í–‰ë¥  ì‹¤ì‹œê°„ í‘œì‹œ í™•ì¸
- [ ] ê¸°ì¡´ Job Submit ê¸°ëŠ¥ ì •ìƒ ë™ì‘ í™•ì¸

---

### Phase 4: Security & Infrastructure

#### ì‹¤í–‰ ìˆœì„œ
```bash
# 1. ë°±ì—…
git add -A && git commit -m "Backup before Phase 4"

# 2. Redis ì„¤ì¹˜ ë° ì„¤ì •
sudo apt-get install redis-server -y
sudo systemctl enable redis-server
sudo systemctl start redis-server

# 3. Backend ë³´ì•ˆ ê°•í™”
# - backend_5010/security/jwt_refresh.py ìƒì„±
# - backend_5010/security/rate_limiter.py ìƒì„±
# - backend_5010/security/input_validator.py ìƒì„±
# - backend_5010/security/cors_config.py ìƒì„±

# 4. requirements.txt ì—…ë°ì´íŠ¸
# redis>=4.5.0, flask-limiter>=3.3.0, marshmallow>=3.19.0 ì¶”ê°€

# 5. Nginx ì„¤ì •
# - cluster/setup/config/nginx_dashboard.conf ìƒì„±
# - phase5_web_services.sh ì—…ë°ì´íŠ¸ (Nginx ì„¤ì • ì¶”ê°€)

# 6. ë¹Œë“œ ë° ë°°í¬
cd dashboard/frontend_3010 && npm run build
sudo ./cluster/setup/phase5_web_services.sh

# 7. ê²€ì¦
redis-cli ping
curl -I http://192.168.0.201:5010/api/health
# Rate limit í…ŒìŠ¤íŠ¸ (100ë²ˆ ë°˜ë³µ ìš”ì²­)
```

#### ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] Redis ì„¤ì¹˜ ë° ì‹¤í–‰ í™•ì¸
- [ ] JWT Refresh Token êµ¬í˜„ ì™„ë£Œ
- [ ] Rate Limiter êµ¬í˜„ ì™„ë£Œ
- [ ] Input Validator êµ¬í˜„ ì™„ë£Œ
- [ ] CORS ì„¤ì • ì—…ë°ì´íŠ¸ ì™„ë£Œ
- [ ] Nginx ì„¤ì • íŒŒì¼ ìƒì„± ì™„ë£Œ
- [ ] requirements.txt ì—…ë°ì´íŠ¸ ì™„ë£Œ
- [ ] ë¹Œë“œ ë° ë°°í¬ ì„±ê³µ í™•ì¸
- [ ] Rate limiting ì •ìƒ ë™ì‘ í™•ì¸
- [ ] JWT refresh ì •ìƒ ë™ì‘ í™•ì¸
- [ ] ê¸°ì¡´ Job Submit ê¸°ëŠ¥ ì •ìƒ ë™ì‘ í™•ì¸

---

### Phase 5: Performance Optimization

#### ì‹¤í–‰ ìˆœì„œ
```bash
# 1. ë°±ì—…
git add -A && git commit -m "Backup before Phase 5"

# 2. Backend ìµœì í™”
# - backend_5010/cache/redis_cache.py ìƒì„±
# - backend_5010/async_tasks.py ì—…ë°ì´íŠ¸ (ë¹„ë™ê¸° ê°œì„ )

# 3. Frontend ìµœì í™”
# - React.lazy(), Suspense ì ìš©
# - Code Splitting ì„¤ì • (vite.config.ts ì—…ë°ì´íŠ¸)
# - ì»´í¬ë„ŒíŠ¸ ë©”ëª¨ì´ì œì´ì…˜ (React.memo, useMemo ì ìš©)

# 4. ë¹Œë“œ ë° ë°°í¬
cd dashboard/frontend_3010
npm run build
npm run build:check  # TypeScript ì²´í¬
sudo ./cluster/setup/phase5_web_services.sh

# 5. ì„±ëŠ¥ ì¸¡ì •
# - Lighthouse ì‹¤í–‰
# - API ì‘ë‹µ ì‹œê°„ ì¸¡ì •
```

#### ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] Redis ìºì‹± ë ˆì´ì–´ êµ¬í˜„ ì™„ë£Œ
- [ ] Backend ë¹„ë™ê¸° ì²˜ë¦¬ ê°œì„  ì™„ë£Œ
- [ ] Frontend Code Splitting ì ìš© ì™„ë£Œ
- [ ] React ì»´í¬ë„ŒíŠ¸ ìµœì í™” ì™„ë£Œ
- [ ] ë¹Œë“œ í¬ê¸° ê°ì†Œ í™•ì¸
- [ ] API ì‘ë‹µ ì‹œê°„ < 200ms (P95) í™•ì¸
- [ ] í˜ì´ì§€ ë¡œë“œ ì‹œê°„ < 2ì´ˆ í™•ì¸
- [ ] WebSocket ì§€ì—° < 50ms í™•ì¸
- [ ] ê¸°ì¡´ Job Submit ê¸°ëŠ¥ ì •ìƒ ë™ì‘ í™•ì¸

---

### Phase 6: Testing & Documentation

#### ì‹¤í–‰ ìˆœì„œ
```bash
# 1. ë°±ì—…
git add -A && git commit -m "Backup before Phase 6"

# 2. Backend í…ŒìŠ¤íŠ¸ ì‘ì„±
# - backend_5010/tests/ ë””ë ‰í† ë¦¬ì— í…ŒìŠ¤íŠ¸ ì¶”ê°€
cd dashboard/backend_5010
python -m pytest tests/ -v

# 3. Frontend í…ŒìŠ¤íŠ¸ ì‘ì„±
# - frontend_3010/src/__tests__/ ë””ë ‰í† ë¦¬ì— í…ŒìŠ¤íŠ¸ ì¶”ê°€
cd dashboard/frontend_3010
npm run test:run

# 4. E2E í…ŒìŠ¤íŠ¸ ì‘ì„±
# - frontend_3010/e2e/ ë””ë ‰í† ë¦¬ì— E2E í…ŒìŠ¤íŠ¸ ì¶”ê°€
npm run test:e2e  # Playwright ì‹¤í–‰

# 5. API ë¬¸ì„œ ìƒì„±
# - backend_5010/docs/API_REFERENCE.md ìƒì„±
# - Swagger/OpenAPI ìŠ¤í™ ìƒì„±

# 6. ì‚¬ìš©ì ê°€ì´ë“œ ì‘ì„±
# - dashboard/USER_GUIDE.md ìƒì„±
# - dashboard/ADMIN_GUIDE.md ìƒì„±

# 7. ìµœì¢… ë°°í¬
sudo ./cluster/setup/setup_cluster_full_multihead.sh
```

#### ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] Backend ìœ ë‹› í…ŒìŠ¤íŠ¸ ì‘ì„± ì™„ë£Œ (ì»¤ë²„ë¦¬ì§€ > 80%)
- [ ] Frontend ìœ ë‹› í…ŒìŠ¤íŠ¸ ì‘ì„± ì™„ë£Œ (ì»¤ë²„ë¦¬ì§€ > 70%)
- [ ] E2E í…ŒìŠ¤íŠ¸ ì‘ì„± ì™„ë£Œ
- [ ] API ë¬¸ì„œ ìƒì„± ì™„ë£Œ
- [ ] ì‚¬ìš©ì ê°€ì´ë“œ ì‘ì„± ì™„ë£Œ
- [ ] ê´€ë¦¬ì ê°€ì´ë“œ ì‘ì„± ì™„ë£Œ
- [ ] ì „ì²´ ì‹œìŠ¤í…œ ë°°í¬ ì„±ê³µ í™•ì¸
- [ ] ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼ í™•ì¸
- [ ] Job Submit ì „ì²´ í”Œë¡œìš° ì •ìƒ ë™ì‘ í™•ì¸

---

## ğŸ” ì „ì²´ ì‹œìŠ¤í…œ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸

### verify_system_health.sh
```bash
#!/bin/bash
# cluster/tests/verify_system_health.sh

set -e

echo "=========================================="
echo "System Health Check"
echo "=========================================="

# 1. ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
echo -e "\n[1/8] Checking services..."
sudo systemctl is-active --quiet auth_backend && echo "âœ… auth_backend running" || echo "âŒ auth_backend stopped"
sudo systemctl is-active --quiet prometheus && echo "âœ… prometheus running" || echo "âŒ prometheus stopped"
sudo systemctl is-active --quiet websocket_5011 && echo "âœ… websocket_5011 running" || echo "âŒ websocket_5011 stopped"

# 2. API ì‘ë‹µ í™•ì¸
echo -e "\n[2/8] Checking API endpoints..."
curl -s -o /dev/null -w "%{http_code}" http://192.168.0.201:5010/api/health | grep -q "200" && echo "âœ… Backend API responding" || echo "âŒ Backend API error"
curl -s -o /dev/null -w "%{http_code}" http://192.168.0.201:3010/ | grep -q "200" && echo "âœ… Frontend serving" || echo "âŒ Frontend error"

# 3. WebSocket ì—°ê²° í™•ì¸
echo -e "\n[3/8] Checking WebSocket..."
timeout 5 nc -zv 192.168.0.201 5011 2>&1 | grep -q "succeeded" && echo "âœ… WebSocket port open" || echo "âŒ WebSocket port closed"

# 4. Redis ì—°ê²° í™•ì¸
echo -e "\n[4/8] Checking Redis..."
redis-cli ping | grep -q "PONG" && echo "âœ… Redis responding" || echo "âŒ Redis error"

# 5. DB í™•ì¸
echo -e "\n[5/8] Checking Database..."
if [ -f /home/koopark/web_services/backend/dashboard.db ]; then
    echo "âœ… Database file exists"
    # í…Œì´ë¸” ì¡´ì¬ í™•ì¸
    sqlite3 /home/koopark/web_services/backend/dashboard.db "SELECT name FROM sqlite_master WHERE type='table' AND name='apptainer_images';" | grep -q "apptainer_images" && echo "âœ… apptainer_images table exists" || echo "âš ï¸  apptainer_images table missing"
else
    echo "âŒ Database file missing"
fi

# 6. Template Storage í™•ì¸
echo -e "\n[6/8] Checking Template Storage..."
[ -d /shared/templates/official ] && echo "âœ… Template storage exists" || echo "âŒ Template storage missing"

# 7. Apptainer ì´ë¯¸ì§€ í™•ì¸
echo -e "\n[7/8] Checking Apptainer Images..."
ssh compute-node001 "ls /opt/apptainers/*.sif" &>/dev/null && echo "âœ… Compute node images accessible" || echo "âŒ Compute node images not accessible"
ssh viz-node001 "ls /opt/apptainers/*.sif" &>/dev/null && echo "âœ… Viz node images accessible" || echo "âŒ Viz node images not accessible"

# 8. ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
echo -e "\n[8/8] Checking Disk Space..."
DISK_USAGE=$(df -h / | awk 'NR==2 {print $5}' | sed 's/%//')
if [ "$DISK_USAGE" -lt 90 ]; then
    echo "âœ… Disk space OK ($DISK_USAGE% used)"
else
    echo "âš ï¸  Disk space high ($DISK_USAGE% used)"
fi

echo -e "\n=========================================="
echo "Health Check Complete"
echo "=========================================="
```

### ì‚¬ìš© ë°©ë²•
```bash
# ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬
chmod +x cluster/tests/verify_system_health.sh

# Phase ì‹œì‘ ì „ ê²€ì¦
./cluster/tests/verify_system_health.sh

# Phase ë°°í¬ í›„ ê²€ì¦
sudo ./cluster/setup/phase5_web_services.sh
./cluster/tests/verify_system_health.sh
```

---

## ğŸ“‹ ì „ì²´ Phase ì§„í–‰ ìƒí™© íŠ¸ë˜í‚¹

### Phase ì§„í–‰ ìƒí™©í‘œ
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase    â”‚ ê¸°ëŠ¥                          â”‚ ìƒíƒœ     â”‚ ì‹œì‘ì¼   â”‚ ì™„ë£Œì¼   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Phase 1  â”‚ Apptainer Discovery           â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”‚          â”‚ - apptainer_service.py        â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”‚          â”‚ - apptainer_api.py            â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”‚          â”‚ - ApptainerSelector.tsx       â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”‚          â”‚ - DB Migration                â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Phase 2  â”‚ Template Management           â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”‚          â”‚ - init_template_storage.sh    â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”‚          â”‚ - template_loader.py          â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”‚          â”‚ - template_watcher.py         â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”‚          â”‚ - TemplateManager components  â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”‚          â”‚ - DB Migration                â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Phase 3  â”‚ File Upload API               â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”‚          â”‚ - file_upload_api.py          â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”‚          â”‚ - file_classifier.py          â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”‚          â”‚ - UnifiedUploader.tsx         â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”‚          â”‚ - WebSocket progress          â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”‚          â”‚ - DB Migration                â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Phase 4  â”‚ Security & Infrastructure     â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”‚          â”‚ - Redis setup                 â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”‚          â”‚ - JWT Refresh                 â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”‚          â”‚ - Rate Limiter                â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”‚          â”‚ - Input Validator             â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”‚          â”‚ - Nginx config                â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Phase 5  â”‚ Performance Optimization      â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”‚          â”‚ - Redis Cache Layer           â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”‚          â”‚ - Backend Async Optimization  â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”‚          â”‚ - Frontend Code Splitting     â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”‚          â”‚ - React Optimization          â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Phase 6  â”‚ Testing & Documentation       â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”‚          â”‚ - Backend Tests               â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”‚          â”‚ - Frontend Tests              â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”‚          â”‚ - E2E Tests                   â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”‚          â”‚ - API Documentation           â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â”‚          â”‚ - User Guide                  â”‚ â¬œ TODO  â”‚          â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ë²”ë¡€: â¬œ TODO | ğŸŸ¦ IN PROGRESS | âœ… DONE | âŒ BLOCKED
```

---

## ğŸ“š References

- [Apptainer Documentation](https://apptainer.org/docs/)
- [Slurm Documentation](https://slurm.schedmd.com/)
- [Flask Best Practices](https://flask.palletsprojects.com/)
- [React Performance](https://react.dev/learn/render-and-commit)
- [Redis Caching Strategies](https://redis.io/docs/manual/patterns/)

---

**ë¬¸ì„œ ë²„ì „:** 1.1
**ìµœì¢… ìˆ˜ì •ì¼:** 2025-11-05
**ì‘ì„±ì:** Dashboard Development Team
