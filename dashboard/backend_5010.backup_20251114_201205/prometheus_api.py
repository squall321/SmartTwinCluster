"""
Prometheus API
RESTful endpoints for Prometheus integration
"""

from flask import Blueprint, request, jsonify
import requests
import os
import random
from datetime import datetime, timedelta

# Create Blueprint
prometheus_bp = Blueprint('prometheus', __name__, url_prefix='/api/prometheus')

# Prometheus configuration
PROMETHEUS_URL = os.getenv('PROMETHEUS_URL', 'http://localhost:9090')
MOCK_MODE = os.getenv('MOCK_MODE', 'true').lower() == 'true'

# ============================================
# Helper Functions
# ============================================

def query_prometheus(endpoint: str, params: dict = None):
    """Query Prometheus API"""
    try:
        url = f"{PROMETHEUS_URL}/api/v1/{endpoint}"
        response = requests.get(url, params=params, timeout=5)
        response.raise_for_status()
        return response.json()
    except Exception as e:
        print(f"‚ùå Prometheus query error: {e}")
        return None

def get_mock_instant_query(query: str):
    """Generate mock instant query response"""
    
    # GPU Í¥ÄÎ†® ÏøºÎ¶¨ Ï≤òÎ¶¨
    if 'nvidia' in query.lower() or 'gpu' in query.lower():
        return get_mock_gpu_data(query)
    
    # Í∏∞Î≥∏ mock Îç∞Ïù¥ÌÑ∞
    mock_data = {
        'status': 'success',
        'data': {
            'resultType': 'vector',
            'result': [
                {
                    'metric': {
                        '__name__': query.split('{')[0] if '{' in query else query,
                        'instance': 'localhost:9090',
                        'job': 'node_exporter'
                    },
                    'value': [
                        datetime.now().timestamp(),
                        str(round(85.5 + (hash(query) % 10), 2))  # Pseudo-random value
                    ]
                }
            ]
        }
    }
    return mock_data

def get_mock_gpu_data(query: str):
    """Generate mock GPU data"""
    num_gpus = 4
    result = []
    
    # GPU ÏÇ¨Ïö©Î•† ÏøºÎ¶¨
    if 'utilization' in query.lower():
        for i in range(num_gpus):
            result.append({
                'metric': {
                    '__name__': 'nvidia_smi_utilization_gpu_ratio',
                    'gpu': str(i),
                    'minor_number': str(i),
                    'instance': 'localhost:9100',
                    'job': 'nvidia_exporter'
                },
                'value': [
                    datetime.now().timestamp(),
                    str(round(random.uniform(0.2, 0.95), 3))  # 0.2 ~ 0.95 (ratio)
                ]
            })
    
    # GPU Î©îÎ™®Î¶¨ ÏøºÎ¶¨
    elif 'memory' in query.lower():
        for i in range(num_gpus):
            # Memory used / total * 100
            memory_percent = random.uniform(30, 95)
            result.append({
                'metric': {
                    '__name__': 'nvidia_smi_memory_used_bytes',
                    'gpu': str(i),
                    'minor_number': str(i),
                    'instance': 'localhost:9100',
                    'job': 'nvidia_exporter'
                },
                'value': [
                    datetime.now().timestamp(),
                    str(round(memory_percent, 2))
                ]
            })
    
    # GPU Ïò®ÎèÑ ÏøºÎ¶¨
    elif 'temperature' in query.lower():
        for i in range(num_gpus):
            result.append({
                'metric': {
                    '__name__': 'nvidia_smi_temperature_gpu',
                    'gpu': str(i),
                    'minor_number': str(i),
                    'instance': 'localhost:9100',
                    'job': 'nvidia_exporter'
                },
                'value': [
                    datetime.now().timestamp(),
                    str(round(random.uniform(45, 80), 1))  # 45¬∞C ~ 80¬∞C
                ]
            })
    
    # ÏùºÎ∞ò GPU ÏøºÎ¶¨ (Í∏∞Î≥∏Í∞í)
    else:
        for i in range(num_gpus):
            result.append({
                'metric': {
                    '__name__': query.split('{')[0] if '{' in query else query,
                    'gpu': str(i),
                    'minor_number': str(i),
                    'instance': 'localhost:9100',
                    'job': 'nvidia_exporter'
                },
                'value': [
                    datetime.now().timestamp(),
                    str(round(random.uniform(60, 90), 2))
                ]
            })
    
    return {
        'status': 'success',
        'data': {
            'resultType': 'vector',
            'result': result
        }
    }

def get_mock_range_query(query: str, start: str, end: str, step: str):
    """Generate mock range query response with multiple time series"""
    import math
    
    start_time = datetime.fromisoformat(start.replace('Z', '+00:00'))
    end_time = datetime.fromisoformat(end.replace('Z', '+00:00'))
    step_seconds = int(step.rstrip('s'))
    
    # Ïó¨Îü¨ ÏãúÍ≥ÑÏó¥ÏùÑ ÏÉùÏÑ±Ìï†ÏßÄ Í≤∞Ï†ï
    results = []
    
    # GPU Í¥ÄÎ†® ÏøºÎ¶¨
    if 'nvidia' in query.lower() or 'gpu' in query.lower():
        num_gpus = 4
        for gpu_idx in range(num_gpus):
            values = []
            current = start_time
            base_value = 60 + (gpu_idx * 10) + random.uniform(-5, 5)
            
            while current <= end_time:
                timestamp = current.timestamp()
                offset = math.sin(timestamp / 1000 + gpu_idx) * 15
                value = max(0, base_value + offset)
                values.append([timestamp, str(round(value, 2))])
                current += timedelta(seconds=step_seconds)
            
            results.append({
                'metric': {
                    '__name__': query.split('{')[0].split('(')[0].strip() if any(c in query for c in ['{', '(']) else query.split()[0],
                    'gpu': str(gpu_idx),
                    'instance': f'node{gpu_idx//2 + 1}:9100',
                    'job': 'nvidia_exporter'
                },
                'values': values
            })
    
    # 'or' Ïó∞ÏÇ∞ÏûêÍ∞Ä ÏûàÎäî ÏøºÎ¶¨ (ÎπÑÍµê ÏøºÎ¶¨)
    elif ' or ' in query.lower():
        # ÏøºÎ¶¨Î•º ' or 'Î°ú Î∂ÑÎ¶¨
        sub_queries = [q.strip() for q in query.split(' or ')]
        print(f"[Mock] Detected comparison query with {len(sub_queries)} sub-queries")
        
        # Í∞Å sub-queryÏóê ÎåÄÌï¥ 2-3Í∞ú ÏãúÍ≥ÑÏó¥ ÏÉùÏÑ±
        for sub_idx, sub_query in enumerate(sub_queries):
            # Î©îÌä∏Î¶≠ Ïù¥Î¶Ñ Ï∂îÏ∂ú
            metric_name = sub_query.split('{')[0].split('(')[0].strip()
            if not metric_name or metric_name in ['100', '-', '+', '*', '/']:
                metric_name = f'metric_{sub_idx}'
            
            # Í∞Å sub-queryÎãπ 2-3Í∞ú ÎÖ∏Îìú
            num_nodes = 2 + (sub_idx % 2)
            for node_idx in range(num_nodes):
                values = []
                current = start_time
                base_value = 40 + (sub_idx * 20) + (node_idx * 10) + random.uniform(-5, 5)
                
                while current <= end_time:
                    timestamp = current.timestamp()
                    offset = math.sin(timestamp / 800 + sub_idx + node_idx) * 12
                    value = max(0, min(100, base_value + offset))
                    values.append([timestamp, str(round(value, 2))])
                    current += timedelta(seconds=step_seconds)
                
                results.append({
                    'metric': {
                        '__name__': metric_name,
                        'instance': f'node{node_idx + 1}:9100',
                        'job': 'node_exporter'
                    },
                    'values': values
                })
    
    # topk() Ìï®ÏàòÍ∞Ä ÏûàÎäî ÏøºÎ¶¨
    elif 'topk(' in query.lower():
        # topk(5, ...) -> 5Í∞ú ÏãúÍ≥ÑÏó¥
        try:
            k = int(query.split('topk(')[1].split(',')[0].strip())
        except:
            k = 5
        
        print(f"[Mock] Detected topk query, generating {k} time series")
        
        for i in range(k):
            values = []
            current = start_time
            # ÎÜíÏùÄ Í∞íÎ∂ÄÌÑ∞ ÎÇÆÏùÄ Í∞íÏúºÎ°ú
            base_value = 90 - (i * 10) + random.uniform(-3, 3)
            
            while current <= end_time:
                timestamp = current.timestamp()
                offset = math.sin(timestamp / 1200 + i) * 8
                value = max(0, min(100, base_value + offset))
                values.append([timestamp, str(round(value, 2))])
                current += timedelta(seconds=step_seconds)
            
            results.append({
                'metric': {
                    '__name__': query.split('{')[0].split('(')[-1].strip() if '(' in query else 'metric',
                    'instance': f'node{i + 1}:9100',
                    'job': 'node_exporter'
                },
                'values': values
            })
    
    # by (instance, cpu) Í∞ôÏùÄ Í∑∏Î£πÌôîÍ∞Ä ÏûàÎäî ÏøºÎ¶¨
    elif 'by (instance, cpu)' in query or 'by(instance,cpu)' in query:
        num_nodes = 2
        num_cpus = 4
        print(f"[Mock] Detected per-core query, generating {num_nodes}x{num_cpus} time series")
        
        for node_idx in range(num_nodes):
            for cpu_idx in range(num_cpus):
                values = []
                current = start_time
                base_value = 30 + random.uniform(0, 50)
                
                while current <= end_time:
                    timestamp = current.timestamp()
                    offset = math.sin(timestamp / 900 + node_idx + cpu_idx) * 20
                    value = max(0, min(100, base_value + offset))
                    values.append([timestamp, str(round(value, 2))])
                    current += timedelta(seconds=step_seconds)
                
                results.append({
                    'metric': {
                        '__name__': query.split('{')[0].split('(')[0].strip() if any(c in query for c in ['{', '(']) else query.split()[0],
                        'instance': f'node{node_idx + 1}:9100',
                        'cpu': str(cpu_idx),
                        'job': 'node_exporter'
                    },
                    'values': values
                })
    
    # by (instance) Í∑∏Î£πÌôîÍ∞Ä ÏûàÎäî ÏøºÎ¶¨ (Îã§Ï§ë ÎÖ∏Îìú)
    elif 'by (instance)' in query or 'by(instance)' in query:
        num_nodes = 3
        print(f"[Mock] Detected per-instance query, generating {num_nodes} time series")
        
        for node_idx in range(num_nodes):
            values = []
            current = start_time
            base_value = 50 + (node_idx * 15) + random.uniform(-8, 8)
            
            while current <= end_time:
                timestamp = current.timestamp()
                offset = math.sin(timestamp / 1000 + node_idx) * 12
                value = max(0, min(100, base_value + offset))
                values.append([timestamp, str(round(value, 2))])
                current += timedelta(seconds=step_seconds)
            
            results.append({
                'metric': {
                    '__name__': query.split('{')[0].split('(')[0].strip() if any(c in query for c in ['{', '(']) else query.split()[0],
                    'instance': f'node{node_idx + 1}:9100',
                    'job': 'node_exporter'
                },
                'values': values
            })
    
    # Í∏∞Î≥∏: Îã®Ïùº ÏãúÍ≥ÑÏó¥
    else:
        values = []
        current = start_time
        base_value = 70 + (hash(query) % 20)
        
        while current <= end_time:
            timestamp = current.timestamp()
            offset = math.sin(timestamp / 1000) * 10
            value = base_value + offset
            values.append([timestamp, str(round(value, 2))])
            current += timedelta(seconds=step_seconds)
        
        results.append({
            'metric': {
                '__name__': query.split('{')[0] if '{' in query else query.split('(')[0].strip() if '(' in query else query.split()[0],
                'instance': 'localhost:9100',
                'job': 'node_exporter'
            },
            'values': values
        })
    
    print(f"[Mock] Generated {len(results)} time series for query: {query[:100]}")
    
    return {
        'status': 'success',
        'data': {
            'resultType': 'matrix',
            'result': results
        }
    }

# ============================================
# GET /api/prometheus/query
# Instant query
# ============================================
@prometheus_bp.route('/query', methods=['GET'])
def instant_query():
    """
    Execute instant Prometheus query
    Query params:
        - query: PromQL expression (required)
        - time: Evaluation timestamp (optional)
    """
    query = request.args.get('query')
    time = request.args.get('time')
    
    if not query:
        return jsonify({'error': 'Query parameter is required'}), 400
    
    if MOCK_MODE:
        print(f"üìä [MOCK] Prometheus instant query: {query}")
        data = get_mock_instant_query(query)
        return jsonify(data)
    
    # Production mode
    params = {'query': query}
    if time:
        params['time'] = time
    
    data = query_prometheus('query', params)
    
    if data is None:
        return jsonify({'error': 'Failed to query Prometheus'}), 500
    
    return jsonify(data)

# ============================================
# GET /api/prometheus/query_range
# Range query
# ============================================
@prometheus_bp.route('/query_range', methods=['GET'])
def range_query():
    """
    Execute range Prometheus query
    Query params:
        - query: PromQL expression (required)
        - start: Start timestamp (required)
        - end: End timestamp (required)
        - step: Query resolution step (required)
    """
    query = request.args.get('query')
    start = request.args.get('start')
    end = request.args.get('end')
    step = request.args.get('step', '15s')
    
    if not all([query, start, end]):
        return jsonify({'error': 'query, start, and end parameters are required'}), 400
    
    if MOCK_MODE:
        print(f"üìä [MOCK] Prometheus range query: {query} ({start} to {end})")
        data = get_mock_range_query(query, start, end, step)
        return jsonify(data)
    
    # Production mode
    params = {
        'query': query,
        'start': start,
        'end': end,
        'step': step
    }
    
    data = query_prometheus('query_range', params)
    
    if data is None:
        return jsonify({'error': 'Failed to query Prometheus'}), 500
    
    return jsonify(data)

# ============================================
# GET /api/prometheus/labels
# Get label names
# ============================================
@prometheus_bp.route('/labels', methods=['GET'])
def get_labels():
    """Get all label names"""
    if MOCK_MODE:
        return jsonify({
            'status': 'success',
            'data': ['__name__', 'instance', 'job', 'device', 'cpu', 'mode', 'gpu']
        })
    
    data = query_prometheus('labels')
    
    if data is None:
        return jsonify({'error': 'Failed to get labels'}), 500
    
    return jsonify(data)

# ============================================
# GET /api/prometheus/label/<label_name>/values
# Get label values
# ============================================
@prometheus_bp.route('/label/<label_name>/values', methods=['GET'])
def get_label_values(label_name):
    """Get values for a specific label"""
    if MOCK_MODE:
        mock_values = {
            'job': ['node_exporter', 'slurm_exporter', 'prometheus', 'nvidia_exporter'],
            'instance': ['localhost:9090', 'node01:9100', 'node02:9100'],
            '__name__': ['node_cpu_seconds_total', 'node_memory_MemTotal_bytes', 'up', 'nvidia_smi_utilization_gpu_ratio'],
            'gpu': ['0', '1', '2', '3']
        }
        return jsonify({
            'status': 'success',
            'data': mock_values.get(label_name, [])
        })
    
    data = query_prometheus(f'label/{label_name}/values')
    
    if data is None:
        return jsonify({'error': f'Failed to get values for label {label_name}'}), 500
    
    return jsonify(data)

# ============================================
# GET /api/prometheus/series
# Get time series
# ============================================
@prometheus_bp.route('/series', methods=['GET'])
def get_series():
    """
    Get time series matching a label set
    Query params:
        - match[]: Series selector (required, can be repeated)
        - start: Start timestamp (optional)
        - end: End timestamp (optional)
    """
    matches = request.args.getlist('match[]')
    start = request.args.get('start')
    end = request.args.get('end')
    
    if not matches:
        return jsonify({'error': 'At least one match[] parameter is required'}), 400
    
    if MOCK_MODE:
        return jsonify({
            'status': 'success',
            'data': [
                {
                    '__name__': 'node_cpu_seconds_total',
                    'instance': 'localhost:9090',
                    'job': 'node_exporter',
                    'mode': 'idle',
                    'cpu': '0'
                },
                {
                    '__name__': 'nvidia_smi_utilization_gpu_ratio',
                    'instance': 'localhost:9100',
                    'job': 'nvidia_exporter',
                    'gpu': '0'
                }
            ]
        })
    
    params = {'match[]': matches}
    if start:
        params['start'] = start
    if end:
        params['end'] = end
    
    data = query_prometheus('series', params)
    
    if data is None:
        return jsonify({'error': 'Failed to get series'}), 500
    
    return jsonify(data)

# ============================================
# GET /api/prometheus/targets
# Get targets
# ============================================
@prometheus_bp.route('/targets', methods=['GET'])
def get_targets():
    """Get all targets"""
    if MOCK_MODE:
        return jsonify({
            'status': 'success',
            'data': {
                'activeTargets': [
                    {
                        'discoveredLabels': {
                            '__address__': 'localhost:9090',
                            '__metrics_path__': '/metrics',
                            '__scheme__': 'http',
                            'job': 'prometheus'
                        },
                        'labels': {
                            'instance': 'localhost:9090',
                            'job': 'prometheus'
                        },
                        'scrapePool': 'prometheus',
                        'scrapeUrl': 'http://localhost:9090/metrics',
                        'lastError': '',
                        'lastScrape': datetime.now().isoformat(),
                        'lastScrapeDuration': 0.023,
                        'health': 'up'
                    },
                    {
                        'discoveredLabels': {
                            '__address__': 'localhost:9100',
                            '__metrics_path__': '/metrics',
                            '__scheme__': 'http',
                            'job': 'node_exporter'
                        },
                        'labels': {
                            'instance': 'localhost:9100',
                            'job': 'node_exporter'
                        },
                        'scrapePool': 'node_exporter',
                        'scrapeUrl': 'http://localhost:9100/metrics',
                        'lastError': '',
                        'lastScrape': datetime.now().isoformat(),
                        'lastScrapeDuration': 0.045,
                        'health': 'up'
                    }
                ],
                'droppedTargets': []
            }
        })
    
    data = query_prometheus('targets')
    
    if data is None:
        return jsonify({'error': 'Failed to get targets'}), 500
    
    return jsonify(data)

# ============================================
# GET /api/prometheus/rules
# Get recording and alerting rules
# ============================================
@prometheus_bp.route('/rules', methods=['GET'])
def get_rules():
    """Get all rules"""
    if MOCK_MODE:
        return jsonify({
            'status': 'success',
            'data': {
                'groups': [
                    {
                        'name': 'node_alerts',
                        'file': '/etc/prometheus/rules.yml',
                        'interval': 30,
                        'rules': [
                            {
                                'name': 'HighCPUUsage',
                                'query': 'node_cpu_usage > 90',
                                'duration': 300,
                                'labels': {
                                    'severity': 'warning'
                                },
                                'annotations': {
                                    'summary': 'High CPU usage detected',
                                    'description': 'CPU usage is above 90% for 5 minutes'
                                },
                                'health': 'ok',
                                'type': 'alerting'
                            }
                        ]
                    }
                ]
            }
        })
    
    data = query_prometheus('rules')
    
    if data is None:
        return jsonify({'error': 'Failed to get rules'}), 500
    
    return jsonify(data)

# ============================================
# GET /api/prometheus/alerts
# Get active alerts
# ============================================
@prometheus_bp.route('/alerts', methods=['GET'])
def get_alerts():
    """Get all active alerts"""
    if MOCK_MODE:
        return jsonify({
            'status': 'success',
            'data': {
                'alerts': [
                    {
                        'labels': {
                            'alertname': 'HighCPUUsage',
                            'instance': 'localhost:9100',
                            'severity': 'warning'
                        },
                        'annotations': {
                            'summary': 'High CPU usage detected',
                            'description': 'CPU usage is above 90% for 5 minutes'
                        },
                        'state': 'firing',
                        'activeAt': datetime.now().isoformat(),
                        'value': '95.2'
                    }
                ]
            }
        })
    
    data = query_prometheus('alerts')
    
    if data is None:
        return jsonify({'error': 'Failed to get alerts'}), 500
    
    return jsonify(data)

# ============================================
# GET /api/prometheus/status/config
# Get Prometheus configuration
# ============================================
@prometheus_bp.route('/status/config', methods=['GET'])
def get_config():
    """Get Prometheus configuration"""
    if MOCK_MODE:
        return jsonify({
            'status': 'success',
            'data': {
                'yaml': 'global:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n\nscrape_configs:\n  - job_name: prometheus\n    static_configs:\n      - targets: [localhost:9090]\n  - job_name: node_exporter\n    static_configs:\n      - targets: [localhost:9100]'
            }
        })
    
    data = query_prometheus('status/config')
    
    if data is None:
        return jsonify({'error': 'Failed to get config'}), 500
    
    return jsonify(data)

# ============================================
# Health Check
# ============================================
@prometheus_bp.route('/health', methods=['GET'])
def health_check():
    """Check Prometheus connection"""
    if MOCK_MODE:
        return jsonify({
            'status': 'healthy',
            'mode': 'mock',
            'prometheus_url': PROMETHEUS_URL
        })
    
    try:
        response = requests.get(f"{PROMETHEUS_URL}/-/healthy", timeout=2)
        if response.status_code == 200:
            return jsonify({
                'status': 'healthy',
                'mode': 'production',
                'prometheus_url': PROMETHEUS_URL
            })
        else:
            return jsonify({
                'status': 'unhealthy',
                'mode': 'production',
                'prometheus_url': PROMETHEUS_URL,
                'error': f'HTTP {response.status_code}'
            }), 503
    except Exception as e:
        return jsonify({
            'status': 'unhealthy',
            'mode': 'production',
            'prometheus_url': PROMETHEUS_URL,
            'error': str(e)
        }), 503

print("‚úÖ Prometheus API initialized")
