# Prometheus Server (Port 9090) - ê¸°ëŠ¥ ìƒì„¸ ë¬¸ì„œ

## ğŸ“‹ ê°œìš”
ì‹œê³„ì—´ ë°ì´í„°ë² ì´ìŠ¤ ë° ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œìœ¼ë¡œ, ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.

**í¬íŠ¸**: 9090  
**í”„ë ˆì„ì›Œí¬**: Prometheus  
**ì¿¼ë¦¬ ì–¸ì–´**: PromQL  
**ë°ì´í„° ë³´ê´€**: Time Series Database  

---

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

### 1. ë””ë ‰í† ë¦¬ êµ¬ì¡°
```
prometheus_9090/
â”œâ”€â”€ prometheus.yml          # ë©”ì¸ ì„¤ì • íŒŒì¼
â”œâ”€â”€ prometheus             # ì‹¤í–‰ íŒŒì¼
â”œâ”€â”€ data/                  # ì‹œê³„ì—´ ë°ì´í„° ì €ì¥
â”œâ”€â”€ rules/                 # ì•Œë¦¼ ê·œì¹™
â”‚   â””â”€â”€ alerts.yml
â””â”€â”€ logs/
    â””â”€â”€ prometheus.log
```

### 2. ë°ì´í„° ìˆ˜ì§‘ êµ¬ì¡°
```
Prometheus (9090)
    â†“ (scrape)
Node Exporter (9100) â†’ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
    â†“
Dashboard Backend (5010) â†’ PromQL ì¿¼ë¦¬
    â†“
Dashboard Frontend (3010) â†’ ì°¨íŠ¸ ì‹œê°í™”
```

---

## âš™ï¸ ì„¤ì • íŒŒì¼ (`prometheus.yml`)

### ê¸°ë³¸ ì„¤ì •
```yaml
# ê¸€ë¡œë²Œ ì„¤ì •
global:
  scrape_interval: 15s      # 15ì´ˆë§ˆë‹¤ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
  evaluation_interval: 15s   # 15ì´ˆë§ˆë‹¤ ê·œì¹™ í‰ê°€
  external_labels:
    cluster: 'slurm-hpc'
    environment: 'production'

# Alertmanager ì„¤ì • (ì˜µì…˜)
alerting:
  alertmanagers:
    - static_configs:
        - targets: ['localhost:9093']

# ê·œì¹™ íŒŒì¼
rule_files:
  - 'rules/alerts.yml'

# ìŠ¤í¬ë© ì„¤ì •
scrape_configs:
  # Prometheus ìì²´ ëª¨ë‹ˆí„°ë§
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
  
  # Node Exporter (ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­)
  - job_name: 'node_exporter'
    static_configs:
      - targets: ['localhost:9100']
        labels:
          node: 'master'
      - targets: ['node001:9100', 'node002:9100', 'node003:9100', 'node004:9100']
        labels:
          node_group: 'compute'
  
  # NVIDIA GPU Exporter (GPU ë©”íŠ¸ë¦­)
  - job_name: 'nvidia_exporter'
    static_configs:
      - targets: ['localhost:9445']
        labels:
          node: 'master'
      - targets: ['node001:9445', 'node002:9445']
        labels:
          node_group: 'gpu'
  
  # Slurm Exporter (Slurm ì‘ì—… ë©”íŠ¸ë¦­)
  - job_name: 'slurm_exporter'
    static_configs:
      - targets: ['localhost:9341']
```

---

## ğŸ“Š ë©”íŠ¸ë¦­ íƒ€ì…

### 1. Node Exporter ë©”íŠ¸ë¦­

#### CPU ë©”íŠ¸ë¦­
| ë©”íŠ¸ë¦­ ì´ë¦„ | ì„¤ëª… | ë‹¨ìœ„ |
|------------|------|------|
| `node_cpu_seconds_total` | CPU ì‹œê°„ ëˆ„ì  | seconds |
| `node_load1` | 1ë¶„ í‰ê·  ë¶€í•˜ | - |
| `node_load5` | 5ë¶„ í‰ê·  ë¶€í•˜ | - |
| `node_load15` | 15ë¶„ í‰ê·  ë¶€í•˜ | - |

**CPU ì‚¬ìš©ë¥  ê³„ì‚° (PromQL)**
```promql
# ì „ì²´ CPU ì‚¬ìš©ë¥ 
100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)

# ì½”ì–´ë³„ CPU ì‚¬ìš©ë¥ 
100 - (avg by (instance, cpu) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)

# ëª¨ë“œë³„ CPU ì‚¬ìš©ë¥ 
rate(node_cpu_seconds_total{mode="user"}[5m]) * 100    # user
rate(node_cpu_seconds_total{mode="system"}[5m]) * 100  # system
rate(node_cpu_seconds_total{mode="iowait"}[5m]) * 100  # iowait
```

#### ë©”ëª¨ë¦¬ ë©”íŠ¸ë¦­
| ë©”íŠ¸ë¦­ ì´ë¦„ | ì„¤ëª… | ë‹¨ìœ„ |
|------------|------|------|
| `node_memory_MemTotal_bytes` | ì „ì²´ ë©”ëª¨ë¦¬ | bytes |
| `node_memory_MemAvailable_bytes` | ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬ | bytes |
| `node_memory_MemFree_bytes` | ë¹ˆ ë©”ëª¨ë¦¬ | bytes |
| `node_memory_Buffers_bytes` | ë²„í¼ ë©”ëª¨ë¦¬ | bytes |
| `node_memory_Cached_bytes` | ìºì‹œ ë©”ëª¨ë¦¬ | bytes |

**ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ê³„ì‚° (PromQL)**
```promql
# ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  (%)
(1 - node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100

# ì‚¬ìš© ì¤‘ì¸ ë©”ëª¨ë¦¬ (GB)
(node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / 1024 / 1024 / 1024

# ìŠ¤ì™‘ ì‚¬ìš©ë¥ 
(1 - node_memory_SwapFree_bytes / node_memory_SwapTotal_bytes) * 100
```

#### ë””ìŠ¤í¬ ë©”íŠ¸ë¦­
| ë©”íŠ¸ë¦­ ì´ë¦„ | ì„¤ëª… | ë‹¨ìœ„ |
|------------|------|------|
| `node_filesystem_size_bytes` | íŒŒì¼ì‹œìŠ¤í…œ í¬ê¸° | bytes |
| `node_filesystem_avail_bytes` | ì‚¬ìš© ê°€ëŠ¥ ê³µê°„ | bytes |
| `node_filesystem_files` | ì „ì²´ inode ìˆ˜ | - |
| `node_disk_io_time_seconds_total` | ë””ìŠ¤í¬ I/O ì‹œê°„ | seconds |
| `node_disk_read_bytes_total` | ì½ì€ ë°”ì´íŠ¸ | bytes |
| `node_disk_written_bytes_total` | ì“´ ë°”ì´íŠ¸ | bytes |

**ë””ìŠ¤í¬ ì‚¬ìš©ë¥  ê³„ì‚° (PromQL)**
```promql
# ë””ìŠ¤í¬ ì‚¬ìš©ë¥  (%)
(1 - node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100

# ë””ìŠ¤í¬ I/O ì†ë„ (bytes/sec)
rate(node_disk_read_bytes_total[5m])    # ì½ê¸°
rate(node_disk_written_bytes_total[5m]) # ì“°ê¸°

# /data íŒŒí‹°ì…˜ ì‚¬ìš©ë¥ 
(1 - node_filesystem_avail_bytes{mountpoint="/data"} / node_filesystem_size_bytes{mountpoint="/data"}) * 100
```

#### ë„¤íŠ¸ì›Œí¬ ë©”íŠ¸ë¦­
| ë©”íŠ¸ë¦­ ì´ë¦„ | ì„¤ëª… | ë‹¨ìœ„ |
|------------|------|------|
| `node_network_receive_bytes_total` | ìˆ˜ì‹  ë°”ì´íŠ¸ | bytes |
| `node_network_transmit_bytes_total` | ì†¡ì‹  ë°”ì´íŠ¸ | bytes |
| `node_network_receive_packets_total` | ìˆ˜ì‹  íŒ¨í‚· | packets |
| `node_network_transmit_packets_total` | ì†¡ì‹  íŒ¨í‚· | packets |

**ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ ê³„ì‚° (PromQL)**
```promql
# ìˆ˜ì‹  ì†ë„ (bytes/sec)
rate(node_network_receive_bytes_total{device="eth0"}[5m])

# ì†¡ì‹  ì†ë„ (bytes/sec)
rate(node_network_transmit_bytes_total{device="eth0"}[5m])

# ì „ì²´ íŠ¸ë˜í”½ (Mbps)
(rate(node_network_receive_bytes_total[5m]) + rate(node_network_transmit_bytes_total[5m])) * 8 / 1000000
```

---

### 2. NVIDIA GPU ë©”íŠ¸ë¦­

#### GPU ì‚¬ìš©ë¥ 
| ë©”íŠ¸ë¦­ ì´ë¦„ | ì„¤ëª… | ë‹¨ìœ„ |
|------------|------|------|
| `nvidia_smi_utilization_gpu_ratio` | GPU ì‚¬ìš©ë¥  | ratio (0-1) |
| `nvidia_smi_utilization_memory_ratio` | GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  | ratio (0-1) |
| `nvidia_smi_memory_total_bytes` | ì „ì²´ GPU ë©”ëª¨ë¦¬ | bytes |
| `nvidia_smi_memory_used_bytes` | ì‚¬ìš© ì¤‘ GPU ë©”ëª¨ë¦¬ | bytes |
| `nvidia_smi_temperature_gpu` | GPU ì˜¨ë„ | celsius |
| `nvidia_smi_power_draw_watts` | GPU ì „ë ¥ ì†Œë¹„ | watts |

**GPU ë©”íŠ¸ë¦­ ì¿¼ë¦¬ (PromQL)**
```promql
# GPU ì‚¬ìš©ë¥  (%)
nvidia_smi_utilization_gpu_ratio * 100

# GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  (%)
nvidia_smi_utilization_memory_ratio * 100

# GPUë³„ ì˜¨ë„
nvidia_smi_temperature_gpu

# GPUë³„ ì „ë ¥ ì†Œë¹„
nvidia_smi_power_draw_watts

# í‰ê·  GPU ì‚¬ìš©ë¥ 
avg(nvidia_smi_utilization_gpu_ratio) * 100

# Top ì‚¬ìš©ë¥  GPU
topk(5, nvidia_smi_utilization_gpu_ratio * 100)
```

---

### 3. Slurm Exporter ë©”íŠ¸ë¦­

#### ì‘ì—… ë©”íŠ¸ë¦­
| ë©”íŠ¸ë¦­ ì´ë¦„ | ì„¤ëª… |
|------------|------|
| `slurm_queue_jobs` | íì— ëŒ€ê¸° ì¤‘ì¸ ì‘ì—… ìˆ˜ |
| `slurm_running_jobs` | ì‹¤í–‰ ì¤‘ì¸ ì‘ì—… ìˆ˜ |
| `slurm_job_cpus_allocated` | í• ë‹¹ëœ CPU ìˆ˜ |
| `slurm_job_memory_allocated_bytes` | í• ë‹¹ëœ ë©”ëª¨ë¦¬ |

#### ë…¸ë“œ ë©”íŠ¸ë¦­
| ë©”íŠ¸ë¦­ ì´ë¦„ | ì„¤ëª… |
|------------|------|
| `slurm_nodes_total` | ì „ì²´ ë…¸ë“œ ìˆ˜ |
| `slurm_nodes_idle` | ìœ íœ´ ë…¸ë“œ ìˆ˜ |
| `slurm_nodes_allocated` | í• ë‹¹ëœ ë…¸ë“œ ìˆ˜ |
| `slurm_nodes_down` | ë‹¤ìš´ëœ ë…¸ë“œ ìˆ˜ |

**Slurm ë©”íŠ¸ë¦­ ì¿¼ë¦¬ (PromQL)**
```promql
# ì „ì²´ ì‘ì—… ìˆ˜
slurm_queue_jobs + slurm_running_jobs

# ë…¸ë“œ ì‚¬ìš©ë¥ 
(slurm_nodes_allocated / slurm_nodes_total) * 100

# CPU í• ë‹¹ë¥ 
(slurm_job_cpus_allocated / slurm_cpus_total) * 100
```

---

## ğŸ” PromQL ì¿¼ë¦¬ ì˜ˆì œ

### ê¸°ë³¸ ì¿¼ë¦¬
```promql
# ë‹¨ì¼ ë©”íŠ¸ë¦­ ì¡°íšŒ
node_cpu_seconds_total

# ë ˆì´ë¸” í•„í„°ë§
node_cpu_seconds_total{cpu="0", mode="idle"}

# ì •ê·œí‘œí˜„ì‹ í•„í„°
node_cpu_seconds_total{instance=~"node.*"}

# ì—¬ëŸ¬ ì¡°ê±´
node_cpu_seconds_total{mode="idle", cpu=~"[0-3]"}
```

### í•¨ìˆ˜ ì‚¬ìš©
```promql
# rate() - ì´ˆë‹¹ ë³€í™”ìœ¨
rate(node_cpu_seconds_total[5m])

# irate() - ìˆœê°„ ë³€í™”ìœ¨
irate(node_cpu_seconds_total[5m])

# increase() - ì¦ê°€ëŸ‰
increase(node_network_receive_bytes_total[1h])

# avg() - í‰ê· 
avg(node_cpu_seconds_total) by (instance)

# sum() - í•©ê³„
sum(node_memory_MemTotal_bytes) by (instance)

# topk() - ìƒìœ„ kê°œ
topk(5, node_cpu_seconds_total)
```

### ê³ ê¸‰ ì¿¼ë¦¬
```promql
# CPU ì‚¬ìš©ë¥  (ëª¨ë“  ì½”ì–´ í‰ê· )
100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (GB)
(node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / 1024 / 1024 / 1024

# ë””ìŠ¤í¬ I/O (MB/s)
rate(node_disk_read_bytes_total[5m]) / 1024 / 1024

# ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­ (Mbps)
(rate(node_network_receive_bytes_total[5m]) * 8) / 1000000

# GPU í‰ê·  ì˜¨ë„
avg(nvidia_smi_temperature_gpu) by (instance)

# ë…¸ë“œë³„ Top 5 CPU ì‚¬ìš©ë¥ 
topk(5, 100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100))
```

### ë¹„êµ ì¿¼ë¦¬
```promql
# CPU vs Memory ì‚¬ìš©ë¥  ë¹„êµ
100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)
or
(1 - node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100

# ì—¬ëŸ¬ ë…¸ë“œ ë¹„êµ
avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100
```

---

## ğŸš¨ ì•Œë¦¼ ê·œì¹™ (`rules/alerts.yml`)

### ê¸°ë³¸ ì•Œë¦¼ ê·œì¹™
```yaml
groups:
  - name: node_alerts
    interval: 30s
    rules:
      # ë†’ì€ CPU ì‚¬ìš©ë¥ 
      - alert: HighCPUUsage
        expr: 100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 90
        for: 5m
        labels:
          severity: warning
          component: cpu
        annotations:
          summary: "High CPU usage on {{ $labels.instance }}"
          description: "CPU usage is {{ $value }}% on {{ $labels.instance }}"
      
      # ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
      - alert: HighMemoryUsage
        expr: (1 - node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100 > 90
        for: 5m
        labels:
          severity: warning
          component: memory
        annotations:
          summary: "High memory usage on {{ $labels.instance }}"
          description: "Memory usage is {{ $value }}% on {{ $labels.instance }}"
      
      # ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±
      - alert: LowDiskSpace
        expr: (1 - node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100 > 85
        for: 10m
        labels:
          severity: warning
          component: disk
        annotations:
          summary: "Low disk space on {{ $labels.instance }}"
          description: "Disk usage is {{ $value }}% on {{ $labels.mountpoint }}"
      
      # ë†’ì€ GPU ì˜¨ë„
      - alert: HighGPUTemperature
        expr: nvidia_smi_temperature_gpu > 80
        for: 5m
        labels:
          severity: warning
          component: gpu
        annotations:
          summary: "High GPU temperature on {{ $labels.instance }}"
          description: "GPU {{ $labels.gpu }} temperature is {{ $value }}Â°C"
      
      # ë…¸ë“œ ë‹¤ìš´
      - alert: NodeDown
        expr: up{job="node_exporter"} == 0
        for: 1m
        labels:
          severity: critical
          component: node
        annotations:
          summary: "Node {{ $labels.instance }} is down"
          description: "Node exporter on {{ $labels.instance }} is not responding"
```

---

## ğŸ”Œ API ì—”ë“œí¬ì¸íŠ¸

### ì¿¼ë¦¬ API
```bash
# Instant query
curl 'http://localhost:9090/api/v1/query?query=up'

# Range query
curl 'http://localhost:9090/api/v1/query_range?query=node_cpu_seconds_total&start=2025-10-10T00:00:00Z&end=2025-10-10T01:00:00Z&step=15s'

# ë ˆì´ë¸” ëª©ë¡
curl 'http://localhost:9090/api/v1/labels'

# ë ˆì´ë¸” ê°’ ëª©ë¡
curl 'http://localhost:9090/api/v1/label/__name__/values'

# ì‹œê³„ì—´ ì¡°íšŒ
curl 'http://localhost:9090/api/v1/series?match[]=node_cpu_seconds_total'
```

### ê´€ë¦¬ API
```bash
# íƒ€ê²Ÿ ëª©ë¡
curl 'http://localhost:9090/api/v1/targets'

# ê·œì¹™ ëª©ë¡
curl 'http://localhost:9090/api/v1/rules'

# ì•Œë¦¼ ëª©ë¡
curl 'http://localhost:9090/api/v1/alerts'

# ì„¤ì • ì¡°íšŒ
curl 'http://localhost:9090/api/v1/status/config'

# Health check
curl 'http://localhost:9090/-/healthy'

# Readiness check
curl 'http://localhost:9090/-/ready'
```

---

## ğŸ–¥ï¸ Web UI

### ì ‘ì†
```
http://localhost:9090
```

### ì£¼ìš” ê¸°ëŠ¥
1. **Graph**: PromQL ì¿¼ë¦¬ ì‹¤í–‰ ë° ê·¸ë˜í”„ ì‹œê°í™”
2. **Alerts**: í™œì„± ì•Œë¦¼ ëª©ë¡
3. **Status**: 
   - Targets: ìŠ¤í¬ë© íƒ€ê²Ÿ ìƒíƒœ
   - Configuration: í˜„ì¬ ì„¤ì •
   - Rules: ì•Œë¦¼ ê·œì¹™
   - Service Discovery: ìë™ ë°œê²¬ ìƒíƒœ
4. **Metrics Explorer**: ë©”íŠ¸ë¦­ íƒìƒ‰

---

## ğŸ’¾ ë°ì´í„° ë³´ê´€

### ë³´ê´€ ì„¤ì •
```yaml
# prometheus.yml
global:
  storage:
    tsdb:
      path: ./data
      retention.time: 15d      # 15ì¼ ë³´ê´€
      retention.size: 50GB     # ìµœëŒ€ 50GB
```

### ë°ì´í„° ë°±ì—…
```bash
# ìŠ¤ëƒ…ìƒ· ìƒì„±
curl -XPOST http://localhost:9090/api/v1/admin/tsdb/snapshot

# ìŠ¤ëƒ…ìƒ· ìœ„ì¹˜
# data/snapshots/YYYYMMDDTHHMMSS-XXXXX/
```

---

## ğŸš€ ì‹œì‘/ì¤‘ì§€ ìŠ¤í¬ë¦½íŠ¸

### `start.sh`
```bash
#!/bin/bash
cd "$(dirname "$0")"

./prometheus \
  --config.file=prometheus.yml \
  --storage.tsdb.path=./data \
  --web.console.templates=./consoles \
  --web.console.libraries=./console_libraries \
  --web.listen-address=:9090 \
  --storage.tsdb.retention.time=15d \
  > logs/prometheus.log 2>&1 &

echo $! > .prometheus.pid
echo "âœ… Prometheus started on http://localhost:9090"
```

### `stop.sh`
```bash
#!/bin/bash
if [ -f .prometheus.pid ]; then
    kill $(cat .prometheus.pid)
    rm .prometheus.pid
    echo "âœ… Prometheus stopped"
fi
```

---

## ğŸ”§ ìµœì í™” íŒ

### 1. ì¿¼ë¦¬ ìµœì í™”
```promql
# ë‚˜ìœ ì˜ˆ: ëª¨ë“  ì‹œê³„ì—´ ì¡°íšŒ
node_cpu_seconds_total

# ì¢‹ì€ ì˜ˆ: í•„í„°ë§
node_cpu_seconds_total{instance="node001:9100"}

# ë‚˜ìœ ì˜ˆ: ê¸´ ë²”ìœ„
rate(node_cpu_seconds_total[1h])

# ì¢‹ì€ ì˜ˆ: ì ì ˆí•œ ë²”ìœ„
rate(node_cpu_seconds_total[5m])
```

### 2. Recording Rules
ìì£¼ ì‚¬ìš©í•˜ëŠ” ë³µì¡í•œ ì¿¼ë¦¬ë¥¼ ë¯¸ë¦¬ ê³„ì‚°í•˜ì—¬ ì €ì¥

```yaml
# rules/recording.yml
groups:
  - name: cpu_rules
    interval: 15s
    rules:
      - record: instance:node_cpu_utilization:rate5m
        expr: 100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)
      
      - record: instance:node_memory_utilization:ratio
        expr: 1 - node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes
```

ì‚¬ìš©:
```promql
# ë³µì¡í•œ ì›ë³¸ ì¿¼ë¦¬ ëŒ€ì‹ 
instance:node_cpu_utilization:rate5m

# ë¹ ë¥´ê³  ê°„ë‹¨
instance:node_memory_utilization:ratio * 100
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸

### ë©”íŠ¸ë¦­ í™•ì¸
```bash
# Node Exporter ë©”íŠ¸ë¦­ í™•ì¸
curl http://localhost:9100/metrics | grep node_cpu

# Prometheusê°€ ìˆ˜ì§‘í•˜ëŠ”ì§€ í™•ì¸
curl 'http://localhost:9090/api/v1/query?query=up{job="node_exporter"}'
```

### ì•Œë¦¼ í…ŒìŠ¤íŠ¸
```bash
# CPU ë¶€í•˜ ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)
stress-ng --cpu 8 --timeout 300s

# ì•Œë¦¼ ë°œìƒ í™•ì¸
curl 'http://localhost:9090/api/v1/alerts' | jq
```

---

## ğŸ“Š ëŒ€ì‹œë³´ë“œ í†µí•©

### Grafana ì—°ë™ (ì˜µì…˜)
```bash
# Grafana ì„¤ì¹˜
sudo apt-get install grafana

# Prometheus ë°ì´í„° ì†ŒìŠ¤ ì¶”ê°€
curl -X POST http://admin:admin@localhost:3000/api/datasources \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Prometheus",
    "type": "prometheus",
    "url": "http://localhost:9090",
    "access": "proxy",
    "isDefault": true
  }'
```

---

## ğŸš€ ì¶”ê°€ ê¸°ëŠ¥ ë¡œë“œë§µ

### Phase 1: í˜„ì¬ êµ¬í˜„ ì™„ë£Œ
- âœ… Node Exporter ì—°ë™
- âœ… GPU ë©”íŠ¸ë¦­ ìˆ˜ì§‘
- âœ… ì•Œë¦¼ ê·œì¹™ ì„¤ì •
- âœ… 15ì¼ ë°ì´í„° ë³´ê´€

### Phase 2: ê°œì„  ì˜ˆì •
- ğŸ”„ **Alertmanager í†µí•©**: ì•Œë¦¼ ë¼ìš°íŒ… ë° ê·¸ë£¹í™”
- ğŸ”„ **Remote Storage**: ì¥ê¸° ë°ì´í„° ë³´ê´€
- ğŸ”„ **Service Discovery**: ë™ì  íƒ€ê²Ÿ ë°œê²¬
- ğŸ”„ **Federation**: ì—¬ëŸ¬ Prometheus ì„œë²„ í†µí•©

### Phase 3: ì‹ ê·œ ê¸°ëŠ¥
- ğŸ“‹ **Custom Exporters**: Slurm ì „ìš© ë©”íŠ¸ë¦­
- ğŸ“‹ **Thanos í†µí•©**: ê³ ê°€ìš©ì„± ë° ì¥ê¸° ì €ì¥
- ğŸ“‹ **Machine Learning**: ì´ìƒ íƒì§€
- ğŸ“‹ **Cost Analysis**: ë¦¬ì†ŒìŠ¤ ë¹„ìš© ë¶„ì„

---

## ğŸ“š ì°¸ê³  ìë£Œ
- [Prometheus ê³µì‹ ë¬¸ì„œ](https://prometheus.io/docs/)
- [PromQL ê°€ì´ë“œ](https://prometheus.io/docs/prometheus/latest/querying/basics/)
- [Node Exporter](https://github.com/prometheus/node_exporter)
- [Best Practices](https://prometheus.io/docs/practices/)
