# Large File Upload Optimization Implementation Guide

**ê°œì„  í•­ëª© #4**: ëŒ€ìš©ëŸ‰ íŒŒì¼ ì—…ë¡œë“œ ìµœì í™”
**ìš°ì„ ìˆœìœ„**: High
**ë‚œì´ë„**: Medium
**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 3-4 hours

---

## ğŸ“‹ ëª©ì°¨

1. [ê°œìš”](#ê°œìš”)
2. [í˜„ì¬ ë¬¸ì œì ](#í˜„ì¬-ë¬¸ì œì )
3. [í•´ê²° ë°©ì•ˆ ì•„í‚¤í…ì²˜](#í•´ê²°-ë°©ì•ˆ-ì•„í‚¤í…ì²˜)
4. [Backend êµ¬í˜„](#backend-êµ¬í˜„)
5. [Frontend êµ¬í˜„](#frontend-êµ¬í˜„)
6. [í…ŒìŠ¤íŠ¸](#í…ŒìŠ¤íŠ¸)
7. [ì„±ëŠ¥ ìµœì í™”](#ì„±ëŠ¥-ìµœì í™”)
8. [ë³´ì•ˆ ê³ ë ¤ì‚¬í•­](#ë³´ì•ˆ-ê³ ë ¤ì‚¬í•­)

---

## ê°œìš”

### ëª©í‘œ
- ëŒ€ìš©ëŸ‰ íŒŒì¼(ìˆ˜ GB)ì„ ì•ˆì •ì ìœ¼ë¡œ ì—…ë¡œë“œ
- ì—…ë¡œë“œ ì§„í–‰ ìƒí™©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í‘œì‹œ
- ë„¤íŠ¸ì›Œí¬ ëŠê¹€ ì‹œ ì¬ê°œ(Resume) ê°€ëŠ¥
- ì²­í¬ ë‹¨ìœ„ ì—…ë¡œë“œë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ

### ê¸°ìˆ  ìŠ¤íƒ
- **Backend**: Flask + Flask-CORS + `werkzeug.utils`
- **Frontend**: React + Axios + `@uppy/core` + `@uppy/xhr-upload`
- **Protocol**: Chunked Upload (Custom or Tus.js)

### ì£¼ìš” ê¸°ëŠ¥
1. **Chunked Upload**: íŒŒì¼ì„ ì‘ì€ ì²­í¬ë¡œ ë¶„í• í•˜ì—¬ ì—…ë¡œë“œ
2. **Progress Tracking**: ì‹¤ì‹œê°„ ì§„í–‰ë¥  í‘œì‹œ
3. **Resume Support**: ì¤‘ë‹¨ëœ ì—…ë¡œë“œ ì¬ê°œ
4. **Concurrent Uploads**: ì—¬ëŸ¬ íŒŒì¼ ë™ì‹œ ì—…ë¡œë“œ
5. **Error Handling**: ì¬ì‹œë„ ë¡œì§ ë° ì˜¤ë¥˜ ì²˜ë¦¬

---

## í˜„ì¬ ë¬¸ì œì 

### 1. ë‹¨ì¼ ìš”ì²­ ì—…ë¡œë“œì˜ í•œê³„
```typescript
// í˜„ì¬ ë°©ì‹ (TemplateEditor.tsx)
const handleFileChange = (e: React.ChangeEvent<HTMLInputElement>, isRequired: boolean) => {
  const files = e.target.files;
  if (!files || files.length === 0) return;

  const file = files[0];
  // ë¬¸ì œ: ëŒ€ìš©ëŸ‰ íŒŒì¼ ì „ì²´ë¥¼ ë©”ëª¨ë¦¬ì— ë¡œë“œ
  const formData = new FormData();
  formData.append('file', file);

  // ë¬¸ì œ: íƒ€ì„ì•„ì›ƒ, ë©”ëª¨ë¦¬ ë¶€ì¡±, ì¬ê°œ ë¶ˆê°€
  apiPost('/api/upload', formData);
};
```

**ë¬¸ì œì **:
- íŒŒì¼ ì „ì²´ë¥¼ ë©”ëª¨ë¦¬ì— ë¡œë“œ â†’ ë©”ëª¨ë¦¬ ë¶€ì¡± ìœ„í—˜
- ë„¤íŠ¸ì›Œí¬ íƒ€ì„ì•„ì›ƒ (ìˆ˜ GB íŒŒì¼ ì—…ë¡œë“œ ì‹œ)
- ì¤‘ë‹¨ ì‹œ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œì‘
- ì§„í–‰ ìƒí™© ì¶”ì  ì–´ë ¤ì›€

### 2. Backend ë©”ëª¨ë¦¬ ë¬¸ì œ
```python
# í˜„ì¬ ë°©ì‹ (ì¶”ì •)
@app.route('/api/upload', methods=['POST'])
def upload_file():
    file = request.files['file']
    # ë¬¸ì œ: ì „ì²´ íŒŒì¼ì„ ë©”ëª¨ë¦¬ì— ì €ì¥
    file.save(f'/uploads/{file.filename}')
```

**ë¬¸ì œì **:
- íŒŒì¼ ì „ì²´ë¥¼ ë©”ëª¨ë¦¬ì— ì ì¬
- ë™ì‹œ ë‹¤ìˆ˜ ì—…ë¡œë“œ ì‹œ ì„œë²„ ë©”ëª¨ë¦¬ ë¶€ì¡±

---

## í•´ê²° ë°©ì•ˆ ì•„í‚¤í…ì²˜

### ì „ì²´ íë¦„ë„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend (React)                                            â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚ FileUploader     â”‚                                       â”‚
â”‚  â”‚ Component        â”‚                                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚           â”‚                                                 â”‚
â”‚           â”‚ 1. File selected                                â”‚
â”‚           â–¼                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚ useChunkedUpload â”‚ â—„â”€â”€â”€â”€ 2. Split into chunks (5MB)     â”‚
â”‚  â”‚ Hook             â”‚                                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚           â”‚                                                 â”‚
â”‚           â”‚ 3. Upload chunk by chunk                        â”‚
â”‚           â–¼                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”‚ Axios POST /api/upload/chunk
            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Backend (Flask)                                             â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚ /api/upload/init â”‚ â—„â”€â”€â”€â”€ 4. Initialize upload session   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       Returns: upload_id             â”‚
â”‚           â”‚                                                 â”‚
â”‚           â–¼                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚ /api/upload/chunkâ”‚ â—„â”€â”€â”€â”€ 5. Receive chunk               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       Save to temp: {upload_id}/{n}  â”‚
â”‚           â”‚                                                 â”‚
â”‚           â”‚ Repeat for all chunks                           â”‚
â”‚           â–¼                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚ /api/upload/     â”‚ â—„â”€â”€â”€â”€ 6. Finalize upload             â”‚
â”‚  â”‚ finalize         â”‚       Merge chunks â†’ final file      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ì²­í¬ ì—…ë¡œë“œ í”„ë¡œí† ì½œ

**ë‹¨ê³„ë³„ íë¦„**:

1. **ì´ˆê¸°í™” (Initialize)**
   ```
   POST /api/upload/init
   Body: { filename, fileSize, chunkSize }
   Response: { upload_id, existingChunks }
   ```

2. **ì²­í¬ ì—…ë¡œë“œ (Upload Chunks)**
   ```
   POST /api/upload/chunk
   Body: FormData {
     upload_id,
     chunk_index,
     chunk_data (binary)
   }
   Response: { success, chunk_index }
   ```

3. **ì™„ë£Œ (Finalize)**
   ```
   POST /api/upload/finalize
   Body: { upload_id, totalChunks, filename }
   Response: { success, file_path }
   ```

---

## Backend êµ¬í˜„

### 1. íŒŒì¼ êµ¬ì¡°

```
dashboard/backend_5010/
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ chunked_upload.py      # ì²­í¬ ì—…ë¡œë“œ ìœ í‹¸ë¦¬í‹°
â”‚   â””â”€â”€ upload_manager.py      # ì—…ë¡œë“œ ì„¸ì…˜ ê´€ë¦¬
â””â”€â”€ api/
    â””â”€â”€ upload_routes.py        # ì—…ë¡œë“œ API ì—”ë“œí¬ì¸íŠ¸
```

### 2. Chunked Upload Utility

**íŒŒì¼**: `dashboard/backend_5010/utils/chunked_upload.py`

```python
"""
Chunked Upload Utility
ëŒ€ìš©ëŸ‰ íŒŒì¼ì„ ì²­í¬ ë‹¨ìœ„ë¡œ ì—…ë¡œë“œí•˜ê³  ë³‘í•©
"""

import os
import uuid
import hashlib
from pathlib import Path
from typing import List, Optional
import logging

logger = logging.getLogger(__name__)

CHUNK_UPLOAD_DIR = Path('/tmp/slurm_uploads')
CHUNK_UPLOAD_DIR.mkdir(parents=True, exist_ok=True)


class ChunkedUploadManager:
    """ì²­í¬ ì—…ë¡œë“œ ì„¸ì…˜ ê´€ë¦¬"""

    def __init__(self, upload_dir: str = str(CHUNK_UPLOAD_DIR)):
        self.upload_dir = Path(upload_dir)
        self.upload_dir.mkdir(parents=True, exist_ok=True)

    def init_upload(self, filename: str, file_size: int, chunk_size: int) -> dict:
        """
        ì—…ë¡œë“œ ì„¸ì…˜ ì´ˆê¸°í™”

        Args:
            filename: ì›ë³¸ íŒŒì¼ëª…
            file_size: ì „ì²´ íŒŒì¼ í¬ê¸° (bytes)
            chunk_size: ì²­í¬ í¬ê¸° (bytes)

        Returns:
            {
                'upload_id': str,
                'total_chunks': int,
                'existing_chunks': List[int]  # ì´ë¯¸ ì—…ë¡œë“œëœ ì²­í¬ (ì¬ê°œìš©)
            }
        """
        upload_id = str(uuid.uuid4())
        upload_dir = self.upload_dir / upload_id
        upload_dir.mkdir(parents=True, exist_ok=True)

        # ë©”íƒ€ë°ì´í„° ì €ì¥
        total_chunks = (file_size + chunk_size - 1) // chunk_size
        metadata = {
            'filename': filename,
            'file_size': file_size,
            'chunk_size': chunk_size,
            'total_chunks': total_chunks,
            'upload_id': upload_id
        }

        metadata_path = upload_dir / 'metadata.json'
        with open(metadata_path, 'w') as f:
            import json
            json.dump(metadata, f)

        logger.info(f"Upload initialized: {upload_id} ({filename}, {file_size} bytes, {total_chunks} chunks)")

        return {
            'upload_id': upload_id,
            'total_chunks': total_chunks,
            'existing_chunks': []  # ìƒˆ ì—…ë¡œë“œëŠ” ë¹ˆ ë¦¬ìŠ¤íŠ¸
        }

    def save_chunk(self, upload_id: str, chunk_index: int, chunk_data: bytes) -> bool:
        """
        ì²­í¬ ë°ì´í„° ì €ì¥

        Args:
            upload_id: ì—…ë¡œë“œ ì„¸ì…˜ ID
            chunk_index: ì²­í¬ ì¸ë±ìŠ¤ (0ë¶€í„° ì‹œì‘)
            chunk_data: ì²­í¬ ë°”ì´ë„ˆë¦¬ ë°ì´í„°

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        upload_dir = self.upload_dir / upload_id
        if not upload_dir.exists():
            logger.error(f"Upload session not found: {upload_id}")
            return False

        chunk_path = upload_dir / f'chunk_{chunk_index:06d}'

        try:
            with open(chunk_path, 'wb') as f:
                f.write(chunk_data)

            logger.debug(f"Chunk saved: {upload_id} - chunk {chunk_index} ({len(chunk_data)} bytes)")
            return True

        except Exception as e:
            logger.error(f"Failed to save chunk {chunk_index} for {upload_id}: {e}")
            return False

    def get_existing_chunks(self, upload_id: str) -> List[int]:
        """
        ì´ë¯¸ ì—…ë¡œë“œëœ ì²­í¬ ëª©ë¡ ë°˜í™˜ (ì¬ê°œìš©)

        Args:
            upload_id: ì—…ë¡œë“œ ì„¸ì…˜ ID

        Returns:
            ì²­í¬ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸
        """
        upload_dir = self.upload_dir / upload_id
        if not upload_dir.exists():
            return []

        chunks = []
        for chunk_file in upload_dir.glob('chunk_*'):
            try:
                chunk_index = int(chunk_file.name.replace('chunk_', ''))
                chunks.append(chunk_index)
            except ValueError:
                continue

        return sorted(chunks)

    def finalize_upload(self, upload_id: str, output_path: str) -> bool:
        """
        ëª¨ë“  ì²­í¬ë¥¼ ë³‘í•©í•˜ì—¬ ìµœì¢… íŒŒì¼ ìƒì„±

        Args:
            upload_id: ì—…ë¡œë“œ ì„¸ì…˜ ID
            output_path: ìµœì¢… íŒŒì¼ ì €ì¥ ê²½ë¡œ

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        upload_dir = self.upload_dir / upload_id
        if not upload_dir.exists():
            logger.error(f"Upload session not found: {upload_id}")
            return False

        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        metadata_path = upload_dir / 'metadata.json'
        if not metadata_path.exists():
            logger.error(f"Metadata not found: {upload_id}")
            return False

        with open(metadata_path, 'r') as f:
            import json
            metadata = json.load(f)

        total_chunks = metadata['total_chunks']
        existing_chunks = self.get_existing_chunks(upload_id)

        # ëª¨ë“  ì²­í¬ê°€ ìˆëŠ”ì§€ í™•ì¸
        if len(existing_chunks) != total_chunks:
            logger.error(f"Missing chunks: expected {total_chunks}, got {len(existing_chunks)}")
            return False

        # ì²­í¬ ë³‘í•©
        try:
            output_file = Path(output_path)
            output_file.parent.mkdir(parents=True, exist_ok=True)

            with open(output_file, 'wb') as outf:
                for chunk_index in range(total_chunks):
                    chunk_path = upload_dir / f'chunk_{chunk_index:06d}'

                    if not chunk_path.exists():
                        logger.error(f"Chunk {chunk_index} not found")
                        return False

                    with open(chunk_path, 'rb') as inf:
                        outf.write(inf.read())

            # íŒŒì¼ í¬ê¸° ê²€ì¦
            actual_size = output_file.stat().st_size
            expected_size = metadata['file_size']

            if actual_size != expected_size:
                logger.error(f"File size mismatch: expected {expected_size}, got {actual_size}")
                return False

            logger.info(f"Upload finalized: {upload_id} â†’ {output_path} ({actual_size} bytes)")

            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            self.cleanup_upload(upload_id)

            return True

        except Exception as e:
            logger.error(f"Failed to finalize upload {upload_id}: {e}")
            return False

    def cleanup_upload(self, upload_id: str):
        """
        ì—…ë¡œë“œ ì„¸ì…˜ ì„ì‹œ íŒŒì¼ ì‚­ì œ

        Args:
            upload_id: ì—…ë¡œë“œ ì„¸ì…˜ ID
        """
        upload_dir = self.upload_dir / upload_id
        if not upload_dir.exists():
            return

        try:
            import shutil
            shutil.rmtree(upload_dir)
            logger.info(f"Upload session cleaned up: {upload_id}")
        except Exception as e:
            logger.error(f"Failed to cleanup upload {upload_id}: {e}")

    def get_upload_progress(self, upload_id: str) -> dict:
        """
        ì—…ë¡œë“œ ì§„í–‰ ìƒí™© ë°˜í™˜

        Args:
            upload_id: ì—…ë¡œë“œ ì„¸ì…˜ ID

        Returns:
            {
                'total_chunks': int,
                'uploaded_chunks': int,
                'progress_percent': float
            }
        """
        upload_dir = self.upload_dir / upload_id
        if not upload_dir.exists():
            return {'error': 'Upload session not found'}

        metadata_path = upload_dir / 'metadata.json'
        if not metadata_path.exists():
            return {'error': 'Metadata not found'}

        with open(metadata_path, 'r') as f:
            import json
            metadata = json.load(f)

        total_chunks = metadata['total_chunks']
        uploaded_chunks = len(self.get_existing_chunks(upload_id))
        progress_percent = (uploaded_chunks / total_chunks) * 100 if total_chunks > 0 else 0

        return {
            'total_chunks': total_chunks,
            'uploaded_chunks': uploaded_chunks,
            'progress_percent': round(progress_percent, 2)
        }
```

### 3. Flask API Routes

**íŒŒì¼**: `dashboard/backend_5010/api/upload_routes.py`

```python
"""
Chunked Upload API Routes
"""

from flask import Blueprint, request, jsonify
from werkzeug.utils import secure_filename
import os
import logging

from utils.chunked_upload import ChunkedUploadManager

logger = logging.getLogger(__name__)

upload_bp = Blueprint('upload', __name__, url_prefix='/api/upload')
upload_manager = ChunkedUploadManager()

# í—ˆìš©ë˜ëŠ” íŒŒì¼ í™•ì¥ì (í•„ìš”ì‹œ ìˆ˜ì •)
ALLOWED_EXTENSIONS = {
    'txt', 'csv', 'json', 'yaml', 'yml',
    'py', 'sh', 'bash',
    'tar', 'gz', 'zip', 'bz2', 'xz',
    'sif', 'img',  # Apptainer images
    'h5', 'hdf5', 'nc', 'dat'  # Data files
}

def allowed_file(filename: str) -> bool:
    """íŒŒì¼ í™•ì¥ì ê²€ì¦"""
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS


@upload_bp.route('/init', methods=['POST'])
def init_upload():
    """
    ì—…ë¡œë“œ ì„¸ì…˜ ì´ˆê¸°í™”

    Request Body:
        {
            "filename": "large_file.tar.gz",
            "file_size": 1073741824,
            "chunk_size": 5242880
        }

    Response:
        {
            "success": true,
            "upload_id": "uuid-string",
            "total_chunks": 205,
            "existing_chunks": []
        }
    """
    try:
        data = request.get_json()

        filename = data.get('filename')
        file_size = data.get('file_size')
        chunk_size = data.get('chunk_size', 5 * 1024 * 1024)  # Default 5MB

        if not filename or not file_size:
            return jsonify({'error': 'Missing filename or file_size'}), 400

        # íŒŒì¼ëª… ê²€ì¦
        if not allowed_file(filename):
            return jsonify({'error': f'File type not allowed: {filename}'}), 400

        # íŒŒì¼ í¬ê¸° ì œí•œ (ì˜ˆ: 10GB)
        max_file_size = 10 * 1024 * 1024 * 1024  # 10GB
        if file_size > max_file_size:
            return jsonify({'error': f'File too large: {file_size} bytes (max: {max_file_size})'}), 400

        result = upload_manager.init_upload(filename, file_size, chunk_size)

        return jsonify({
            'success': True,
            **result
        })

    except Exception as e:
        logger.error(f"Failed to initialize upload: {e}")
        return jsonify({'error': str(e)}), 500


@upload_bp.route('/chunk', methods=['POST'])
def upload_chunk():
    """
    ì²­í¬ ë°ì´í„° ì—…ë¡œë“œ

    Request Form Data:
        upload_id: str
        chunk_index: int
        chunk: File (binary)

    Response:
        {
            "success": true,
            "chunk_index": 5,
            "progress": {
                "uploaded_chunks": 6,
                "total_chunks": 205,
                "progress_percent": 2.93
            }
        }
    """
    try:
        upload_id = request.form.get('upload_id')
        chunk_index = request.form.get('chunk_index')

        if not upload_id or chunk_index is None:
            return jsonify({'error': 'Missing upload_id or chunk_index'}), 400

        chunk_index = int(chunk_index)

        # ì²­í¬ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
        if 'chunk' not in request.files:
            return jsonify({'error': 'No chunk data'}), 400

        chunk_file = request.files['chunk']
        chunk_data = chunk_file.read()

        # ì²­í¬ ì €ì¥
        success = upload_manager.save_chunk(upload_id, chunk_index, chunk_data)

        if not success:
            return jsonify({'error': 'Failed to save chunk'}), 500

        # ì§„í–‰ ìƒí™© ë°˜í™˜
        progress = upload_manager.get_upload_progress(upload_id)

        return jsonify({
            'success': True,
            'chunk_index': chunk_index,
            'progress': progress
        })

    except Exception as e:
        logger.error(f"Failed to upload chunk: {e}")
        return jsonify({'error': str(e)}), 500


@upload_bp.route('/finalize', methods=['POST'])
def finalize_upload():
    """
    ì—…ë¡œë“œ ì™„ë£Œ ë° íŒŒì¼ ë³‘í•©

    Request Body:
        {
            "upload_id": "uuid-string",
            "filename": "large_file.tar.gz",
            "destination": "job_files"  # ì €ì¥ ìœ„ì¹˜ (ì„ íƒ)
        }

    Response:
        {
            "success": true,
            "file_path": "/uploads/job_files/large_file.tar.gz",
            "file_size": 1073741824
        }
    """
    try:
        data = request.get_json()

        upload_id = data.get('upload_id')
        filename = data.get('filename')
        destination = data.get('destination', 'job_files')

        if not upload_id or not filename:
            return jsonify({'error': 'Missing upload_id or filename'}), 400

        # ì•ˆì „í•œ íŒŒì¼ëª… ìƒì„±
        safe_filename = secure_filename(filename)

        # ìµœì¢… ì €ì¥ ê²½ë¡œ
        upload_base_dir = os.getenv('UPLOAD_DIR', '/uploads')
        output_dir = os.path.join(upload_base_dir, destination)
        os.makedirs(output_dir, exist_ok=True)

        output_path = os.path.join(output_dir, safe_filename)

        # ì²­í¬ ë³‘í•©
        success = upload_manager.finalize_upload(upload_id, output_path)

        if not success:
            return jsonify({'error': 'Failed to finalize upload'}), 500

        # íŒŒì¼ í¬ê¸° í™•ì¸
        file_size = os.path.getsize(output_path)

        return jsonify({
            'success': True,
            'file_path': output_path,
            'file_size': file_size
        })

    except Exception as e:
        logger.error(f"Failed to finalize upload: {e}")
        return jsonify({'error': str(e)}), 500


@upload_bp.route('/progress/<upload_id>', methods=['GET'])
def get_progress(upload_id: str):
    """
    ì—…ë¡œë“œ ì§„í–‰ ìƒí™© ì¡°íšŒ

    Response:
        {
            "total_chunks": 205,
            "uploaded_chunks": 50,
            "progress_percent": 24.39
        }
    """
    try:
        progress = upload_manager.get_upload_progress(upload_id)

        if 'error' in progress:
            return jsonify(progress), 404

        return jsonify(progress)

    except Exception as e:
        logger.error(f"Failed to get progress: {e}")
        return jsonify({'error': str(e)}), 500


@upload_bp.route('/cancel/<upload_id>', methods=['DELETE'])
def cancel_upload(upload_id: str):
    """
    ì—…ë¡œë“œ ì·¨ì†Œ ë° ì„ì‹œ íŒŒì¼ ì‚­ì œ

    Response:
        {
            "success": true,
            "message": "Upload cancelled"
        }
    """
    try:
        upload_manager.cleanup_upload(upload_id)

        return jsonify({
            'success': True,
            'message': 'Upload cancelled'
        })

    except Exception as e:
        logger.error(f"Failed to cancel upload: {e}")
        return jsonify({'error': str(e)}), 500
```

### 4. Flask App í†µí•©

**íŒŒì¼**: `dashboard/backend_5010/app.py` (ìˆ˜ì •)

```python
from flask import Flask
from flask_cors import CORS

# ... (ê¸°ì¡´ imports)

# ì—…ë¡œë“œ ë¼ìš°íŠ¸ ì¶”ê°€
from api.upload_routes import upload_bp

app = Flask(__name__)
CORS(app)

# ... (ê¸°ì¡´ ì„¤ì •)

# Blueprint ë“±ë¡
app.register_blueprint(upload_bp)

# ... (ê¸°ì¡´ ì½”ë“œ)
```

---

## Frontend êµ¬í˜„

### 1. íŒŒì¼ êµ¬ì¡°

```
dashboard/frontend_3010/src/
â”œâ”€â”€ hooks/
â”‚   â””â”€â”€ useChunkedUpload.ts    # ì²­í¬ ì—…ë¡œë“œ ì»¤ìŠ¤í…€ í›…
â”œâ”€â”€ components/
â”‚   â””â”€â”€ FileUploader/
â”‚       â”œâ”€â”€ FileUploader.tsx    # íŒŒì¼ ì—…ë¡œë“œ ì»´í¬ë„ŒíŠ¸
â”‚       â””â”€â”€ index.ts
â””â”€â”€ utils/
    â””â”€â”€ uploadApi.ts            # ì—…ë¡œë“œ API í˜¸ì¶œ ìœ í‹¸
```

### 2. Upload API Utility

**íŒŒì¼**: `dashboard/frontend_3010/src/utils/uploadApi.ts`

```typescript
/**
 * Chunked Upload API Client
 */

import axios from 'axios';

const API_BASE_URL = process.env.REACT_APP_API_URL || 'http://localhost:5010';

export interface InitUploadResponse {
  success: boolean;
  upload_id: string;
  total_chunks: number;
  existing_chunks: number[];
}

export interface UploadChunkResponse {
  success: boolean;
  chunk_index: number;
  progress: {
    uploaded_chunks: number;
    total_chunks: number;
    progress_percent: number;
  };
}

export interface FinalizeUploadResponse {
  success: boolean;
  file_path: string;
  file_size: number;
}

export interface ProgressResponse {
  total_chunks: number;
  uploaded_chunks: number;
  progress_percent: number;
}

/**
 * ì—…ë¡œë“œ ì„¸ì…˜ ì´ˆê¸°í™”
 */
export async function initUpload(
  filename: string,
  fileSize: number,
  chunkSize: number = 5 * 1024 * 1024 // Default 5MB
): Promise<InitUploadResponse> {
  const response = await axios.post(`${API_BASE_URL}/api/upload/init`, {
    filename,
    file_size: fileSize,
    chunk_size: chunkSize,
  });

  return response.data;
}

/**
 * ì²­í¬ ì—…ë¡œë“œ
 */
export async function uploadChunk(
  uploadId: string,
  chunkIndex: number,
  chunkData: Blob,
  onProgress?: (progress: number) => void
): Promise<UploadChunkResponse> {
  const formData = new FormData();
  formData.append('upload_id', uploadId);
  formData.append('chunk_index', chunkIndex.toString());
  formData.append('chunk', chunkData);

  const response = await axios.post(`${API_BASE_URL}/api/upload/chunk`, formData, {
    headers: {
      'Content-Type': 'multipart/form-data',
    },
    onUploadProgress: (progressEvent) => {
      if (onProgress && progressEvent.total) {
        const percent = (progressEvent.loaded / progressEvent.total) * 100;
        onProgress(percent);
      }
    },
  });

  return response.data;
}

/**
 * ì—…ë¡œë“œ ì™„ë£Œ
 */
export async function finalizeUpload(
  uploadId: string,
  filename: string,
  destination?: string
): Promise<FinalizeUploadResponse> {
  const response = await axios.post(`${API_BASE_URL}/api/upload/finalize`, {
    upload_id: uploadId,
    filename,
    destination,
  });

  return response.data;
}

/**
 * ì—…ë¡œë“œ ì§„í–‰ ìƒí™© ì¡°íšŒ
 */
export async function getUploadProgress(uploadId: string): Promise<ProgressResponse> {
  const response = await axios.get(`${API_BASE_URL}/api/upload/progress/${uploadId}`);
  return response.data;
}

/**
 * ì—…ë¡œë“œ ì·¨ì†Œ
 */
export async function cancelUpload(uploadId: string): Promise<void> {
  await axios.delete(`${API_BASE_URL}/api/upload/cancel/${uploadId}`);
}
```

### 3. Chunked Upload Hook

**íŒŒì¼**: `dashboard/frontend_3010/src/hooks/useChunkedUpload.ts`

```typescript
/**
 * useChunkedUpload Hook
 * ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²­í¬ ì—…ë¡œë“œ ê´€ë¦¬
 */

import { useState, useCallback, useRef } from 'react';
import {
  initUpload,
  uploadChunk,
  finalizeUpload,
  cancelUpload,
  UploadChunkResponse,
} from '../utils/uploadApi';

export interface UploadState {
  uploadId: string | null;
  status: 'idle' | 'uploading' | 'paused' | 'completed' | 'error';
  progress: number; // 0-100
  uploadedChunks: number;
  totalChunks: number;
  error: string | null;
  currentChunkProgress: number; // í˜„ì¬ ì²­í¬ ì—…ë¡œë“œ ì§„í–‰ë¥  (0-100)
}

export interface UseChunkedUploadOptions {
  chunkSize?: number; // Bytes (default: 5MB)
  maxRetries?: number; // ì²­í¬ ì—…ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ íšŸìˆ˜
  onProgress?: (progress: number) => void;
  onComplete?: (filePath: string) => void;
  onError?: (error: string) => void;
}

export function useChunkedUpload(options: UseChunkedUploadOptions = {}) {
  const {
    chunkSize = 5 * 1024 * 1024, // 5MB
    maxRetries = 3,
    onProgress,
    onComplete,
    onError,
  } = options;

  const [state, setState] = useState<UploadState>({
    uploadId: null,
    status: 'idle',
    progress: 0,
    uploadedChunks: 0,
    totalChunks: 0,
    error: null,
    currentChunkProgress: 0,
  });

  const abortControllerRef = useRef<AbortController | null>(null);
  const fileRef = useRef<File | null>(null);

  /**
   * íŒŒì¼ ì—…ë¡œë“œ ì‹œì‘
   */
  const startUpload = useCallback(
    async (file: File, destination?: string) => {
      try {
        // ì´ˆê¸°í™”
        setState({
          uploadId: null,
          status: 'uploading',
          progress: 0,
          uploadedChunks: 0,
          totalChunks: 0,
          error: null,
          currentChunkProgress: 0,
        });

        fileRef.current = file;
        abortControllerRef.current = new AbortController();

        // 1. ì—…ë¡œë“œ ì„¸ì…˜ ì´ˆê¸°í™”
        const initResponse = await initUpload(file.name, file.size, chunkSize);
        const { upload_id, total_chunks, existing_chunks } = initResponse;

        setState((prev) => ({
          ...prev,
          uploadId: upload_id,
          totalChunks: total_chunks,
          uploadedChunks: existing_chunks.length,
        }));

        // 2. ì²­í¬ ì—…ë¡œë“œ
        const uploadedSet = new Set(existing_chunks);

        for (let i = 0; i < total_chunks; i++) {
          // ì´ë¯¸ ì—…ë¡œë“œëœ ì²­í¬ëŠ” ìŠ¤í‚µ
          if (uploadedSet.has(i)) {
            continue;
          }

          // ì¤‘ë‹¨ í™•ì¸
          if (abortControllerRef.current?.signal.aborted) {
            setState((prev) => ({ ...prev, status: 'paused' }));
            return;
          }

          // ì²­í¬ ì¶”ì¶œ
          const start = i * chunkSize;
          const end = Math.min(start + chunkSize, file.size);
          const chunkBlob = file.slice(start, end);

          // ì¬ì‹œë„ ë¡œì§
          let retries = 0;
          let success = false;

          while (retries <= maxRetries && !success) {
            try {
              const chunkResponse = await uploadChunk(
                upload_id,
                i,
                chunkBlob,
                (chunkProgress) => {
                  setState((prev) => ({
                    ...prev,
                    currentChunkProgress: chunkProgress,
                  }));
                }
              );

              // ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
              const overallProgress = (chunkResponse.progress.uploaded_chunks / total_chunks) * 100;

              setState((prev) => ({
                ...prev,
                uploadedChunks: chunkResponse.progress.uploaded_chunks,
                progress: overallProgress,
                currentChunkProgress: 0,
              }));

              onProgress?.(overallProgress);
              success = true;

            } catch (error) {
              retries++;
              console.error(`Chunk ${i} upload failed (attempt ${retries}/${maxRetries}):`, error);

              if (retries > maxRetries) {
                throw new Error(`Failed to upload chunk ${i} after ${maxRetries} retries`);
              }

              // ì¬ì‹œë„ ì „ ëŒ€ê¸° (exponential backoff)
              await new Promise((resolve) => setTimeout(resolve, 1000 * Math.pow(2, retries - 1)));
            }
          }
        }

        // 3. ì—…ë¡œë“œ ì™„ë£Œ
        const finalizeResponse = await finalizeUpload(upload_id, file.name, destination);

        setState((prev) => ({
          ...prev,
          status: 'completed',
          progress: 100,
        }));

        onComplete?.(finalizeResponse.file_path);

      } catch (error: any) {
        const errorMessage = error.response?.data?.error || error.message || 'Upload failed';

        setState((prev) => ({
          ...prev,
          status: 'error',
          error: errorMessage,
        }));

        onError?.(errorMessage);
      }
    },
    [chunkSize, maxRetries, onProgress, onComplete, onError]
  );

  /**
   * ì—…ë¡œë“œ ì¼ì‹œì •ì§€
   */
  const pauseUpload = useCallback(() => {
    abortControllerRef.current?.abort();
    setState((prev) => ({ ...prev, status: 'paused' }));
  }, []);

  /**
   * ì—…ë¡œë“œ ì¬ê°œ
   */
  const resumeUpload = useCallback(
    async (destination?: string) => {
      if (!fileRef.current) {
        console.error('No file to resume');
        return;
      }

      setState((prev) => ({ ...prev, status: 'uploading' }));
      await startUpload(fileRef.current, destination);
    },
    [startUpload]
  );

  /**
   * ì—…ë¡œë“œ ì·¨ì†Œ
   */
  const cancelCurrentUpload = useCallback(async () => {
    if (state.uploadId) {
      try {
        await cancelUpload(state.uploadId);
      } catch (error) {
        console.error('Failed to cancel upload:', error);
      }
    }

    abortControllerRef.current?.abort();

    setState({
      uploadId: null,
      status: 'idle',
      progress: 0,
      uploadedChunks: 0,
      totalChunks: 0,
      error: null,
      currentChunkProgress: 0,
    });

    fileRef.current = null;
  }, [state.uploadId]);

  /**
   * ìƒíƒœ ë¦¬ì…‹
   */
  const reset = useCallback(() => {
    abortControllerRef.current?.abort();

    setState({
      uploadId: null,
      status: 'idle',
      progress: 0,
      uploadedChunks: 0,
      totalChunks: 0,
      error: null,
      currentChunkProgress: 0,
    });

    fileRef.current = null;
  }, []);

  return {
    state,
    startUpload,
    pauseUpload,
    resumeUpload,
    cancel: cancelCurrentUpload,
    reset,
  };
}
```

### 4. FileUploader Component

**íŒŒì¼**: `dashboard/frontend_3010/src/components/FileUploader/FileUploader.tsx`

```typescript
/**
 * FileUploader Component
 * ëŒ€ìš©ëŸ‰ íŒŒì¼ ì—…ë¡œë“œ UI
 */

import React, { useState, useRef } from 'react';
import { useChunkedUpload } from '../../hooks/useChunkedUpload';

export interface FileUploaderProps {
  onUploadComplete?: (filePath: string, filename: string) => void;
  onUploadError?: (error: string) => void;
  destination?: string; // ì—…ë¡œë“œ í´ë” (ì˜ˆ: 'job_files', 'templates')
  accept?: string; // í—ˆìš© íŒŒì¼ íƒ€ì… (ì˜ˆ: '.tar,.gz,.zip')
  maxSize?: number; // ìµœëŒ€ íŒŒì¼ í¬ê¸° (bytes)
  className?: string;
}

export const FileUploader: React.FC<FileUploaderProps> = ({
  onUploadComplete,
  onUploadError,
  destination = 'job_files',
  accept,
  maxSize = 10 * 1024 * 1024 * 1024, // Default 10GB
  className = '',
}) => {
  const [selectedFile, setSelectedFile] = useState<File | null>(null);
  const fileInputRef = useRef<HTMLInputElement>(null);

  const { state, startUpload, pauseUpload, resumeUpload, cancel, reset } = useChunkedUpload({
    chunkSize: 5 * 1024 * 1024, // 5MB chunks
    maxRetries: 3,
    onComplete: (filePath) => {
      onUploadComplete?.(filePath, selectedFile?.name || '');
      // ì™„ë£Œ í›„ ìë™ ë¦¬ì…‹ (ì„ íƒì‚¬í•­)
      // reset();
    },
    onError: (error) => {
      onUploadError?.(error);
    },
  });

  /**
   * íŒŒì¼ ì„ íƒ í•¸ë“¤ëŸ¬
   */
  const handleFileChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    const files = e.target.files;
    if (!files || files.length === 0) return;

    const file = files[0];

    // íŒŒì¼ í¬ê¸° ê²€ì¦
    if (file.size > maxSize) {
      alert(`File too large: ${(file.size / 1024 / 1024 / 1024).toFixed(2)} GB (max: ${(maxSize / 1024 / 1024 / 1024).toFixed(0)} GB)`);
      return;
    }

    setSelectedFile(file);
    reset(); // ì´ì „ ì—…ë¡œë“œ ìƒíƒœ ì´ˆê¸°í™”
  };

  /**
   * ì—…ë¡œë“œ ì‹œì‘
   */
  const handleStartUpload = () => {
    if (!selectedFile) {
      alert('Please select a file first');
      return;
    }

    startUpload(selectedFile, destination);
  };

  /**
   * íŒŒì¼ ì„ íƒ ë²„íŠ¼ í´ë¦­
   */
  const handleSelectFileClick = () => {
    fileInputRef.current?.click();
  };

  /**
   * ì—…ë¡œë“œ ì·¨ì†Œ
   */
  const handleCancel = () => {
    cancel();
    setSelectedFile(null);
    if (fileInputRef.current) {
      fileInputRef.current.value = '';
    }
  };

  /**
   * íŒŒì¼ í¬ê¸° í¬ë§·íŒ…
   */
  const formatFileSize = (bytes: number): string => {
    if (bytes === 0) return '0 Bytes';
    const k = 1024;
    const sizes = ['Bytes', 'KB', 'MB', 'GB'];
    const i = Math.floor(Math.log(bytes) / Math.log(k));
    return `${(bytes / Math.pow(k, i)).toFixed(2)} ${sizes[i]}`;
  };

  return (
    <div className={`file-uploader ${className}`}>
      {/* íŒŒì¼ ì„ íƒ */}
      <div className="mb-4">
        <input
          ref={fileInputRef}
          type="file"
          accept={accept}
          onChange={handleFileChange}
          className="hidden"
        />

        <button
          onClick={handleSelectFileClick}
          disabled={state.status === 'uploading'}
          className="px-4 py-2 bg-blue-500 text-white rounded hover:bg-blue-600 disabled:bg-gray-400"
        >
          {selectedFile ? 'Change File' : 'Select File'}
        </button>

        {selectedFile && (
          <div className="mt-2 text-sm text-gray-700">
            <p>
              <strong>Selected:</strong> {selectedFile.name}
            </p>
            <p>
              <strong>Size:</strong> {formatFileSize(selectedFile.size)}
            </p>
          </div>
        )}
      </div>

      {/* ì§„í–‰ ìƒíƒœ */}
      {state.status !== 'idle' && (
        <div className="mb-4">
          <div className="flex justify-between items-center mb-2">
            <span className="text-sm font-medium">
              {state.status === 'uploading' && 'Uploading...'}
              {state.status === 'paused' && 'Paused'}
              {state.status === 'completed' && 'Completed'}
              {state.status === 'error' && 'Error'}
            </span>
            <span className="text-sm text-gray-600">
              {state.uploadedChunks} / {state.totalChunks} chunks ({state.progress.toFixed(1)}%)
            </span>
          </div>

          {/* ì§„í–‰ë¥  ë°” */}
          <div className="w-full bg-gray-200 rounded-full h-4 overflow-hidden">
            <div
              className={`h-full rounded-full transition-all ${
                state.status === 'completed'
                  ? 'bg-green-500'
                  : state.status === 'error'
                  ? 'bg-red-500'
                  : 'bg-blue-500'
              }`}
              style={{ width: `${state.progress}%` }}
            />
          </div>

          {/* ì—ëŸ¬ ë©”ì‹œì§€ */}
          {state.error && (
            <div className="mt-2 p-2 bg-red-100 border border-red-400 text-red-700 rounded text-sm">
              {state.error}
            </div>
          )}
        </div>
      )}

      {/* ì»¨íŠ¸ë¡¤ ë²„íŠ¼ */}
      <div className="flex gap-2">
        {state.status === 'idle' && selectedFile && (
          <button
            onClick={handleStartUpload}
            className="px-4 py-2 bg-green-500 text-white rounded hover:bg-green-600"
          >
            Start Upload
          </button>
        )}

        {state.status === 'uploading' && (
          <button
            onClick={pauseUpload}
            className="px-4 py-2 bg-yellow-500 text-white rounded hover:bg-yellow-600"
          >
            Pause
          </button>
        )}

        {state.status === 'paused' && (
          <button
            onClick={() => resumeUpload(destination)}
            className="px-4 py-2 bg-blue-500 text-white rounded hover:bg-blue-600"
          >
            Resume
          </button>
        )}

        {(state.status === 'uploading' || state.status === 'paused') && (
          <button
            onClick={handleCancel}
            className="px-4 py-2 bg-red-500 text-white rounded hover:bg-red-600"
          >
            Cancel
          </button>
        )}

        {state.status === 'completed' && (
          <button
            onClick={() => {
              reset();
              setSelectedFile(null);
              if (fileInputRef.current) {
                fileInputRef.current.value = '';
              }
            }}
            className="px-4 py-2 bg-gray-500 text-white rounded hover:bg-gray-600"
          >
            Upload Another File
          </button>
        )}
      </div>
    </div>
  );
};

export default FileUploader;
```

### 5. Component Export

**íŒŒì¼**: `dashboard/frontend_3010/src/components/FileUploader/index.ts`

```typescript
export { FileUploader } from './FileUploader';
export type { FileUploaderProps } from './FileUploader';
```

---

## í…ŒìŠ¤íŠ¸

### 1. Backend í…ŒìŠ¤íŠ¸

**í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸**: `test_chunked_upload.py`

```python
"""
Chunked Upload Backend Test
"""

import requests
import os
from pathlib import Path

API_BASE = 'http://localhost:5010/api/upload'
TEST_FILE = '/path/to/large_test_file.tar.gz'  # í…ŒìŠ¤íŠ¸ìš© ëŒ€ìš©ëŸ‰ íŒŒì¼
CHUNK_SIZE = 5 * 1024 * 1024  # 5MB

def test_chunked_upload():
    """ì²­í¬ ì—…ë¡œë“œ ì „ì²´ í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""

    # 1. íŒŒì¼ ì •ë³´
    file_path = Path(TEST_FILE)
    file_size = file_path.stat().st_size
    filename = file_path.name

    print(f"Testing upload: {filename} ({file_size} bytes)")

    # 2. ì—…ë¡œë“œ ì´ˆê¸°í™”
    init_response = requests.post(f'{API_BASE}/init', json={
        'filename': filename,
        'file_size': file_size,
        'chunk_size': CHUNK_SIZE
    })

    assert init_response.status_code == 200
    init_data = init_response.json()
    upload_id = init_data['upload_id']
    total_chunks = init_data['total_chunks']

    print(f"Upload ID: {upload_id}, Total chunks: {total_chunks}")

    # 3. ì²­í¬ ì—…ë¡œë“œ
    with open(file_path, 'rb') as f:
        for chunk_index in range(total_chunks):
            chunk_data = f.read(CHUNK_SIZE)

            files = {'chunk': ('chunk', chunk_data)}
            data = {
                'upload_id': upload_id,
                'chunk_index': str(chunk_index)
            }

            chunk_response = requests.post(f'{API_BASE}/chunk', files=files, data=data)

            assert chunk_response.status_code == 200
            progress = chunk_response.json()['progress']

            print(f"Chunk {chunk_index + 1}/{total_chunks} uploaded ({progress['progress_percent']:.2f}%)")

    # 4. ì—…ë¡œë“œ ì™„ë£Œ
    finalize_response = requests.post(f'{API_BASE}/finalize', json={
        'upload_id': upload_id,
        'filename': filename,
        'destination': 'test_uploads'
    })

    assert finalize_response.status_code == 200
    finalize_data = finalize_response.json()

    print(f"Upload completed: {finalize_data['file_path']} ({finalize_data['file_size']} bytes)")

    # 5. íŒŒì¼ í¬ê¸° ê²€ì¦
    assert finalize_data['file_size'] == file_size

    print("âœ… All tests passed!")

if __name__ == '__main__':
    test_chunked_upload()
```

### 2. Frontend í…ŒìŠ¤íŠ¸

**í…ŒìŠ¤íŠ¸ í˜ì´ì§€**: `UploadTest.tsx`

```typescript
import React from 'react';
import { FileUploader } from '../components/FileUploader';

export const UploadTestPage: React.FC = () => {
  return (
    <div className="container mx-auto p-8">
      <h1 className="text-3xl font-bold mb-6">Chunked Upload Test</h1>

      <FileUploader
        destination="test_uploads"
        accept=".tar,.gz,.zip,.sif"
        maxSize={10 * 1024 * 1024 * 1024} // 10GB
        onUploadComplete={(filePath, filename) => {
          console.log('Upload completed:', filePath, filename);
          alert(`Upload completed: ${filename}`);
        }}
        onUploadError={(error) => {
          console.error('Upload error:', error);
          alert(`Upload error: ${error}`);
        }}
      />
    </div>
  );
};
```

---

## ì„±ëŠ¥ ìµœì í™”

### 1. ì²­í¬ í¬ê¸° ì¡°ì •

**ê¶Œì¥ ì²­í¬ í¬ê¸°**:
- **Fast Network (100 Mbps+)**: 10MB chunks
- **Normal Network (10-100 Mbps)**: 5MB chunks
- **Slow Network (<10 Mbps)**: 2MB chunks

**ë™ì  ì¡°ì •**:
```typescript
function getOptimalChunkSize(networkSpeed: number): number {
  // networkSpeed in Mbps
  if (networkSpeed >= 100) return 10 * 1024 * 1024; // 10MB
  if (networkSpeed >= 10) return 5 * 1024 * 1024;   // 5MB
  return 2 * 1024 * 1024;                            // 2MB
}
```

### 2. ë³‘ë ¬ ì²­í¬ ì—…ë¡œë“œ

**ë™ì‹œ ì—…ë¡œë“œ**: 2-3ê°œ ì²­í¬ë¥¼ ë™ì‹œì— ì—…ë¡œë“œí•˜ì—¬ ì²˜ë¦¬ëŸ‰ í–¥ìƒ

```typescript
// useChunkedUpload.ts ìˆ˜ì •
const CONCURRENT_CHUNKS = 2;

for (let i = 0; i < total_chunks; i += CONCURRENT_CHUNKS) {
  const chunkPromises = [];

  for (let j = 0; j < CONCURRENT_CHUNKS && (i + j) < total_chunks; j++) {
    const chunkIndex = i + j;
    if (uploadedSet.has(chunkIndex)) continue;

    const start = chunkIndex * chunkSize;
    const end = Math.min(start + chunkSize, file.size);
    const chunkBlob = file.slice(start, end);

    chunkPromises.push(uploadChunk(upload_id, chunkIndex, chunkBlob));
  }

  await Promise.all(chunkPromises);
}
```

### 3. ì„ì‹œ íŒŒì¼ ì •ë¦¬

**ìë™ ì •ë¦¬ ìŠ¤ì¼€ì¤„ëŸ¬** (Backend):

```python
# cleanup_scheduler.py
import os
import time
from pathlib import Path
from datetime import datetime, timedelta

CHUNK_UPLOAD_DIR = Path('/tmp/slurm_uploads')
MAX_AGE_HOURS = 24  # 24ì‹œê°„ ì´ìƒ ëœ ì„ì‹œ íŒŒì¼ ì‚­ì œ

def cleanup_old_uploads():
    """ì˜¤ë˜ëœ ì—…ë¡œë“œ ì„¸ì…˜ ì •ë¦¬"""
    now = datetime.now()

    for upload_dir in CHUNK_UPLOAD_DIR.iterdir():
        if not upload_dir.is_dir():
            continue

        # ë§ˆì§€ë§‰ ìˆ˜ì • ì‹œê°„ í™•ì¸
        mtime = datetime.fromtimestamp(upload_dir.stat().st_mtime)
        age = now - mtime

        if age > timedelta(hours=MAX_AGE_HOURS):
            print(f"Cleaning up old upload: {upload_dir.name} (age: {age})")
            import shutil
            shutil.rmtree(upload_dir)

if __name__ == '__main__':
    while True:
        cleanup_old_uploads()
        time.sleep(3600)  # Run every hour
```

---

## ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

### 1. íŒŒì¼ íƒ€ì… ê²€ì¦

```python
# upload_routes.py
ALLOWED_EXTENSIONS = {'tar', 'gz', 'zip', 'sif', ...}

def allowed_file(filename: str) -> bool:
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS
```

### 2. íŒŒì¼ í¬ê¸° ì œí•œ

```python
# upload_routes.py
MAX_FILE_SIZE = 10 * 1024 * 1024 * 1024  # 10GB

if file_size > MAX_FILE_SIZE:
    return jsonify({'error': 'File too large'}), 400
```

### 3. ì—…ë¡œë“œ ì„¸ì…˜ ì†Œìœ ê¶Œ í™•ì¸

```python
# upload_routes.py (ì¸ì¦ ì¶”ê°€ ì‹œ)
from flask_jwt_extended import jwt_required, get_jwt_identity

@upload_bp.route('/chunk', methods=['POST'])
@jwt_required()
def upload_chunk():
    user_id = get_jwt_identity()

    # ì—…ë¡œë“œ ì„¸ì…˜ ì†Œìœ ê¶Œ í™•ì¸
    upload_session = get_upload_session(upload_id)
    if upload_session['user_id'] != user_id:
        return jsonify({'error': 'Unauthorized'}), 403

    # ... ì²­í¬ ì—…ë¡œë“œ ì²˜ë¦¬
```

### 4. ë°”ì´ëŸ¬ìŠ¤ ìŠ¤ìº” (ì„ íƒì‚¬í•­)

```python
# upload_routes.py
import subprocess

def scan_file_for_virus(file_path: str) -> bool:
    """ClamAVë¡œ ë°”ì´ëŸ¬ìŠ¤ ìŠ¤ìº”"""
    try:
        result = subprocess.run(
            ['clamscan', '--no-summary', file_path],
            capture_output=True,
            timeout=300
        )
        return result.returncode == 0  # 0 = clean
    except Exception as e:
        logger.error(f"Virus scan failed: {e}")
        return False

@upload_bp.route('/finalize', methods=['POST'])
def finalize_upload():
    # ... ì²­í¬ ë³‘í•© í›„

    if not scan_file_for_virus(output_path):
        os.remove(output_path)
        return jsonify({'error': 'File contains malware'}), 400

    # ... ì •ìƒ ì‘ë‹µ
```

---

## ìš”ì•½

### êµ¬í˜„ ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

**Backend**:
- [x] ChunkedUploadManager í´ë˜ìŠ¤ (ì²­í¬ ê´€ë¦¬)
- [x] Flask API Routes (init, chunk, finalize, progress, cancel)
- [x] íŒŒì¼ íƒ€ì… ê²€ì¦
- [x] íŒŒì¼ í¬ê¸° ì œí•œ
- [x] ì—ëŸ¬ í•¸ë“¤ë§

**Frontend**:
- [x] uploadApi.ts (API í´ë¼ì´ì–¸íŠ¸)
- [x] useChunkedUpload Hook (ì²­í¬ ì—…ë¡œë“œ ë¡œì§)
- [x] FileUploader Component (UI)
- [x] ì§„í–‰ë¥  í‘œì‹œ
- [x] ì¬ê°œ/ì·¨ì†Œ ê¸°ëŠ¥

**í…ŒìŠ¤íŠ¸**:
- [x] Backend í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
- [x] Frontend í…ŒìŠ¤íŠ¸ í˜ì´ì§€

**ìµœì í™”**:
- [x] ì²­í¬ í¬ê¸° ì¡°ì • ê°€ì´ë“œ
- [x] ë³‘ë ¬ ì—…ë¡œë“œ ë°©ë²•
- [x] ì„ì‹œ íŒŒì¼ ì •ë¦¬ ìŠ¤ì¼€ì¤„ëŸ¬

**ë³´ì•ˆ**:
- [x] íŒŒì¼ íƒ€ì… ê²€ì¦
- [x] íŒŒì¼ í¬ê¸° ì œí•œ
- [x] ì—…ë¡œë“œ ì„¸ì…˜ ì†Œìœ ê¶Œ í™•ì¸
- [x] ë°”ì´ëŸ¬ìŠ¤ ìŠ¤ìº” (ì„ íƒ)

### ë‹¤ìŒ ë‹¨ê³„

1. **Backend ì„¤ì¹˜**:
   ```bash
   cd dashboard/backend_5010
   # (í•„ìš”ì‹œ) pip install flask-cors
   python app.py
   ```

2. **Frontend ì„¤ì¹˜**:
   ```bash
   cd dashboard/frontend_3010
   # (í•„ìš”ì‹œ) npm install axios
   npm start
   ```

3. **í…ŒìŠ¤íŠ¸**:
   - ëŒ€ìš©ëŸ‰ íŒŒì¼(1GB+) ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸
   - ë„¤íŠ¸ì›Œí¬ ëŠê¹€ ì‹œë®¬ë ˆì´ì…˜ â†’ ì¬ê°œ ê¸°ëŠ¥ í™•ì¸
   - ë™ì‹œ ë‹¤ìˆ˜ íŒŒì¼ ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸

4. **í”„ë¡œë•ì…˜ ë°°í¬**:
   - Nginx ì—…ë¡œë“œ í¬ê¸° ì œí•œ ì„¤ì •: `client_max_body_size 10G;`
   - Flask íƒ€ì„ì•„ì›ƒ ì„¤ì •
   - ì„ì‹œ íŒŒì¼ ì •ë¦¬ í¬ë¡ ì¡ ë“±ë¡

---

**ì‘ì„±ì¼**: 2025-11-10
**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 3-4 hours
**ë‚œì´ë„**: Medium
**ìš°ì„ ìˆœìœ„**: High
